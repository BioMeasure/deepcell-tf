{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "https://github.com/vanvalenlab/deepcell-tf/blob/master/scripts/feature_pyramids/RetinaNet%20-%20Movie.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import errno\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -\n",
      "X.shape: (192, 30, 154, 182, 1)\n",
      "y.shape: (192, 30, 154, 182, 1)\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "\n",
    "DATA_DIR = '/data/training_data/cells/3T3/NIH/movie'\n",
    "DATA_FILE = os.path.join(DATA_DIR, 'nuclear_movie_3T3_0-2_same.trks')\n",
    "\n",
    "# Load Information for hardcoded image size training\n",
    "seed = 1\n",
    "test_size = .2\n",
    "train_dict, test_dict = get_data(DATA_FILE, mode='siamese_daughters', seed=seed, test_size=test_size)\n",
    "X_train, y_train = train_dict['X'], train_dict['y']\n",
    "X_test, y_test = test_dict['X'], test_dict['y']\n",
    "\n",
    "print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Download four different sets of data (saves to ~/.keras/datasets)\n",
    "filename_3T3 = '3T3_NIH.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.nih_3t3.load_tracked_data(filename_3T3)\n",
    "print('3T3 -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up other required filepaths\n",
    "PREFIX = os.path.relpath(os.path.dirname(DATA_FILE), DATA_DIR)\n",
    "ROOT_DIR = '/data' # mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models', PREFIX))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs', PREFIX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each head of the model uses its own loss\n",
    "from deepcell.losses import RetinaNetLosses\n",
    "from deepcell.losses import discriminative_instance_loss\n",
    "\n",
    "\n",
    "sigma = 3.0\n",
    "alpha = 0.25\n",
    "gamma = 2.0\n",
    "iou_threshold = 0.5\n",
    "max_detections = 100\n",
    "mask_size = (28, 28)\n",
    "\n",
    "retinanet_losses = RetinaNetLosses(\n",
    "    sigma=sigma, alpha=alpha, gamma=gamma,\n",
    "    iou_threshold=iou_threshold,\n",
    "    mask_size=mask_size)\n",
    "\n",
    "loss = {\n",
    "    'regression': retinanet_losses.regress_loss,\n",
    "    'classification': retinanet_losses.classification_loss,\n",
    "    'association_features': discriminative_instance_loss,\n",
    "    'masks': retinanet_losses.mask_loss,\n",
    "    'final_detection': retinanet_losses.final_detection_loss,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RetinaMask Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "model_name = 'trackrcnn_model'\n",
    "backbone = 'resnet50'  # vgg16, vgg19, resnet50, densenet121, densenet169, densenet201\n",
    "\n",
    "n_epoch = 10  # Number of training epochs\n",
    "lr = 1e-5\n",
    "\n",
    "optimizer = Adam(lr=lr, clipnorm=0.001)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=lr, decay=0.99)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "num_classes = 1  # \"object\" is the only class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.utils.retinanet_anchor_utils import get_anchor_parameters\n",
    "\n",
    "flat_shape = [y_train.shape[0] * y_train.shape[1]] + list(y_train.shape[2:])\n",
    "flat_y = np.reshape(y_train, tuple(flat_shape)).astype('int')\n",
    "\n",
    "# Generate backbone information from the data\n",
    "backbone_levels, pyramid_levels, anchor_params = get_anchor_parameters(flat_y)\n",
    "\n",
    "fpb = 3  # number of frames in each training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0204 23:43:46.667853 140457387505472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0204 23:44:03.054301 140457387505472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0204 23:44:14.536428 140457387505472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rois.shape (?, ?, ?, ?, ?, ?)\n"
     ]
    }
   ],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "# Pass frames_per_batch > 1 to enable 3D mode!\n",
    "model = model_zoo.RetinaMask(\n",
    "    backbone=backbone,\n",
    "    input_shape=X_train.shape[2:],\n",
    "    frames_per_batch=fpb,\n",
    "    class_specific_filter=False,\n",
    "    num_classes=num_classes,\n",
    "    backbone_levels=backbone_levels,\n",
    "    pyramid_levels=pyramid_levels,\n",
    "    anchor_params=anchor_params\n",
    ")\n",
    "\n",
    "prediction_model = model\n",
    "\n",
    "# prediction_model = model_zoo.retinanet_bbox(\n",
    "#     model,\n",
    "#     panoptic=False,\n",
    "#     frames_per_batch=fpb,\n",
    "#     max_detections=100,\n",
    "#     anchor_params=anchor_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50_retinanet_mask\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        [(None, 3, 154, 182, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 3, 154, 182,  0           image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 3, 154, 182,  6           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 3, 39, 46, 25 229760      time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 3, 77, 91, 64 9728        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "C2_reduced (Conv3D)             (None, 3, 39, 46, 25 65792       time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "C1_reduced (Conv3D)             (None, 3, 77, 91, 25 16640       time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "P2_upsampled (UpsampleLike)     (None, None, None, N 0           C2_reduced[0][0]                 \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 3, 20, 23, 51 1460096     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "P1_merged (Add)                 (None, 3, 77, 91, 25 0           C1_reduced[0][0]                 \n",
      "                                                                 P2_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "C3_reduced (Conv3D)             (None, 3, 20, 23, 25 131328      time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "P1 (Conv3D)                     (None, 3, 77, 91, 25 590080      P1_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P3_upsampled (UpsampleLike)     (None, None, None, N 0           C3_reduced[0][0]                 \n",
      "                                                                 time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "P2_merged (Add)                 (None, 3, 39, 46, 25 0           C2_reduced[0][0]                 \n",
      "                                                                 P3_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "boxes_input (InputLayer)        [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "upsamplelike (UpsampleLike)     (None, None, None, N 0           P1[0][0]                         \n",
      "                                                                 image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "P2 (Conv3D)                     (None, 3, 39, 46, 25 590080      P2_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P3 (Conv3D)                     (None, 3, 20, 23, 25 590080      C3_reduced[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "roialign (RoiAlign)             (None, None, None, N 0           boxes_input[0][0]                \n",
      "                                                                 upsamplelike[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "regression_submodel (Model)     (None, 3, None, 4)   7327780     P1[0][0]                         \n",
      "                                                                 P2[0][0]                         \n",
      "                                                                 P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "classification_submodel (Model) (None, 3, None, 1)   7141129     P1[0][0]                         \n",
      "                                                                 P2[0][0]                         \n",
      "                                                                 P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "mask_submodel (TimeDistributed) (None, None, None, 2 2950657     roialign[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, None, None, 1 2950657     roialign[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, None, None, N 1032960     roialign[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "regression (Concatenate)        (None, 3, None, 4)   0           regression_submodel[1][0]        \n",
      "                                                                 regression_submodel[2][0]        \n",
      "                                                                 regression_submodel[3][0]        \n",
      "__________________________________________________________________________________________________\n",
      "classification (Concatenate)    (None, 3, None, 1)   0           classification_submodel[1][0]    \n",
      "                                                                 classification_submodel[2][0]    \n",
      "                                                                 classification_submodel[3][0]    \n",
      "__________________________________________________________________________________________________\n",
      "masks (ConcatenateBoxes)        (None, None, None, N 0           boxes_input[0][0]                \n",
      "                                                                 mask_submodel[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_detection (ConcatenateBox (None, None, None, N 0           boxes_input[0][0]                \n",
      "                                                                 time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "association_features (Concatena (None, None, None, N 0           boxes_input[0][0]                \n",
      "                                                                 time_distributed_14[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 24,847,285\n",
      "Trainable params: 24,837,173\n",
      "Non-trainable params: 10,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0204 23:44:16.171706 140457387505472 training_utils.py:1101] Output mask_submodel missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to mask_submodel.\n",
      "W0204 23:44:16.172880 140457387505472 training_utils.py:1101] Output time_distributed_9 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to time_distributed_9.\n",
      "W0204 23:44:16.173635 140457387505472 training_utils.py:1101] Output time_distributed_14 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to time_distributed_14.\n",
      "W0204 23:44:16.288187 140457387505472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/deepcell/losses.py:332: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0204 23:44:16.999886 140457387505472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "reduction_indices is deprecated, use axis instead\n",
      "W0204 23:44:17.085949 140457387505472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/deepcell/losses.py:203: The name tf.diag_part is deprecated. Please use tf.linalg.tensor_diag_part instead.\n",
      "\n",
      "W0204 23:44:17.088701 140457387505472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/deepcell/losses.py:204: The name tf.matrix_set_diag is deprecated. Please use tf.linalg.set_diag instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RetinaMask Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.image_generators import RetinaMovieDataGenerator\n",
    "\n",
    "datagen = RetinaMovieDataGenerator(\n",
    "    rotation_range=180,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "datagen_val = RetinaMovieDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dict keys :\n",
      "X\n",
      "y\n",
      "daughters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0204 23:44:20.387309 140457387505472 retinanet.py:651] Removing 2 of 192 images with fewer than 3 objects.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dict keys :\n",
      "X\n",
      "y\n",
      "daughters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0204 23:44:21.851473 140457387505472 retinanet.py:651] Removing 1 of 48 images with fewer than 3 objects.\n"
     ]
    }
   ],
   "source": [
    "train_data = datagen.flow(\n",
    "    train_dict,\n",
    "    batch_size=1,\n",
    "    include_masks=True,\n",
    "    include_final_detection_layer=True,\n",
    "    assoc_head=True,\n",
    "    frames_per_batch=fpb,\n",
    "    pyramid_levels=pyramid_levels,\n",
    "    anchor_params=anchor_params)\n",
    "\n",
    "val_data = datagen_val.flow(\n",
    "    test_dict,\n",
    "    batch_size=1,\n",
    "    include_masks=True,\n",
    "    include_final_detection_layer=True,\n",
    "    assoc_head=True,\n",
    "    frames_per_batch=fpb,\n",
    "    pyramid_levels=pyramid_levels,\n",
    "    anchor_params=anchor_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 13)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 13)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 13)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 13)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 27)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 27)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 27)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 27)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 7)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 6)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 7)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 7)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 8)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 9)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 7)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 8)\n",
      "ann['assoc_head'].shape:  (154, 182, 9)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 5)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 5)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 5)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 5)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 15)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 15)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 15)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 15)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 13)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 13)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 13)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 13)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 10)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 10)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 12)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 10)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 13)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 10)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 13)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 13)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 12)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 11)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 11)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 12)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 10)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 10)\n",
      "y shape:  (154, 182, 1)\n",
      "y_transform shape:  (154, 182, 10)\n",
      "regressions.shape:  (1, 3, 83349, 5)\n",
      "labels.shape:  (1, 3, 83349, 2)\n",
      "assoc_heads_batch_shape:  (1, 3, 154, 1456)\n",
      "ann['assoc_head'].shape:  (154, 182, 10)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2366) into shape (1456)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b7b73d750888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                      \u001b[0mframes_per_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                      weighted_average=True),\n\u001b[0;32m---> 29\u001b[0;31m             prediction_model)]\n\u001b[0m\u001b[1;32m     30\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(uid, i)\u001b[0m\n\u001b[1;32m    569\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mat\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mi\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m   \"\"\"\n\u001b[0;32m--> 571\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepcell/image_generators/retinanet.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    868\u001b[0m                     \u001b[0;31m# add flattened association head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massoc_head\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'assoc_head'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                         \u001b[0massoc_heads_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massoc_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2366) into shape (1456)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "from deepcell.callbacks import RedirectModel, Evaluate\n",
    "\n",
    "iou_threshold = 0.5\n",
    "score_threshold = 0.01\n",
    "max_detections = 100\n",
    "\n",
    "model.fit_generator(\n",
    "    train_data,\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    epochs=n_epoch,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=X_test.shape[0] // batch_size,\n",
    "    callbacks=[\n",
    "        callbacks.LearningRateScheduler(lr_sched),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            os.path.join(MODEL_DIR, model_name + '.h5'),\n",
    "            monitor='val_loss',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False),\n",
    "        RedirectModel(\n",
    "            Evaluate(val_data,\n",
    "                     iou_threshold=iou_threshold,\n",
    "                     score_threshold=score_threshold,\n",
    "                     max_detections=max_detections,\n",
    "                     frames_per_batch=fpb,\n",
    "                     weighted_average=True),\n",
    "            prediction_model)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs, batch_outputs = train_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in batch_inputs:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in batch_outputs:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 7.36526184e+01,  5.15165043e+00,  7.74914551e+01,\n",
       "           3.63908730e+01,  0.00000000e+00],\n",
       "         [ 5.89738693e+01,  4.60461617e+00,  6.09892578e+01,\n",
       "           2.83677044e+01,  0.00000000e+00],\n",
       "         [ 4.73233414e+01,  4.17043495e+00,  4.78914604e+01,\n",
       "           2.19997158e+01,  0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.47747576e+00, -1.42937860e+01, -2.05805826e+00,\n",
       "          -1.47638836e+01, -1.00000000e+00],\n",
       "         [-6.56924367e-01, -1.08292360e+01, -2.14923072e+00,\n",
       "          -1.22338505e+01, -1.00000000e+00],\n",
       "         [-5.65267634e-03, -8.07942200e+00, -2.22159410e+00,\n",
       "          -1.02257624e+01, -1.00000000e+00]],\n",
       "\n",
       "        [[ 2.05805826e+00,  1.61611652e+00,  2.80330086e+00,\n",
       "           1.87132034e+01,  0.00000000e+00],\n",
       "         [ 2.14923072e+00,  1.79846120e+00,  1.70923245e+00,\n",
       "           1.43369303e+01,  0.00000000e+00],\n",
       "         [ 2.22159410e+00,  1.94318831e+00,  8.40870261e-01,\n",
       "           1.08634806e+01,  0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.09792233e+01, -4.11650389e-02, -7.36135912e+00,\n",
       "          -2.72097087e+00, -1.00000000e+00],\n",
       "         [-8.19846630e+00,  4.83076125e-01, -6.35846329e+00,\n",
       "          -2.67538476e+00, -1.00000000e+00],\n",
       "         [-5.99137831e+00,  8.99166346e-01, -5.56246424e+00,\n",
       "          -2.63920283e+00, -1.00000000e+00]],\n",
       "\n",
       "        [[ 2.05805826e+00,  8.11656342e+01,  1.03163109e+01,\n",
       "           1.24779221e+02,  0.00000000e+00],\n",
       "         [ 2.14923072e+00,  6.49369507e+01,  7.67231178e+00,\n",
       "           9.85215759e+01,  0.00000000e+00],\n",
       "         [ 2.22159410e+00,  5.20562401e+01,  5.57376957e+00,\n",
       "           7.76808853e+01,  0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.72747574e+01, -4.79203892e+00, -3.56456299e+01,\n",
       "          -3.71533990e+00, -1.00000000e+00],\n",
       "         [-2.90692444e+01, -3.28769469e+00, -2.88077030e+01,\n",
       "          -3.46461582e+00, -1.00000000e+00],\n",
       "         [-2.25565262e+01, -2.09369659e+00, -2.33804398e+01,\n",
       "          -3.26561618e+00, -1.00000000e+00]]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
