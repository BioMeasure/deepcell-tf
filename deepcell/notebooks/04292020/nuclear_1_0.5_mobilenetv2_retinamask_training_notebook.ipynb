{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028918,
     "end_time": "2020-04-29T20:56:37.077703",
     "exception": false,
     "start_time": "2020-04-29T20:56:37.048785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# General nuclear segmentation training notebook\n",
    "\n",
    "This notebook trains a model to perform nuclear segmentation of fluorescent microscopy images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016419,
     "end_time": "2020-04-29T20:56:37.111163",
     "exception": false,
     "start_time": "2020-04-29T20:56:37.094744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 1: Import relevant python packages\n",
    "\n",
    "This section imports python packages that are used throughout the notebook and defines parameters that can be used with papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 3.436243,
     "end_time": "2020-04-29T20:56:40.563819",
     "exception": false,
     "start_time": "2020-04-29T20:56:37.127576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.027234,
     "end_time": "2020-04-29T20:56:40.610540",
     "exception": false,
     "start_time": "2020-04-29T20:56:40.583306",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Define parameters that can be set with papermill\n",
    "backbone = 'resnet50'\n",
    "dataset_name='general_nuclear'\n",
    "n_epochs = 8\n",
    "date = '04242020'\n",
    "dataset_fraction = .01\n",
    "train_test_seed = 0\n",
    "train_permutation_seed = 0\n",
    "train_val_seed=314\n",
    "model_type = 'watershed'\n",
    "batch_size = 4 if model_type == 'retinamask' else 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.02689,
     "end_time": "2020-04-29T20:56:40.655896",
     "exception": false,
     "start_time": "2020-04-29T20:56:40.629006",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_epochs = 16\n",
    "batch_size = 4\n",
    "date = \"04292020\"\n",
    "filename = \"nuclear_1_0.5_mobilenetv2_retinamask\"\n",
    "train_permutation_seed = 1\n",
    "dataset_fraction = 0.5\n",
    "backbone = \"mobilenetv2\"\n",
    "model_type = \"retinamask\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015736,
     "end_time": "2020-04-29T20:56:40.687506",
     "exception": false,
     "start_time": "2020-04-29T20:56:40.671770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 2: Load training data and create data generators\n",
    "\n",
    "Data generators augment data and feed it into the model training process. Here, we define the generators that will be used to train our segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 854.975025,
     "end_time": "2020-04-29T21:10:55.678609",
     "exception": false,
     "start_time": "2020-04-29T20:56:40.703584",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 40, 216, 256, 1) (180, 40, 216, 256, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259, 30, 135, 160, 1) (259, 30, 135, 160, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 30, 154, 182, 1) (240, 30, 154, 182, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 30, 202, 240, 1) (124, 30, 202, 240, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (53, 40, 216, 256, 1) to (212, 40, 128, 128, 1)\n",
      "Reshaped training data from (53, 40, 216, 256, 1) to (212, 40, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (80, 30, 135, 160, 1) to (320, 30, 128, 128, 1)\n",
      "Reshaped training data from (80, 30, 135, 160, 1) to (320, 30, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (83, 30, 154, 182, 1) to (332, 30, 128, 128, 1)\n",
      "Reshaped training data from (83, 30, 154, 182, 1) to (332, 30, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (41, 30, 202, 240, 1) to (164, 30, 128, 128, 1)\n",
      "Reshaped training data from (41, 30, 202, 240, 1) to (164, 30, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (21, 40, 216, 256, 1) to (84, 40, 128, 128, 1)\n",
      "Reshaped training data from (21, 40, 216, 256, 1) to (84, 40, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (12, 30, 135, 160, 1) to (48, 30, 128, 128, 1)\n",
      "Reshaped training data from (12, 30, 135, 160, 1) to (48, 30, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (25, 30, 154, 182, 1) to (100, 30, 128, 128, 1)\n",
      "Reshaped training data from (25, 30, 154, 182, 1) to (100, 30, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (6, 30, 202, 240, 1) to (24, 30, 128, 128, 1)\n",
      "Reshaped training data from (6, 30, 202, 240, 1) to (24, 30, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (36, 40, 128, 128, 1) to (36, 40, 128, 128, 1)\n",
      "Reshaped training data from (36, 40, 128, 128, 1) to (36, 40, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (52, 30, 128, 128, 1) to (52, 30, 128, 128, 1)\n",
      "Reshaped training data from (52, 30, 128, 128, 1) to (52, 30, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (48, 30, 128, 128, 1) to (48, 30, 128, 128, 1)\n",
      "Reshaped training data from (48, 30, 128, 128, 1) to (48, 30, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (25, 30, 202, 240, 1) to (100, 30, 128, 128, 1)\n",
      "Reshaped training data from (25, 30, 202, 240, 1) to (100, 30, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32960, 128, 128, 1) (32960, 128, 128, 1) (8520, 128, 128, 1) (8520, 128, 128, 1)\n",
      "Number of training tracks 4012\n",
      "Number of validation tracks 916\n",
      "Number of testing tracks 1925\n",
      "Number of training cells 95444\n",
      "Number of validation cells 22710\n",
      "Number of testing cells 42731\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.data_utils import get_data, reshape_movie\n",
    "from deepcell import image_generators\n",
    "from deepcell.utils import train_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepcell_tracking.utils import load_trks\n",
    "\n",
    "# Helper function - get unique tracks\n",
    "def get_n_tracks(array):\n",
    "    # array with dims (batch, time, x, y, c)\n",
    "    n_tracks = 0\n",
    "    for b in array:\n",
    "        n_tracks += len(np.unique(b)) - 1\n",
    "    return n_tracks\n",
    "\n",
    "# Helper function - get unique cells\n",
    "def get_n_cells(array):\n",
    "    # array with dims (batch, time, x, y, c)\n",
    "    n_cells = 0\n",
    "    for b in array:\n",
    "        for t in b:\n",
    "            n_cells += len(np.unique(t)) - 1\n",
    "    return n_cells\n",
    "\n",
    "# Helper function - convert indices\n",
    "def convert_indices(indices, X_list):\n",
    "    N_batches = np.array([x.shape[0] for x in X_list])\n",
    "    N_cumsum = np.cumsum(N_batches)\n",
    "    converted_index = []\n",
    "    for i in range(len(X_list)):\n",
    "        if i==0:\n",
    "            i_index = indices[indices < N_cumsum[i]]\n",
    "            converted_index.append(i_index)\n",
    "        else:\n",
    "            i_index = indices[np.logical_and(indices < N_cumsum[i], indices >= N_cumsum[i-1])] - N_cumsum[i-1]\n",
    "            converted_index.append(i_index)    \n",
    "    return converted_index\n",
    "\n",
    "# Helper function - reshape movies\n",
    "def reshape_list_of_movies(X_list, y_list, reshape_size=128, crop=False):\n",
    "    X_reshape = []\n",
    "    y_reshape = []\n",
    "    for Xl, yl in zip(X_list, y_list):\n",
    "        Xr, yr = reshape_movie(Xl, yl, reshape_size=reshape_size)\n",
    "        Xr = Xr.reshape((-1, reshape_size, reshape_size, Xr.shape[-1]))\n",
    "        yr = yr.reshape((-1, reshape_size, reshape_size, yr.shape[-1]))\n",
    "        X_reshape.append(Xr)\n",
    "        y_reshape.append(yr)\n",
    "    X_reshape = np.concatenate(X_reshape, axis=0)\n",
    "    y_reshape = np.concatenate(y_reshape, axis=0)\n",
    "    \n",
    "    return X_reshape, y_reshape\n",
    "\n",
    "# Load datasets \n",
    "dataset_direc = '/data/training_data/'\n",
    "\n",
    "hela_filename = 'HeLa_S3.trks'\n",
    "hek_filename = 'HEK293.trks'\n",
    "nih_filename = '3T3_NIH.trks'\n",
    "raw_filename = 'RAW2647.trks'\n",
    "\n",
    "filenames = [hela_filename, hek_filename, nih_filename, raw_filename]\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for filename in filenames:\n",
    "    path = os.path.join(dataset_direc, filename)\n",
    "    training_data = load_trks(path)\n",
    "    X = training_data['X']\n",
    "    y = training_data['y']\n",
    "    \n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "    # Split into training and testing dataset\n",
    "    Xt, Xtest, yt, ytest = train_test_split(X, y, test_size=0.2, random_state=train_test_seed)\n",
    "    \n",
    "    # Crop test dataset\n",
    "    X_test = [arr[:,:,0:128,0:128,:] for arr in X_test]\n",
    "    y_test = [arr[:,:,0:128,0:128,:] for arr in y_test]\n",
    "    \n",
    "    X_train.append(Xt)\n",
    "    y_train.append(yt)\n",
    "    X_test.append(Xtest)\n",
    "    y_test.append(ytest)\n",
    "    \n",
    "# Select subset of the training data\n",
    "N_batches = sum([x.shape[0] for x in X_train])\n",
    "index = np.arange(N_batches)\n",
    "dataset_size = int(dataset_fraction * N_batches)\n",
    "permuted_index = np.random.RandomState(seed=train_permutation_seed).permutation(index)\n",
    "reduced_index = permuted_index[0:dataset_size]\n",
    "converted_index = convert_indices(reduced_index, X_train)\n",
    "\n",
    "X_reduced = [x[ci] for x, ci in zip(X_train, converted_index)]\n",
    "y_reduced = [y[ci] for y, ci in zip(y_train, converted_index)]\n",
    "\n",
    "# Split into training and validation datasets\n",
    "N_batches = sum([x.shape[0] for x in X_reduced])\n",
    "index = np.arange(N_batches)\n",
    "val_size = int(0.2 * N_batches)\n",
    "permuted_index = np.random.RandomState(seed=train_val_seed).permutation(index)\n",
    "val_index = permuted_index[0:val_size]\n",
    "train_index = permuted_index[val_size:]\n",
    "\n",
    "val_ci = convert_indices(val_index, X_reduced)\n",
    "train_ci = convert_indices(train_index, X_reduced)\n",
    "\n",
    "X_train = [x[ci] for x, ci in zip(X_reduced, train_ci)]\n",
    "y_train = [y[ci] for y, ci in zip(y_reduced, train_ci)]\n",
    "\n",
    "X_val = [x[ci] for x, ci in zip(X_reduced, val_ci)]\n",
    "y_val = [y[ci] for y, ci in zip(y_reduced, val_ci)]\n",
    "    \n",
    "# Record the number of tracks and cells\n",
    "n_tracks_train = sum([get_n_tracks(y) for y in y_train])\n",
    "n_tracks_val = sum([get_n_tracks(y) for y in y_val])\n",
    "n_tracks_test = sum([get_n_tracks(y) for y in y_test])\n",
    "\n",
    "n_cells_train = sum([get_n_cells(y) for y in y_train])\n",
    "n_cells_val = sum([get_n_cells(y) for y in y_val])\n",
    "n_cells_test = sum([get_n_cells(y) for y in y_test])\n",
    "    \n",
    "# Reshape the datasets\n",
    "X_train, y_train = reshape_list_of_movies(X_train, y_train)\n",
    "X_val, y_val = reshape_list_of_movies(X_val, y_val)\n",
    "X_test, y_test = reshape_list_of_movies(X_test, y_test)\n",
    "\n",
    "train_dict = {'X':X_train, 'y':y_train}\n",
    "val_dict = {'X':X_val, 'y':y_val}\n",
    "test_dict = {'X':X_test, 'y':y_test}\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "print('Number of training tracks {}'.format(n_tracks_train))\n",
    "print('Number of validation tracks {}'.format(n_tracks_val))\n",
    "print('Number of testing tracks {}'.format(n_tracks_test))\n",
    "\n",
    "print('Number of training cells {}'.format(n_cells_train))\n",
    "print('Number of validation cells {}'.format(n_cells_val))\n",
    "print('Number of testing cells {}'.format(n_cells_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 9.993817,
     "end_time": "2020-04-29T21:11:05.702269",
     "exception": false,
     "start_time": "2020-04-29T21:10:55.708452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0429 21:11:01.930831 139978681857856 retinanet.py:357] Removing 6946 of 32960 images with fewer than 3 objects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:11:05.260400 139978681857856 retinanet.py:357] Removing 2146 of 8520 images with fewer than 3 objects.\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.retinanet_anchor_utils import generate_anchor_params\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# Get anchor settings for RetinaMask models\n",
    "pyramid_levels = ['P3', 'P4']\n",
    "anchor_size_dict = {'P3':16, 'P4':32}\n",
    "anchor_params = generate_anchor_params(pyramid_levels, anchor_size_dict)\n",
    "\n",
    "# Data augmentation parameters\n",
    "generator_kwargs = {}\n",
    "generator_kwargs['rotation_range'] = 180\n",
    "generator_kwargs['shear_range'] = 0\n",
    "generator_kwargs['zoom_range'] = 0.25\n",
    "generator_kwargs['horizontal_flip'] = True\n",
    "generator_kwargs['vertical_flip'] = True\n",
    "\n",
    "generator_val_kwargs = {}\n",
    "generator_val_kwargs['rotation_range'] = 0\n",
    "generator_val_kwargs['shear_range'] = 0\n",
    "generator_val_kwargs['zoom_range'] = 0\n",
    "generator_val_kwargs['horizontal_flip'] = False\n",
    "generator_val_kwargs['vertical_flip'] = False\n",
    "\n",
    "# Minimum number of objects in an image\n",
    "min_objects = 3 if model_type == 'retinamask' else 0\n",
    "\n",
    "# Random seed\n",
    "seed=808\n",
    "\n",
    "if model_type == 'watershed':\n",
    "    datagen = image_generators.SemanticDataGenerator(**generator_kwargs)\n",
    "    datagen_val = image_generators.SemanticDataGenerator(**generator_val_kwargs)\n",
    "    \n",
    "    train_data = datagen.flow(\n",
    "        train_dict,\n",
    "        seed=seed,\n",
    "        transforms=['centroid', 'watershed-cont', 'fgbg'],\n",
    "        transforms_kwargs={'watershed-cont': {'erosion_width': 1}, 'centroid': {'alpha':'auto', 'beta':0.5}},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    val_data = datagen_val.flow(\n",
    "        val_dict,\n",
    "        seed=seed,\n",
    "        transforms=['centroid', 'watershed-cont', 'fgbg'],\n",
    "        transforms_kwargs={'watershed-cont': {'erosion_width': 1}, 'centroid': {'alpha':'auto', 'beta':0.5}},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "elif model_type == 'pixelwise':\n",
    "    datagen = image_generators.SemanticDataGenerator(**generator_kwargs)\n",
    "    datagen_val = image_generators.SemanticDataGenerator(**generator_val_kwargs)\n",
    "    \n",
    "    train_data = datagen.flow(\n",
    "        train_dict,\n",
    "        seed=seed,\n",
    "        transforms=['pixelwise'],\n",
    "        transforms_kwargs={},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    val_data = datagen_val.flow(\n",
    "        val_dict,\n",
    "        seed=seed,\n",
    "        transforms=['pixelwise'],\n",
    "        transforms_kwargs={},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "elif model_type == 'retinamask':\n",
    "    datagen = image_generators.RetinaNetGenerator(**generator_kwargs)\n",
    "    datagen_val = image_generators.RetinaNetGenerator(**generator_val_kwargs)\n",
    "    \n",
    "    train_data = datagen.flow(\n",
    "        train_dict=train_dict,\n",
    "        seed=seed,\n",
    "        transforms=[],\n",
    "        transforms_kwargs={},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size,\n",
    "        anchor_params=anchor_params,\n",
    "        pyramid_levels=pyramid_levels,\n",
    "        include_masks=True)\n",
    "    \n",
    "    val_data = datagen_val.flow(\n",
    "        train_dict=val_dict,\n",
    "        seed=seed,\n",
    "        transforms=[],\n",
    "        transforms_kwargs={},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size,\n",
    "        anchor_params=anchor_params,\n",
    "        pyramid_levels=pyramid_levels,\n",
    "        include_masks=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025566,
     "end_time": "2020-04-29T21:11:05.758530",
     "exception": false,
     "start_time": "2020-04-29T21:11:05.732964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 3: Define model\n",
    "\n",
    "Here we define a PanopticNet to perform the image segmentation. This model will predict the inner distance and outer distance transform (as done in ), as well as the foreground-background transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 32.686215,
     "end_time": "2020-04-29T21:11:38.470691",
     "exception": false,
     "start_time": "2020-04-29T21:11:05.784476",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:11:05.843412 139978681857856 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   8192/9406464 [..............................] - ETA: 1:13"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  40960/9406464 [..............................] - ETA: 29s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 106496/9406464 [..............................] - ETA: 16s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 245760/9406464 [..............................] - ETA: 9s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 442368/9406464 [>.............................] - ETA: 6s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 909312/9406464 [=>............................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1728512/9406464 [====>.........................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "3366912/9406464 [=========>....................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "6496256/9406464 [===================>..........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "8347648/9406464 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "9412608/9406464 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:11:31.195525 139978681857856 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:11:36.591612 139978681857856 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:11:37.578872 139978681857856 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:11:37.863636 139978681857856 training_utils.py:1101] Output filtered_detections missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to filtered_detections.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:11:37.864525 139978681857856 training_utils.py:1101] Output filtered_detections_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to filtered_detections_1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:11:37.865342 139978681857856 training_utils.py:1101] Output filtered_detections_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to filtered_detections_2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:11:37.866105 139978681857856 training_utils.py:1101] Output mask_submodel missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to mask_submodel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_retinanet_mask\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization2d (ImageNor (None, 128, 128, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tensor_product (TensorProduct)  (None, 128, 128, 3)  6           image_normalization2d[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 129, 129, 3)  0           tensor_product[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 64, 64, 32)   864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 64, 64, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 64, 64, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 64, 64, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 64, 64, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 64, 64, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 64, 64, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 64, 64, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 64, 64, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 64, 64, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 64, 64, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 65, 65, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 32, 32, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 32, 32, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 32, 32, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 32, 32, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 32, 32, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 32, 32, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 32, 32, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 32, 32, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 32, 32, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 32, 32, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 32, 32, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 32, 32, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 32, 32, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 33, 33, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 16, 16, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 16, 16, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 16, 16, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 16, 16, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 16, 16, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 16, 16, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 16, 16, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 16, 16, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 16, 16, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 16, 16, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 16, 16, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 16, 16, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 16, 16, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 16, 16, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 17, 17, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 8, 8, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 8, 8, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 8, 8, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 8, 8, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 8, 8, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 8, 8, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 8, 8, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 8, 8, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 8, 8, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 8, 8, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 8, 8, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 8, 8, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 8, 8, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 8, 8, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 8, 8, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 8, 8, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 8, 8, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 8, 8, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 8, 8, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 8, 8, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 8, 8, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 8, 8, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 8, 8, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 8, 8, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 8, 8, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 8, 8, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 8, 8, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 8, 8, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 8, 8, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 8, 8, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 8, 8, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 8, 8, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 8, 8, 576)    55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 9, 9, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 4, 4, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 4, 4, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 4, 4, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 4, 4, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 4, 4, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 4, 4, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 4, 4, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 4, 4, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 4, 4, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 4, 4, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 4, 4, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 4, 4, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 4, 4, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 4, 4, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 4, 4, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 4, 4, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "C5_reduced (Conv2D)             (None, 4, 4, 256)    82176       block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C4_reduced (Conv2D)             (None, 8, 8, 256)    24832       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "P5_upsampled (UpsampleLike)     (None, None, None, 2 0           C5_reduced[0][0]                 \n",
      "                                                                 block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "P4_merged (Add)                 (None, 8, 8, 256)    0           C4_reduced[0][0]                 \n",
      "                                                                 P5_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "C3_reduced (Conv2D)             (None, 16, 16, 256)  8448        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "P4_upsampled (UpsampleLike)     (None, None, None, 2 0           P4_merged[0][0]                  \n",
      "                                                                 block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "P3_merged (Add)                 (None, 16, 16, 256)  0           C3_reduced[0][0]                 \n",
      "                                                                 P4_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "P3 (Conv2D)                     (None, 16, 16, 256)  590080      P3_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P4 (Conv2D)                     (None, 8, 8, 256)    590080      P4_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "regression_submodel (Model)     (None, None, 4)      2443300     P3[0][0]                         \n",
      "                                                                 P4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "anchors_0 (Anchors)             (None, None, 4)      36          P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "anchors_1 (Anchors)             (None, None, 4)      36          P4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "regression (Concatenate)        (None, None, 4)      0           regression_submodel[1][0]        \n",
      "                                                                 regression_submodel[2][0]        \n",
      "__________________________________________________________________________________________________\n",
      "anchors (Concatenate)           (None, None, 4)      0           anchors_0[0][0]                  \n",
      "                                                                 anchors_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification_submodel (Model) (None, None, 1)      2381065     P3[0][0]                         \n",
      "                                                                 P4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "boxes (RegressBoxes)            (None, None, 4)      0           anchors[0][0]                    \n",
      "                                                                 regression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "classification (Concatenate)    (None, None, 1)      0           classification_submodel[1][0]    \n",
      "                                                                 classification_submodel[2][0]    \n",
      "__________________________________________________________________________________________________\n",
      "clipped_boxes (ClipBoxes)       (None, None, 4)      0           input_1[0][0]                    \n",
      "                                                                 boxes[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "filtered_detections (FilterDete [(None, 100, 4), (No 0           clipped_boxes[0][0]              \n",
      "                                                                 classification[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "upsample_like (UpsampleLike)    (None, None, None, 2 0           P3[0][0]                         \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "roi_align (RoiAlign)            (None, 100, 14, 14,  0           filtered_detections[0][0]        \n",
      "                                                                 upsample_like[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask_submodel (Model)           multiple             2950657     roi_align[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masks (ConcatenateBoxes)        (None, 100, None)    0           filtered_detections[0][0]        \n",
      "                                                                 mask_submodel[1][0]              \n",
      "==================================================================================================\n",
      "Total params: 10,913,980\n",
      "Trainable params: 10,882,428\n",
      "Non-trainable params: 31,552\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "from deepcell.model_zoo.retinamask import RetinaMask\n",
    "from deepcell import losses\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.losses import MSE\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = Adam(lr=1e-4, clipnorm=0.001)\n",
    "    \n",
    "if model_type == 'watershed':\n",
    "    model = PanopticNet(backbone,\n",
    "                       input_shape=train_data.x.shape[1:],\n",
    "                       norm_method='whole_image',\n",
    "                       num_semantic_heads=3,\n",
    "                       num_semantic_classes=[1,1,2],\n",
    "                       location=True,\n",
    "                       include_top=True,\n",
    "                       interpolation='bilinear',\n",
    "                       lite=True)\n",
    "\n",
    "    # Define loss\n",
    "    loss_layers = ['semantic_0', 'semantic_1', 'semantic_2']\n",
    "    loss = {}\n",
    "\n",
    "    for layer_name in loss_layers:\n",
    "        n_classes = model.get_layer(layer_name).output_shape[-1]\n",
    "        if n_classes > 1:\n",
    "            def loss_function(y_true, y_pred):\n",
    "                return 0.01 * losses.weighted_categorical_crossentropy(\n",
    "                    y_true, y_pred, n_classes=n_classes)\n",
    "            loss[layer_name] = loss_function\n",
    "        elif n_classes == 1:\n",
    "            loss[layer_name] = MSE\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "elif model_type == 'pixelwise':\n",
    "    model = PanopticNet(backbone,\n",
    "                       input_shape=train_data.x.shape[1:],\n",
    "                       norm_method='whole_image',\n",
    "                       num_semantic_heads=1,\n",
    "                       num_semantic_classes=[3],\n",
    "                       location=False,\n",
    "                       include_top=True)\n",
    "\n",
    "    # Define loss\n",
    "    loss = {}\n",
    "    \n",
    "    def loss_function(y_true, y_pred):\n",
    "        return losses.weighted_categorical_crossentropy(\n",
    "                    y_true, y_pred, n_classes=3)\n",
    "    \n",
    "    loss['semantic_0'] = loss_function\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "elif model_type == 'retinamask':\n",
    "    model = RetinaMask(backbone,\n",
    "                      num_classes=1,\n",
    "                      input_shape=train_data.x.shape[1:],\n",
    "                      norm_method='whole_image',\n",
    "                      use_imagenet=True,\n",
    "                      pyramid_levels=pyramid_levels,\n",
    "                      anchor_params=anchor_params)\n",
    "    \n",
    "    # Define loss\n",
    "    retinanet_losses = losses.RetinaNetLosses()\n",
    "    loss = {\n",
    "        'regression': retinanet_losses.regress_loss,\n",
    "        'classification': retinanet_losses.classification_loss,\n",
    "        'masks': retinanet_losses.mask_loss\n",
    "    }\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037086,
     "end_time": "2020-04-29T21:11:38.546463",
     "exception": false,
     "start_time": "2020-04-29T21:11:38.509377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 4: Define model training parameters\n",
    "\n",
    "Here, we define all of the parameters needed for training. The model trainer objects will record these metadata after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.042093,
     "end_time": "2020-04-29T21:11:38.625871",
     "exception": false,
     "start_time": "2020-04-29T21:11:38.583778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'nuclear_{}_{}_{}_{}'.format(str(train_permutation_seed), dataset_fraction, backbone, model_type)\n",
    "model_path = os.path.join('/data', 'models', date, model_name)\n",
    "dataset_metadata={'name': dataset_name,\n",
    "                  'other': 'Pooled nuclear data from HEK293, HeLa-S3, NIH-3T3, and RAW264.7 cells.'}\n",
    "training_kwargs = {}\n",
    "training_kwargs['batch_size'] = batch_size\n",
    "training_kwargs['lr'] = 1e-5 if model_type=='retinamask' else 1e-4\n",
    "training_kwargs['lr_decay'] = 0.95\n",
    "training_kwargs['training_seed'] = 0\n",
    "training_kwargs['n_epochs'] = n_epochs\n",
    "training_kwargs['training_steps_per_epoch'] = 82800//16 if model_type == 'retinamask' else 82800 // training_kwargs['batch_size']\n",
    "training_kwargs['validation_steps_per_epoch'] = val_data.y.shape[0] // training_kwargs['batch_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029162,
     "end_time": "2020-04-29T21:11:38.687886",
     "exception": false,
     "start_time": "2020-04-29T21:11:38.658724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 5: Create the model trainer and train the model\n",
    "\n",
    "Here, we create the model trainer, train the model, and export the model - along with the metadata and benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.090569,
     "end_time": "2020-04-29T21:11:38.807550",
     "exception": false,
     "start_time": "2020-04-29T21:11:38.716981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "from deepcell.utils.export_utils import export_model\n",
    "from deepcell.utils.train_utils import rate_scheduler, get_callbacks\n",
    "from deepcell.metrics import Metrics\n",
    "\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "class ModelTrainer(object):\n",
    "    def __init__(self, \n",
    "                model,\n",
    "                model_name,\n",
    "                model_path,\n",
    "                train_generator,\n",
    "                validation_generator,\n",
    "                benchmarking_data=None,\n",
    "                log_dir=None,\n",
    "                tfserving_path=None,\n",
    "                training_callbacks='default',\n",
    "                max_batch_size=256,\n",
    "                export_precisions = ['fp16'],\n",
    "                postprocessing_fn=None,\n",
    "                postprocessing_kwargs={},\n",
    "                predict_batch_size=4,\n",
    "                model_version=0,\n",
    "                min_size=100,\n",
    "                dataset_metadata={},\n",
    "                training_kwargs={}):\n",
    "    \n",
    "        \"\"\"\n",
    "        Model trainer class for segmentation models. This class eases model development by\n",
    "        linking relevant metadata (dataset, training parameters, benchmarking) to the model\n",
    "        training process.\n",
    "        \"\"\"\n",
    "\n",
    "        # Add model information\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "        self.model_version = model_version\n",
    "\n",
    "        # Add dataset information\n",
    "        self.train_generator = train_generator\n",
    "        self.validation_generator = validation_generator\n",
    "        self.benchmarking_data = benchmarking_data\n",
    "        self.dataset_metadata = dataset_metadata\n",
    "        self.postprocessing_fn = postprocessing_fn\n",
    "        self.postprocessing_kwargs = postprocessing_kwargs\n",
    "        self.predict_batch_size = predict_batch_size\n",
    "\n",
    "        # Add benchmarking information\n",
    "        self.min_size = min_size\n",
    "\n",
    "        # Add export information\n",
    "        self.max_batch_size = max_batch_size\n",
    "        self.export_precisions = export_precisions\n",
    "\n",
    "        # Add directories for logging and model export\n",
    "        if log_dir is None:\n",
    "            self.log_dir = os.path.join(model_path, 'logging')\n",
    "        else:\n",
    "            self.log_dir = log_dir\n",
    "        \n",
    "        if tfserving_path is None:\n",
    "            self.tfserving_path = os.path.join(model_path, 'serving')\n",
    "        else:\n",
    "            self.tfserving_path = tfserving_path\n",
    "\n",
    "        # Add training kwargs\n",
    "        self.batch_size = training_kwargs.pop('batch_size', 1)\n",
    "        self.training_steps_per_epoch = training_kwargs.pop('training_steps_per_epoch', \n",
    "                                                self.train_generator.y.shape[0] // self.batch_size)\n",
    "        self.validation_steps_per_epoch = training_kwargs.pop('validation_steps_per_epoch', \n",
    "                                                self.validation_generator.y.shape[0] // self.batch_size)\n",
    "        self.n_epochs = training_kwargs.pop('n_epochs', 8)\n",
    "        self.lr = training_kwargs.pop('lr', 1e-5)\n",
    "        self.lr_decay = training_kwargs.pop('lr_decay', 0.95)\n",
    "        self.lr_sched = training_kwargs.pop('lr_sched', rate_scheduler(lr=self.lr, decay=self.lr_decay))\n",
    "\n",
    "        # Add callbacks\n",
    "        if training_callbacks == 'default':\n",
    "            model_name = os.path.join(model_path, model_name + '.h5')\n",
    "            self.training_callbacks = get_callbacks(model_name, lr_sched=self.lr_sched,\n",
    "                                        tensorboard_log_dir=self.log_dir,\n",
    "                                        save_weights_only=False,\n",
    "                                        monitor='val_loss', verbose=1)\n",
    "        else:\n",
    "            self.training_callbacks = training_callbacks\n",
    "\n",
    "        self.trained = False\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _create_hash(self):\n",
    "        if not self.trained:\n",
    "            raise ValueError('Can only create a hash for a trained model')\n",
    "        else:\n",
    "            weights = []\n",
    "            for layer in self.model.layers:\n",
    "                weights += layer.get_weights()\n",
    "            summed_weights_list = [np.sum(w) for w in weights]\n",
    "            summed_weights = sum(summed_weights_list)\n",
    "            model_hash = hashlib.md5(str(summed_weights).encode())\n",
    "            self.model_hash = model_hash.hexdigest()\n",
    "\n",
    "    def _fit(self):\n",
    "        loss_history = self.model.fit_generator(\n",
    "        self.train_generator,\n",
    "        steps_per_epoch=self.training_steps_per_epoch,\n",
    "        epochs=self.n_epochs,\n",
    "        validation_data=self.validation_generator,\n",
    "        validation_steps=self.validation_steps_per_epoch,\n",
    "        callbacks=self.training_callbacks,\n",
    "        verbose=2)\n",
    "\n",
    "        self.trained = True\n",
    "        self.loss_history = loss_history\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _benchmark(self):\n",
    "        if not self.trained:\n",
    "            raise ValueError('Model training is not complete')\n",
    "        else:\n",
    "            if self.benchmarking_data is None:\n",
    "                x = self.validation_generator.x.copy()\n",
    "                y_true = self.validation_generator.y.copy()\n",
    "            else:\n",
    "                x = self.benchmarking_data['X']\n",
    "                y_true = self.benchmarking_data['y']\n",
    "\n",
    "            outputs = self.model.predict(x, batch_size=self.predict_batch_size)\n",
    "            y_pred = self.postprocessing_fn(outputs, **self.postprocessing_kwargs)\n",
    "\n",
    "            if len(y_pred.shape) == 3:\n",
    "                y_pred = np.expand_dims(y_pred, axis=-1)    #TODO: This is a hack because the postprocessing fn returns\n",
    "                                                            #masks with no channel dimensions. This should be fixed.\n",
    "            \n",
    "            benchmarks = Metrics(self.model_name, seg=False)\n",
    "            benchmarks.calc_object_stats(y_true, y_pred)\n",
    "\n",
    "            # Save benchmarks in dict\n",
    "            self.benchmarks = {}\n",
    "            for key in benchmarks.stats.keys():\n",
    "                self.benchmarks[key] = int(benchmarks.stats[key].sum())\n",
    "\n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred[i] = remove_small_objects(y_pred[i].astype(int), min_size=self.min_size)\n",
    "                y_true[i] = remove_small_objects(y_true[i].astype(int), min_size=self.min_size)\n",
    "\n",
    "            benchmarks = Metrics(self.model_name + ' - Removed objects less than {} pixels'.format(self.min_size), \n",
    "                                    seg=False)\n",
    "            benchmarks.calc_object_stats(y_true, y_pred)\n",
    "\n",
    "            # Save benchmarks in dict\n",
    "            self.benchmarks_remove_small_objects = {}\n",
    "            for key in benchmarks.stats.keys():\n",
    "                self.benchmarks_remove_small_objects[key] = int(benchmarks.stats[key].sum())\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _create_training_metadata(self):\n",
    "        training_metadata = {}\n",
    "        training_metadata['batch_size'] = self.batch_size\n",
    "        training_metadata['lr'] = self.lr\n",
    "        training_metadata['lr_decay'] = self.lr_decay\n",
    "        training_metadata['n_epochs'] = self.n_epochs\n",
    "        training_metadata['training_steps_per_epoch'] = self.training_steps_per_epoch\n",
    "        training_metadata['validation_steps_per_epoch'] = self.validation_steps_per_epoch\n",
    "\n",
    "        self.training_metadata = training_metadata\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _export_tf_serving(self):\n",
    "        export_model(self.model, self.tfserving_path, model_version=self.model_version)\n",
    "\n",
    "        # Convert model to TensorRT with float16\n",
    "        if 'fp16' in self.export_precisions:\n",
    "            export_model_dir = os.path.join(self.tfserving_path, str(self.model_version))\n",
    "            export_model_dir_fp16 = os.path.join(self.tfserving_path + '_fp16', str(self.model_version))\n",
    "\n",
    "            converter = trt.TrtGraphConverter(input_saved_model_dir=export_model_dir,\n",
    "                                            max_batch_size=self.max_batch_size,\n",
    "                                            precision_mode='fp16')\n",
    "            converter.convert()\n",
    "            converter.save(export_model_dir_fp16)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def create_model(self, export_serving=False, export_lite=False):\n",
    "\n",
    "        # Train model\n",
    "        self._fit()\n",
    "\n",
    "        # Load best performing weights\n",
    "        model_name = os.path.join(self.model_path, self.model_name + '.h5')\n",
    "        self.model.load_weights(model_name)\n",
    "\n",
    "        # Create model hash\n",
    "        self._create_hash()\n",
    "\n",
    "        # Create benchmarks\n",
    "        self._benchmark()\n",
    "\n",
    "        # Create model metadata\n",
    "        self._create_training_metadata()\n",
    "\n",
    "        # Save model\n",
    "        model_name = os.path.join(self.model_path, self.model_name + '_' + self.model_hash + '.h5')\n",
    "        self.model.save(model_name)\n",
    "\n",
    "        # Save loss history\n",
    "        loss_name = os.path.join(self.model_path, self.model_name + '_loss_' + self.model_hash + '.npz')\n",
    "        np.savez(loss_name, loss_history=self.loss_history.history)\n",
    "\n",
    "        # Save metadata (training and dataset) and benchmarks\n",
    "        metadata = {}\n",
    "        metadata['model_hash'] = self.model_hash\n",
    "        metadata['training_metadata'] = self.training_metadata\n",
    "        metadata['dataset_metadata'] = self.dataset_metadata\n",
    "        metadata['benchmarks'] = self.benchmarks\n",
    "        metadata['benchmarks_remove_small_objects'] = self.benchmarks_remove_small_objects\n",
    "\n",
    "        # TODO: Saving the benchmarking object in this way saves each individual benchmark.\n",
    "        # This should be refactored to save the sums.\n",
    "\n",
    "        metadata_name = os.path.join(self.model_path, self.model_name + '_' + self.model_hash + '.json')\n",
    "        \n",
    "        with open(metadata_name, 'w') as json_file:\n",
    "            json.dump(metadata, json_file)\n",
    "\n",
    "        # Export tf serving model\n",
    "        if export_serving:\n",
    "            self._export_tf_serving()\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 25693.005576,
     "end_time": "2020-04-30T04:19:51.846602",
     "exception": false,
     "start_time": "2020-04-29T21:11:38.841026",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 21:12:09.325457 139978681857856 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (0.264857). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 724.20604, saving model to /data/models/04292020/nuclear_1_0.5_mobilenetv2_retinamask/nuclear_1_0.5_mobilenetv2_retinamask.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 1597s - loss: 3.3305 - regression_loss: 2.3071 - classification_loss: 0.4815 - masks_loss: 0.5418 - val_loss: 724.2060 - val_regression_loss: 10.4103 - val_classification_loss: 713.5737 - val_masks_loss: 0.2227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss did not improve from 724.20604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 1528s - loss: 3.2412 - regression_loss: 2.2426 - classification_loss: 0.4633 - masks_loss: 0.5353 - val_loss: 831.2504 - val_regression_loss: 19.5601 - val_classification_loss: 810.5061 - val_masks_loss: 1.1841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 724.20604\n",
      "5175/5175 - 1526s - loss: 3.2397 - regression_loss: 2.2463 - classification_loss: 0.4605 - masks_loss: 0.5329 - val_loss: 886.2467 - val_regression_loss: 38.1441 - val_classification_loss: 847.8000 - val_masks_loss: 0.3033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss did not improve from 724.20604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 1528s - loss: 3.2358 - regression_loss: 2.2438 - classification_loss: 0.4602 - masks_loss: 0.5319 - val_loss: 880.6209 - val_regression_loss: 38.1244 - val_classification_loss: 842.1992 - val_masks_loss: 0.2972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 724.20604\n",
      "5175/5175 - 1526s - loss: 3.2289 - regression_loss: 2.2389 - classification_loss: 0.4594 - masks_loss: 0.5307 - val_loss: 891.2373 - val_regression_loss: 47.7778 - val_classification_loss: 843.3472 - val_masks_loss: 0.1130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss did not improve from 724.20604\n",
      "5175/5175 - 1527s - loss: 3.2294 - regression_loss: 2.2378 - classification_loss: 0.4626 - masks_loss: 0.5290 - val_loss: 850.9794 - val_regression_loss: 42.9402 - val_classification_loss: 807.2904 - val_masks_loss: 0.7491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss did not improve from 724.20604\n",
      "5175/5175 - 1529s - loss: 3.2233 - regression_loss: 2.2352 - classification_loss: 0.4593 - masks_loss: 0.5288 - val_loss: 773.9200 - val_regression_loss: 44.5207 - val_classification_loss: 727.7227 - val_masks_loss: 1.6766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss did not improve from 724.20604\n",
      "5175/5175 - 1528s - loss: 3.2249 - regression_loss: 2.2364 - classification_loss: 0.4600 - masks_loss: 0.5285 - val_loss: 820.3526 - val_regression_loss: 39.0638 - val_classification_loss: 780.6997 - val_masks_loss: 0.5893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_loss did not improve from 724.20604\n",
      "5175/5175 - 1527s - loss: 3.2249 - regression_loss: 2.2367 - classification_loss: 0.4612 - masks_loss: 0.5271 - val_loss: 881.0738 - val_regression_loss: 44.8391 - val_classification_loss: 835.5262 - val_masks_loss: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss improved from 724.20604 to 629.44465, saving model to /data/models/04292020/nuclear_1_0.5_mobilenetv2_retinamask/nuclear_1_0.5_mobilenetv2_retinamask.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 1545s - loss: 3.2237 - regression_loss: 2.2365 - classification_loss: 0.4595 - masks_loss: 0.5277 - val_loss: 629.4447 - val_regression_loss: 34.4480 - val_classification_loss: 593.7697 - val_masks_loss: 1.2270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss did not improve from 629.44465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 1528s - loss: 3.2179 - regression_loss: 2.2335 - classification_loss: 0.4582 - masks_loss: 0.5262 - val_loss: 842.7752 - val_regression_loss: 38.9784 - val_classification_loss: 802.8948 - val_masks_loss: 0.9021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_loss improved from 629.44465 to 476.43792, saving model to /data/models/04292020/nuclear_1_0.5_mobilenetv2_retinamask/nuclear_1_0.5_mobilenetv2_retinamask.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 1553s - loss: 3.2222 - regression_loss: 2.2365 - classification_loss: 0.4593 - masks_loss: 0.5265 - val_loss: 476.4379 - val_regression_loss: 33.6145 - val_classification_loss: 442.6920 - val_masks_loss: 0.1318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_loss did not improve from 476.43792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 1527s - loss: 3.2236 - regression_loss: 2.2365 - classification_loss: 0.4612 - masks_loss: 0.5260 - val_loss: 837.9892 - val_regression_loss: 37.8975 - val_classification_loss: 799.5172 - val_masks_loss: 0.5747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss did not improve from 476.43792\n",
      "5175/5175 - 1528s - loss: 3.2201 - regression_loss: 2.2349 - classification_loss: 0.4587 - masks_loss: 0.5265 - val_loss: 662.0641 - val_regression_loss: 44.2150 - val_classification_loss: 616.7032 - val_masks_loss: 1.1458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss did not improve from 476.43792\n",
      "5175/5175 - 1527s - loss: 3.2168 - regression_loss: 2.2331 - classification_loss: 0.4576 - masks_loss: 0.5261 - val_loss: 684.2254 - val_regression_loss: 37.4592 - val_classification_loss: 646.4680 - val_masks_loss: 0.2985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss did not improve from 476.43792\n",
      "5175/5175 - 1526s - loss: 3.2167 - regression_loss: 2.2329 - classification_loss: 0.4574 - masks_loss: 0.5264 - val_loss: 772.8767 - val_regression_loss: 33.8908 - val_classification_loss: 738.6722 - val_masks_loss: 0.3140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepcell/metrics.py:114: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = intersection.sum() / truth.sum()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepcell/metrics.py:115: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  Fmeasure = (2 * precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 47124\n",
      "Number of predicted cells:\t 44640\n",
      "\n",
      "Correct detections:  134\tRecall: 0.2843561667091079048219626201898790895938873291015625%\n",
      "Incorrect detections: 44506\tPrecision: 0.300179211469534024114835801810841076076030731201171875%\n",
      "\n",
      "Gained detections: 35908\tPerc Error: 51.7600253697350609627392259426414966583251953125%\n",
      "Missed detections: 27403\tPerc Error: 39.50038919479920451749421772547066211700439453125%\n",
      "Merges: 3870\t\tPerc Error: 5.5784587885951513186455485993064939975738525390625%\n",
      "Splits: 1215\t\tPerc Error: 1.7513765964194079050031405131448991596698760986328125%\n",
      "Catastrophes: 978\t\tPerc Error: 1.409750050451177738608521394780836999416351318359375%\n",
      "\n",
      "Gained detections from splits: 1235\n",
      "Missed detections from merges: 10269\n",
      "True detections involved in catastrophes: 4115\n",
      "Predicted detections involved in catastrophes: 2239 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.149939971549805262096555225070915184915065765380859375 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:158: UserWarning: Only one label was provided to `remove_small_objects`. Did you mean to use a boolean array?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 39608\n",
      "Number of predicted cells:\t 22320\n",
      "\n",
      "Correct detections:  134\tRecall: 0.338315491819834390785359801157028414309024810791015625%\n",
      "Incorrect detections: 22186\tPrecision: 0.60035842293906804822967160362168215215206146240234375%\n",
      "\n",
      "Gained detections: 16691\tPerc Error: 39.116475275369111841428093612194061279296875%\n",
      "Missed detections: 21111\tPerc Error: 49.4750410124209025752861634828150272369384765625%\n",
      "Merges: 4268\t\tPerc Error: 10.0023435669088360810974336345680058002471923828125%\n",
      "Splits: 22\t\tPerc Error: 0.0515584719943754377080580297842971049249172210693359375%\n",
      "Catastrophes: 578\t\tPerc Error: 1.3545816733067728154793485373375006020069122314453125%\n",
      "\n",
      "Gained detections from splits: 22\n",
      "Missed detections from merges: 11537\n",
      "True detections involved in catastrophes: 2536\n",
      "Predicted detections involved in catastrophes: 1183 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.1502326169197072402994308504275977611541748046875 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepcell_toolbox import retinamask_postprocess\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed as watershed_postprocess \n",
    "from functools import partial\n",
    "from scipy import ndimage\n",
    "\n",
    "if model_type == 'watershed':\n",
    "    postprocessing_fn = watershed_postprocess\n",
    "elif model_type == 'pixelwise':\n",
    "    def pixelwise(prediction, threshold=.5):\n",
    "        \"\"\"Post-processing for pixelwise transform predictions.\n",
    "        Uses the interior predictions to uniquely label every instance.\n",
    "        Args:\n",
    "            prediction: pixelwise transform prediction\n",
    "            threshold: confidence threshold for interior predictions\n",
    "        Returns:\n",
    "            post-processed data with each cell uniquely annotated\n",
    "        \"\"\"\n",
    "        labeled = []\n",
    "        for b in range(prediction.shape[0]):\n",
    "            pred = prediction[b]\n",
    "            interior = pred[..., 1] > threshold\n",
    "            data = np.expand_dims(interior, axis=-1)\n",
    "            label_image = ndimage.label(data)[0]\n",
    "            labeled.append(label_image)\n",
    "        labeled = np.stack(labeled, axis=0)\n",
    "        return labeled\n",
    "    postprocessing_fn = pixelwise\n",
    "elif model_type == 'retinamask':\n",
    "    postprocessing_fn = partial(retinamask_postprocess, image_shape=(128,128))\n",
    "    \n",
    "model_trainer = ModelTrainer(model,\n",
    "                            model_name,\n",
    "                            model_path,\n",
    "                            train_data,\n",
    "                            val_data,\n",
    "                            benchmarking_data = test_dict,\n",
    "                            postprocessing_fn=postprocessing_fn,\n",
    "                            predict_batch_size=32,\n",
    "                            dataset_metadata=dataset_metadata,\n",
    "                            training_kwargs=training_kwargs)\n",
    "\n",
    "model_trainer.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.060982,
     "end_time": "2020-04-30T04:19:51.974567",
     "exception": false,
     "start_time": "2020-04-30T04:19:51.913585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "papermill": {
   "duration": 26599.4125,
   "end_time": "2020-04-30T04:19:55.540085",
   "environment_variables": {},
   "exception": null,
   "input_path": "/notebooks/papermill/Papermill - Nuclear Accuracy - Proper Split.ipynb",
   "output_path": "/notebooks/04292020/nuclear_1_0.5_mobilenetv2_retinamask_training_notebook.ipynb",
   "parameters": {
    "backbone": "mobilenetv2",
    "batch_size": 4,
    "dataset_fraction": 0.5,
    "date": "04292020",
    "filename": "nuclear_1_0.5_mobilenetv2_retinamask",
    "model_type": "retinamask",
    "n_epochs": 16,
    "train_permutation_seed": 1
   },
   "start_time": "2020-04-29T20:56:36.127585",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}