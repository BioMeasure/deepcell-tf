{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018724,
     "end_time": "2020-04-19T02:21:02.213203",
     "exception": false,
     "start_time": "2020-04-19T02:21:02.194479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# General nuclear segmentation training notebook\n",
    "\n",
    "This notebook trains a model to perform nuclear segmentation of fluorescent microscopy images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014045,
     "end_time": "2020-04-19T02:21:02.242090",
     "exception": false,
     "start_time": "2020-04-19T02:21:02.228045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 1: Import relevant python packages\n",
    "\n",
    "This section imports python packages that are used throughout the notebook and defines parameters that can be used with papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 3.051733,
     "end_time": "2020-04-19T02:21:05.307936",
     "exception": false,
     "start_time": "2020-04-19T02:21:02.256203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.026006,
     "end_time": "2020-04-19T02:21:05.346859",
     "exception": false,
     "start_time": "2020-04-19T02:21:05.320853",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Define parameters that can be set with papermill\n",
    "backbone = 'resnet50'\n",
    "n_epochs = 16\n",
    "date = '04092020'\n",
    "filename = 'general_nuclear_train_large.npz'\n",
    "dataset_name = 'general_nuclear_train_large'\n",
    "dataset_size = 82800\n",
    "dataset_split_seed = 0\n",
    "model_type = 'pixelwise'\n",
    "batch_size = 4 if model_type == 'retinamask' else 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.025417,
     "end_time": "2020-04-19T02:21:05.386483",
     "exception": false,
     "start_time": "2020-04-19T02:21:05.361066",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_epochs = 16\n",
    "batch_size = 16\n",
    "date = \"04182020\"\n",
    "filename = \"nuclear_1_32768_mobilenetv2_watershed\"\n",
    "dataset_split_seed = 1\n",
    "dataset_size = 32768\n",
    "backbone = \"mobilenetv2\"\n",
    "model_type = \"watershed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012384,
     "end_time": "2020-04-19T02:21:05.414372",
     "exception": false,
     "start_time": "2020-04-19T02:21:05.401988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 2: Load training data and create data generators\n",
    "\n",
    "Data generators augment data and feed it into the model training process. Here, we define the generators that will be used to train our segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 25.679143,
     "end_time": "2020-04-19T02:21:31.106221",
     "exception": false,
     "start_time": "2020-04-19T02:21:05.427078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26214, 128, 128, 1) (26214, 128, 128, 1) (6554, 128, 128, 1) (6554, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell import image_generators\n",
    "from deepcell.utils import train_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset based \n",
    "dataset_direc = '/data/training_data/'\n",
    "training_file = 'general_nuclear_train_large.npz'\n",
    "test_file = 'general_nuclear_test_large.npz'\n",
    "\n",
    "# Load training data\n",
    "training_data = np.load(os.path.join(dataset_direc,training_file))\n",
    "X = training_data['X']\n",
    "y = training_data['y']\n",
    "\n",
    "# Shuffle training data\n",
    "index = np.arange(X.shape[0])\n",
    "np.random.seed(dataset_split_seed)\n",
    "index = np.random.permutation(index)\n",
    "index = index[0:dataset_size]\n",
    "X = X[index]\n",
    "y = y[index]\n",
    "\n",
    "# Split training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                random_state=dataset_split_seed, \n",
    "                                                shuffle=False, \n",
    "                                                test_size=0.2)\n",
    "train_dict = {'X':X_train, 'y':y_train}\n",
    "val_dict = {'X':X_val, 'y':y_val}\n",
    "test_dict = np.load(os.path.join(dataset_direc, test_file))\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 224.89562,
     "end_time": "2020-04-19T02:25:16.017057",
     "exception": false,
     "start_time": "2020-04-19T02:21:31.121437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepcell.utils.retinanet_anchor_utils import generate_anchor_params\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# Get anchor settings for RetinaMask models\n",
    "pyramid_levels = ['P3', 'P4']\n",
    "anchor_size_dict = {'P3':16, 'P4':32}\n",
    "anchor_params = generate_anchor_params(pyramid_levels, anchor_size_dict)\n",
    "\n",
    "# Data augmentation parameters\n",
    "generator_kwargs = {}\n",
    "generator_kwargs['rotation_range'] = 180\n",
    "generator_kwargs['shear_range'] = 0\n",
    "generator_kwargs['zoom_range'] = 0.25\n",
    "generator_kwargs['horizontal_flip'] = True\n",
    "generator_kwargs['vertical_flip'] = True\n",
    "\n",
    "generator_val_kwargs = {}\n",
    "generator_val_kwargs['rotation_range'] = 0\n",
    "generator_val_kwargs['shear_range'] = 0\n",
    "generator_val_kwargs['zoom_range'] = 0\n",
    "generator_val_kwargs['horizontal_flip'] = False\n",
    "generator_val_kwargs['vertical_flip'] = False\n",
    "\n",
    "# Minimum number of objects in an image\n",
    "min_objects = 3 if model_type == 'retinamask' else 0\n",
    "\n",
    "# Random seed\n",
    "seed=808\n",
    "\n",
    "if model_type == 'watershed':\n",
    "    datagen = image_generators.SemanticGenerator(**generator_kwargs)\n",
    "    datagen_val = image_generators.SemanticGenerator(**generator_val_kwargs)\n",
    "    \n",
    "    train_data = datagen.flow(\n",
    "        train_dict,\n",
    "        seed=seed,\n",
    "        transforms=['centroid', 'watershed-cont', 'fgbg'],\n",
    "        transforms_kwargs={'watershed-cont': {'erosion_width': 0}},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    val_data = datagen_val.flow(\n",
    "        val_dict,\n",
    "        seed=seed,\n",
    "        transforms=['centroid', 'watershed-cont', 'fgbg'],\n",
    "        transforms_kwargs={'watershed-cont': {'erosion_width': 0}},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "elif model_type == 'pixelwise':\n",
    "    datagen = image_generators.SemanticGenerator(**generator_kwargs)\n",
    "    datagen_val = image_generators.SemanticGenerator(**generator_val_kwargs)\n",
    "    \n",
    "    train_data = datagen.flow(\n",
    "        train_dict,\n",
    "        seed=seed,\n",
    "        transforms=['pixelwise'],\n",
    "        transforms_kwargs={},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    val_data = datagen_val.flow(\n",
    "        val_dict,\n",
    "        seed=seed,\n",
    "        transforms=['pixelwise'],\n",
    "        transforms_kwargs={},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "elif model_type == 'retinamask':\n",
    "    datagen = image_generators.RetinaNetGenerator(**generator_kwargs)\n",
    "    datagen_val = image_generators.RetinaNetGenerator(**generator_val_kwargs)\n",
    "    \n",
    "    train_data = datagen.flow(\n",
    "        train_dict=train_dict,\n",
    "        seed=seed,\n",
    "        transforms=[],\n",
    "        transforms_kwargs={},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size,\n",
    "        anchor_params=anchor_params,\n",
    "        pyramid_levels=pyramid_levels,\n",
    "        include_masks=True)\n",
    "    \n",
    "    val_data = datagen_val.flow(\n",
    "        train_dict=val_dict,\n",
    "        seed=seed,\n",
    "        transforms=[],\n",
    "        transforms_kwargs={},\n",
    "        min_objects=min_objects,\n",
    "        batch_size=batch_size,\n",
    "        anchor_params=anchor_params,\n",
    "        pyramid_levels=pyramid_levels,\n",
    "        include_masks=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020303,
     "end_time": "2020-04-19T02:25:16.058222",
     "exception": false,
     "start_time": "2020-04-19T02:25:16.037919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 3: Define model\n",
    "\n",
    "Here we define a PanopticNet to perform the image segmentation. This model will predict the inner distance and outer distance transform (as done in ), as well as the foreground-background transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 28.325818,
     "end_time": "2020-04-19T02:25:44.404778",
     "exception": false,
     "start_time": "2020-04-19T02:25:16.078960",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0419 02:25:16.133387 139936159074112 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"panopticnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_0 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "norm (ImageNormalization2D)     (None, 128, 128, 1)  0           input_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "location (Location2D)           (None, 128, 128, 2)  0           norm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_location (Concatena (None, 128, 128, 3)  0           norm[0][0]                       \n",
      "                                                                 location[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tensor_product_channels (Conv2D (None, 128, 128, 3)  12          concatenate_location[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 129, 129, 3)  0           tensor_product_channels[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 64, 64, 32)   864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 64, 64, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 64, 64, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 64, 64, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 64, 64, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 64, 64, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 64, 64, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 64, 64, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 64, 64, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 64, 64, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 64, 64, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 65, 65, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 32, 32, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 32, 32, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 32, 32, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 32, 32, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 32, 32, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 32, 32, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 32, 32, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 32, 32, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 32, 32, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 32, 32, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 32, 32, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 32, 32, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 32, 32, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 32, 32, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 32, 32, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 33, 33, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 16, 16, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 16, 16, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 16, 16, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 16, 16, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 16, 16, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 16, 16, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 16, 16, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 16, 16, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 16, 16, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 16, 16, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 16, 16, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 16, 16, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 16, 16, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 16, 16, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 16, 16, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 16, 16, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 16, 16, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 16, 16, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 16, 16, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 17, 17, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 8, 8, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 8, 8, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 8, 8, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 8, 8, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 8, 8, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 8, 8, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 8, 8, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 8, 8, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 8, 8, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 8, 8, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 8, 8, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 8, 8, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 8, 8, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 8, 8, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 8, 8, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 8, 8, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 8, 8, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 8, 8, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 8, 8, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 8, 8, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 8, 8, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 8, 8, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 8, 8, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 8, 8, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 8, 8, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 8, 8, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 8, 8, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 8, 8, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 8, 8, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 8, 8, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 8, 8, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 8, 8, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 8, 8, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 8, 8, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 8, 8, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 8, 8, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 8, 8, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 8, 8, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 8, 8, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 8, 8, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 8, 8, 576)    55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 8, 8, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 8, 8, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 9, 9, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 4, 4, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 4, 4, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 4, 4, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 4, 4, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 4, 4, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 4, 4, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 4, 4, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 4, 4, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 4, 4, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 4, 4, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 4, 4, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 4, 4, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 4, 4, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 4, 4, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 4, 4, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 4, 4, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 4, 4, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 4, 4, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 4, 4, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 4, 4, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 4, 4, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "C5_reduced (Conv2D)             (None, 4, 4, 256)    82176       block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C4_reduced (Conv2D)             (None, 8, 8, 256)    24832       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "P5_upsampled (UpSampling2D)     (None, 8, 8, 256)    0           C5_reduced[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "P4_merged (Add)                 (None, 8, 8, 256)    0           C4_reduced[0][0]                 \n",
      "                                                                 P5_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "C3_reduced (Conv2D)             (None, 16, 16, 256)  8448        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "P4_upsampled (UpSampling2D)     (None, 16, 16, 256)  0           P4_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P3_merged (Add)                 (None, 16, 16, 256)  0           C3_reduced[0][0]                 \n",
      "                                                                 P4_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "P3 (DepthwiseConv2D)            (None, 16, 16, 256)  2560        P3_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_0_semantic_upsample_0 (Con (None, 16, 16, 64)   147520      P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv_0_semantic_upsample_1 (Con (None, 16, 16, 64)   147520      P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv_0_semantic_upsample_2 (Con (None, 16, 16, 64)   147520      P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_0_semantic_upsample_ (None, 32, 32, 64)   0           conv_0_semantic_upsample_0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_0_semantic_upsample_ (None, 32, 32, 64)   0           conv_0_semantic_upsample_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_0_semantic_upsample_ (None, 32, 32, 64)   0           conv_0_semantic_upsample_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_semantic_upsample_0 (Con (None, 32, 32, 64)   36928       upsampling_0_semantic_upsample_0[\n",
      "__________________________________________________________________________________________________\n",
      "conv_1_semantic_upsample_1 (Con (None, 32, 32, 64)   36928       upsampling_0_semantic_upsample_1[\n",
      "__________________________________________________________________________________________________\n",
      "conv_1_semantic_upsample_2 (Con (None, 32, 32, 64)   36928       upsampling_0_semantic_upsample_2[\n",
      "__________________________________________________________________________________________________\n",
      "upsampling_1_semantic_upsample_ (None, 64, 64, 64)   0           conv_1_semantic_upsample_0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_1_semantic_upsample_ (None, 64, 64, 64)   0           conv_1_semantic_upsample_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_1_semantic_upsample_ (None, 64, 64, 64)   0           conv_1_semantic_upsample_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_semantic_upsample_0 (Con (None, 64, 64, 64)   36928       upsampling_1_semantic_upsample_0[\n",
      "__________________________________________________________________________________________________\n",
      "conv_2_semantic_upsample_1 (Con (None, 64, 64, 64)   36928       upsampling_1_semantic_upsample_1[\n",
      "__________________________________________________________________________________________________\n",
      "conv_2_semantic_upsample_2 (Con (None, 64, 64, 64)   36928       upsampling_1_semantic_upsample_2[\n",
      "__________________________________________________________________________________________________\n",
      "upsampling_2_semantic_upsample_ (None, 128, 128, 64) 0           conv_2_semantic_upsample_0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_2_semantic_upsample_ (None, 128, 128, 64) 0           conv_2_semantic_upsample_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_2_semantic_upsample_ (None, 128, 128, 64) 0           conv_2_semantic_upsample_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tensor_product_0_semantic_0 (Co (None, 128, 128, 128 8320        upsampling_2_semantic_upsample_0[\n",
      "__________________________________________________________________________________________________\n",
      "tensor_product_0_semantic_1 (Co (None, 128, 128, 128 8320        upsampling_2_semantic_upsample_1[\n",
      "__________________________________________________________________________________________________\n",
      "tensor_product_0_semantic_2 (Co (None, 128, 128, 128 8320        upsampling_2_semantic_upsample_2[\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_0_semantic_ (None, 128, 128, 128 512         tensor_product_0_semantic_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_0_semantic_ (None, 128, 128, 128 512         tensor_product_0_semantic_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_0_semantic_ (None, 128, 128, 128 512         tensor_product_0_semantic_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "relu_0_semantic_0 (Activation)  (None, 128, 128, 128 0           batch_normalization_0_semantic_0[\n",
      "__________________________________________________________________________________________________\n",
      "relu_0_semantic_1 (Activation)  (None, 128, 128, 128 0           batch_normalization_0_semantic_1[\n",
      "__________________________________________________________________________________________________\n",
      "relu_0_semantic_2 (Activation)  (None, 128, 128, 128 0           batch_normalization_0_semantic_2[\n",
      "__________________________________________________________________________________________________\n",
      "tensor_product_1_semantic_0 (Co (None, 128, 128, 1)  129         relu_0_semantic_0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tensor_product_1_semantic_1 (Co (None, 128, 128, 1)  129         relu_0_semantic_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tensor_product_1_semantic_2 (Co (None, 128, 128, 2)  258         relu_0_semantic_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "semantic_0 (Activation)         (None, 128, 128, 1)  0           tensor_product_1_semantic_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "semantic_1 (Activation)         (None, 128, 128, 1)  0           tensor_product_1_semantic_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "semantic_2 (Softmax)            (None, 128, 128, 2)  0           tensor_product_1_semantic_2[0][0]\n",
      "==================================================================================================\n",
      "Total params: 2,652,432\n",
      "Trainable params: 2,620,112\n",
      "Non-trainable params: 32,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "from deepcell.model_zoo.maskrcnn import RetinaMask\n",
    "from deepcell import losses\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.losses import MSE\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = Adam(lr=1e-4, clipnorm=0.001)\n",
    "    \n",
    "if model_type == 'watershed':\n",
    "    model = PanopticNet(backbone,\n",
    "                       input_shape=train_data.x.shape[1:],\n",
    "                       norm_method='whole_image',\n",
    "                       num_semantic_heads=3,\n",
    "                       num_semantic_classes=[1,1,2],\n",
    "                       location=True,\n",
    "                       include_top=True)\n",
    "\n",
    "    # Define loss\n",
    "    loss_layers = ['semantic_0', 'semantic_1', 'semantic_2']\n",
    "    loss = {}\n",
    "\n",
    "    for layer_name in loss_layers:\n",
    "        n_classes = model.get_layer(layer_name).output_shape[-1]\n",
    "        if n_classes > 1:\n",
    "            def loss_function(y_true, y_pred):\n",
    "                return 0.01 * losses.weighted_categorical_crossentropy(\n",
    "                    y_true, y_pred, n_classes=n_classes)\n",
    "            loss[layer_name] = loss_function\n",
    "        elif n_classes == 1:\n",
    "            loss[layer_name] = MSE\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "elif model_type == 'pixelwise':\n",
    "    model = PanopticNet(backbone,\n",
    "                       input_shape=train_data.x.shape[1:],\n",
    "                       norm_method='whole_image',\n",
    "                       num_semantic_heads=1,\n",
    "                       num_semantic_classes=[3],\n",
    "                       location=False,\n",
    "                       include_top=True)\n",
    "\n",
    "    # Define loss\n",
    "    loss = {}\n",
    "    \n",
    "    def loss_function(y_true, y_pred):\n",
    "        return losses.weighted_categorical_crossentropy(\n",
    "                    y_true, y_pred, n_classes=3)\n",
    "    \n",
    "    loss['semantic_0'] = loss_function\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "elif model_type == 'retinamask':\n",
    "    model = RetinaMask(backbone,\n",
    "                      num_classes=1,\n",
    "                      input_shape=train_data.x.shape[1:],\n",
    "                      norm_method='whole_image',\n",
    "                      use_imagenet=True,\n",
    "                      pyramid_levels=pyramid_levels,\n",
    "                      anchor_params=anchor_params)\n",
    "    \n",
    "    # Define loss\n",
    "    retinanet_losses = losses.RetinaNetLosses()\n",
    "    loss = {\n",
    "        'regression': retinanet_losses.regress_loss,\n",
    "        'classification': retinanet_losses.classification_loss,\n",
    "        'masks': retinanet_losses.mask_loss\n",
    "    }\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017408,
     "end_time": "2020-04-19T02:25:44.442948",
     "exception": false,
     "start_time": "2020-04-19T02:25:44.425540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 4: Define model training parameters\n",
    "\n",
    "Here, we define all of the parameters needed for training. The model trainer objects will record these metadata after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.03588,
     "end_time": "2020-04-19T02:25:44.496098",
     "exception": false,
     "start_time": "2020-04-19T02:25:44.460218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'nuclear_{}_{}_{}_{}'.format(str(dataset_split_seed), dataset_size, backbone, model_type)\n",
    "model_path = os.path.join('/data', 'models', date, model_name)\n",
    "dataset_metadata={'name': dataset_name,\n",
    "                  'other': 'Pooled nuclear data from HEK293, HeLa-S3, NIH-3T3, and RAW264.7 cells.'}\n",
    "training_kwargs = {}\n",
    "training_kwargs['batch_size'] = batch_size\n",
    "training_kwargs['lr'] = 1e-5 if model_type=='retinamask' else 1e-4\n",
    "training_kwargs['lr_decay'] = 0.95\n",
    "training_kwargs['training_seed'] = 0\n",
    "training_kwargs['n_epochs'] = n_epochs\n",
    "training_kwargs['training_steps_per_epoch'] = 82800//16 if model_type == 'retinamask' else 82800 // training_kwargs['batch_size']\n",
    "training_kwargs['validation_steps_per_epoch'] = val_data.y.shape[0] // training_kwargs['batch_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017114,
     "end_time": "2020-04-19T02:25:44.533304",
     "exception": false,
     "start_time": "2020-04-19T02:25:44.516190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 5: Create the model trainer and train the model\n",
    "\n",
    "Here, we create the model trainer, train the model, and export the model - along with the metadata and benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 14689.902778,
     "end_time": "2020-04-19T06:30:34.453494",
     "exception": false,
     "start_time": "2020-04-19T02:25:44.550716",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0419 02:25:49.824963 139936159074112 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0419 02:26:13.138062 139936159074112 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (0.192182). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00489, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 921s - loss: 0.0077 - semantic_0_loss: 0.0025 - semantic_1_loss: 0.0044 - semantic_2_loss: 8.0620e-04 - val_loss: 0.0049 - val_semantic_0_loss: 0.0017 - val_semantic_1_loss: 0.0025 - val_semantic_2_loss: 6.4036e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from 0.00489 to 0.00464, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 865s - loss: 0.0050 - semantic_0_loss: 0.0014 - semantic_1_loss: 0.0029 - semantic_2_loss: 6.9326e-04 - val_loss: 0.0046 - val_semantic_0_loss: 0.0016 - val_semantic_1_loss: 0.0024 - val_semantic_2_loss: 5.9889e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 0.00464 to 0.00459, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 866s - loss: 0.0047 - semantic_0_loss: 0.0013 - semantic_1_loss: 0.0028 - semantic_2_loss: 6.7095e-04 - val_loss: 0.0046 - val_semantic_0_loss: 0.0017 - val_semantic_1_loss: 0.0023 - val_semantic_2_loss: 6.1460e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss improved from 0.00459 to 0.00442, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 862s - loss: 0.0045 - semantic_0_loss: 0.0012 - semantic_1_loss: 0.0027 - semantic_2_loss: 6.5609e-04 - val_loss: 0.0044 - val_semantic_0_loss: 0.0015 - val_semantic_1_loss: 0.0023 - val_semantic_2_loss: 6.0800e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss improved from 0.00442 to 0.00442, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 850s - loss: 0.0044 - semantic_0_loss: 0.0012 - semantic_1_loss: 0.0026 - semantic_2_loss: 6.4587e-04 - val_loss: 0.0044 - val_semantic_0_loss: 0.0016 - val_semantic_1_loss: 0.0023 - val_semantic_2_loss: 5.9318e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss improved from 0.00442 to 0.00428, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 860s - loss: 0.0043 - semantic_0_loss: 0.0011 - semantic_1_loss: 0.0025 - semantic_2_loss: 6.3825e-04 - val_loss: 0.0043 - val_semantic_0_loss: 0.0015 - val_semantic_1_loss: 0.0022 - val_semantic_2_loss: 5.8290e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00428\n",
      "5175/5175 - 863s - loss: 0.0042 - semantic_0_loss: 0.0011 - semantic_1_loss: 0.0025 - semantic_2_loss: 6.2973e-04 - val_loss: 0.0043 - val_semantic_0_loss: 0.0015 - val_semantic_1_loss: 0.0022 - val_semantic_2_loss: 5.6955e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss improved from 0.00428 to 0.00424, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 865s - loss: 0.0041 - semantic_0_loss: 0.0011 - semantic_1_loss: 0.0024 - semantic_2_loss: 6.2225e-04 - val_loss: 0.0042 - val_semantic_0_loss: 0.0015 - val_semantic_1_loss: 0.0022 - val_semantic_2_loss: 5.8140e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_loss improved from 0.00424 to 0.00409, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 865s - loss: 0.0041 - semantic_0_loss: 0.0011 - semantic_1_loss: 0.0024 - semantic_2_loss: 6.1811e-04 - val_loss: 0.0041 - val_semantic_0_loss: 0.0014 - val_semantic_1_loss: 0.0021 - val_semantic_2_loss: 5.7145e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00409\n",
      "5175/5175 - 863s - loss: 0.0040 - semantic_0_loss: 0.0010 - semantic_1_loss: 0.0024 - semantic_2_loss: 6.1168e-04 - val_loss: 0.0042 - val_semantic_0_loss: 0.0014 - val_semantic_1_loss: 0.0021 - val_semantic_2_loss: 5.7741e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00409\n",
      "5175/5175 - 865s - loss: 0.0040 - semantic_0_loss: 0.0010 - semantic_1_loss: 0.0023 - semantic_2_loss: 6.0887e-04 - val_loss: 0.0041 - val_semantic_0_loss: 0.0014 - val_semantic_1_loss: 0.0021 - val_semantic_2_loss: 5.7273e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_loss improved from 0.00409 to 0.00396, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 865s - loss: 0.0039 - semantic_0_loss: 0.0010 - semantic_1_loss: 0.0023 - semantic_2_loss: 6.0348e-04 - val_loss: 0.0040 - val_semantic_0_loss: 0.0013 - val_semantic_1_loss: 0.0021 - val_semantic_2_loss: 5.6836e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00396\n",
      "5175/5175 - 864s - loss: 0.0039 - semantic_0_loss: 9.9166e-04 - semantic_1_loss: 0.0023 - semantic_2_loss: 5.9871e-04 - val_loss: 0.0041 - val_semantic_0_loss: 0.0014 - val_semantic_1_loss: 0.0021 - val_semantic_2_loss: 5.6785e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss improved from 0.00396 to 0.00386, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 851s - loss: 0.0038 - semantic_0_loss: 9.8575e-04 - semantic_1_loss: 0.0023 - semantic_2_loss: 5.9713e-04 - val_loss: 0.0039 - val_semantic_0_loss: 0.0013 - val_semantic_1_loss: 0.0020 - val_semantic_2_loss: 5.4904e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00386\n",
      "5175/5175 - 854s - loss: 0.0038 - semantic_0_loss: 9.7444e-04 - semantic_1_loss: 0.0022 - semantic_2_loss: 5.9263e-04 - val_loss: 0.0039 - val_semantic_0_loss: 0.0014 - val_semantic_1_loss: 0.0020 - val_semantic_2_loss: 5.4341e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss improved from 0.00386 to 0.00383, saving model to /data/models/04182020/nuclear_1_32768_mobilenetv2_watershed/nuclear_1_32768_mobilenetv2_watershed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5175 - 856s - loss: 0.0038 - semantic_0_loss: 9.7314e-04 - semantic_1_loss: 0.0022 - semantic_2_loss: 5.9082e-04 - val_loss: 0.0038 - val_semantic_0_loss: 0.0013 - val_semantic_1_loss: 0.0020 - val_semantic_2_loss: 5.3729e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepcell/metrics.py:112: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  dice = (2 * intersection.sum() / (pred.sum() + truth.sum()))\n",
      "/usr/local/lib/python3.6/dist-packages/deepcell/metrics.py:113: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  jaccard = intersection.sum() / union.sum()\n",
      "/usr/local/lib/python3.6/dist-packages/deepcell/metrics.py:114: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = intersection.sum() / pred.sum()\n",
      "/usr/local/lib/python3.6/dist-packages/deepcell/metrics.py:115: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = intersection.sum() / truth.sum()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepcell/metrics.py:116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  Fmeasure = (2 * precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 150490\n",
      "Number of predicted cells:\t 149219\n",
      "\n",
      "Correct detections:  136851\tRecall: 90.936939331517038453966961242258548736572265625%\n",
      "Incorrect detections: 12368\tPrecision: 91.7115112686722255830318317748606204986572265625%\n",
      "\n",
      "Gained detections: 11448\tPerc Error: 46.76661628334490927727529196999967098236083984375%\n",
      "Missed detections: 12307\tPerc Error: 50.27574655827444161104722297750413417816162109375%\n",
      "Merges: 534\t\tPerc Error: 2.181461661015564157395374422776512801647186279296875%\n",
      "Splits: 138\t\tPerc Error: 0.56374851913885370979784283917979337275028228759765625%\n",
      "Catastrophes: 52\t\tPerc Error: 0.212426978226234741686795359782990999519824981689453125%\n",
      "\n",
      "Gained detections from splits: 142\n",
      "Missed detections from merges: 538\n",
      "True detections involved in catastrophes: 122\n",
      "Predicted detections involved in catastrophes: 106 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.85795009867071991838116673534386791288852691650390625 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepcell/model_trainer.py:184: UserWarning: Only one label was provided to `remove_small_objects`. Did you mean to use a boolean array?\n",
      "  y_pred[i] = remove_small_objects(y_pred[i].astype(int), min_size=self.min_size)\n",
      "/usr/local/lib/python3.6/dist-packages/deepcell/model_trainer.py:185: UserWarning: Only one label was provided to `remove_small_objects`. Did you mean to use a boolean array?\n",
      "  y_true[i] = remove_small_objects(y_true[i].astype(int), min_size=self.min_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 127382\n",
      "Number of predicted cells:\t 127908\n",
      "\n",
      "Correct detections:  122736\tRecall: 96.3527028936584457596836728043854236602783203125%\n",
      "Incorrect detections: 5172\tPrecision: 95.9564687118866714854448218829929828643798828125%\n",
      "\n",
      "Gained detections: 4544\tPerc Error: 51.91956124314442178047102061100304126739501953125%\n",
      "Missed detections: 3704\tPerc Error: 42.32175502742230577268855995498597621917724609375%\n",
      "Merges: 386\t\tPerc Error: 4.41042047531992675857281938078813254833221435546875%\n",
      "Splits: 79\t\tPerc Error: 0.90265082266910423580696942735812626779079437255859375%\n",
      "Catastrophes: 39\t\tPerc Error: 0.445612431444241341438328163349069654941558837890625%\n",
      "\n",
      "Gained detections from splits: 83\n",
      "Missed detections from merges: 390\n",
      "True detections involved in catastrophes: 87\n",
      "Predicted detections involved in catastrophes: 80 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.86381922186924897655302402199595235288143157958984375 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepcell.model_trainer import ModelTrainer\n",
    "from deepcell_toolbox import retinamask_postprocess\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed as watershed_postprocess \n",
    "from functools import partial\n",
    "from scipy import ndimage\n",
    "\n",
    "if model_type == 'watershed':\n",
    "    postprocessing_fn = watershed_postprocess\n",
    "elif model_type == 'pixelwise':\n",
    "    def pixelwise(prediction, threshold=.75):\n",
    "        \"\"\"Post-processing for pixelwise transform predictions.\n",
    "        Uses the interior predictions to uniquely label every instance.\n",
    "        Args:\n",
    "            prediction: pixelwise transform prediction\n",
    "            threshold: confidence threshold for interior predictions\n",
    "        Returns:\n",
    "            post-processed data with each cell uniquely annotated\n",
    "        \"\"\"\n",
    "        labeled = []\n",
    "        for b in range(prediction.shape[0]):\n",
    "            pred = prediction[b]\n",
    "            interior = pred[..., 1] > threshold\n",
    "            data = np.expand_dims(interior, axis=-1)\n",
    "            label_image = ndimage.label(data)[0]\n",
    "            labeled.append(label_image)\n",
    "        labeled = np.stack(labeled, axis=0)\n",
    "        return labeled\n",
    "    postprocessing_fn = pixelwise\n",
    "elif model_type == 'retinamask':\n",
    "    postprocessing_fn = partial(retinamask_postprocess, image_shape=(128,128))\n",
    "    \n",
    "model_trainer = ModelTrainer(model,\n",
    "                            model_name,\n",
    "                            model_path,\n",
    "                            train_data,\n",
    "                            val_data,\n",
    "                            benchmarking_data = test_dict,\n",
    "                            postprocessing_fn=postprocessing_fn,\n",
    "                            predict_batch_size=32,\n",
    "                            dataset_metadata=dataset_metadata,\n",
    "                            training_kwargs=training_kwargs)\n",
    "\n",
    "model_trainer.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.044029,
     "end_time": "2020-04-19T06:30:34.543687",
     "exception": false,
     "start_time": "2020-04-19T06:30:34.499658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "papermill": {
   "duration": 14976.817961,
   "end_time": "2020-04-19T06:30:38.003072",
   "environment_variables": {},
   "exception": null,
   "input_path": "/notebooks/papermill/Papermill - Nuclear Accuracy.ipynb",
   "output_path": "/notebooks/04182020/nuclear_1_32768_mobilenetv2_watershed_training_notebook.ipynb",
   "parameters": {
    "backbone": "mobilenetv2",
    "batch_size": 16,
    "dataset_size": 32768,
    "dataset_split_seed": 1,
    "date": "04182020",
    "filename": "nuclear_1_32768_mobilenetv2_watershed",
    "model_type": "watershed",
    "n_epochs": 16
   },
   "start_time": "2020-04-19T02:21:01.185111",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}