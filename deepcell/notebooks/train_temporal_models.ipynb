{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "\n",
    "import deepcell\n",
    "from deepcell import model_zoo\n",
    "from deepcell import losses\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from deepcell.utils.tracking_utils import save_trks\n",
    "from deepcell.utils.retinanet_anchor_utils import get_anchor_parameters\n",
    "from deepcell.callbacks import RedirectModel, Evaluate\n",
    "from deepcell.image_generators import RetinaMovieDataGenerator, RetinaNetGenerator\n",
    "# from deepcell.model_zoo import shapemask_box\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "From `shape_mask` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                model_dir=None,\n",
    "                model_name=None,\n",
    "                train_dict=None,\n",
    "                test_dict=None,\n",
    "                batch_size=1,\n",
    "                num_classes=1,\n",
    "                fpb=1,\n",
    "                backbone_levels=None,\n",
    "                pyramid_levels=None,\n",
    "                anchor_params=None,\n",
    "                n_epoch=16,\n",
    "                optimizer=Adam(lr=1e-5, clipnorm=0.001),\n",
    "                lr_sched = rate_scheduler(lr=1e-5, decay=0.99)\n",
    "                ):\n",
    "    \n",
    "    if fpb == 1:\n",
    "        datagen = RetinaNetGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaNetGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "    \n",
    "    else:\n",
    "        datagen = RetinaMovieDataGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaMovieDataGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "    retinanet_losses = losses.RetinaNetLosses(\n",
    "        sigma=3.0,\n",
    "        alpha=0.25,\n",
    "        gamma=2.0,\n",
    "        iou_threshold=0.5,\n",
    "        mask_size=(28,28))\n",
    "\n",
    "    loss = {\n",
    "        'regression': retinanet_losses.regress_loss,\n",
    "        'classification': retinanet_losses.classification_loss,\n",
    "        'masks': retinanet_losses.mask_loss,\n",
    "        'final_detection': retinanet_losses.final_detection_loss\n",
    "        }\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    iou_threshold = 0.5\n",
    "    score_threshold = 0.01\n",
    "    max_detections = 100\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_data,\n",
    "        steps_per_epoch=X_train.shape[0] * X_train.shape[1]// batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=X_test.shape[0] * X_test.shape[1]// batch_size,\n",
    "        callbacks=[\n",
    "            callbacks.LearningRateScheduler(lr_sched),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                os.path.join(model_dir, model_name + '.h5'),\n",
    "                monitor='val_loss',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False),\n",
    "            RedirectModel(\n",
    "                Evaluate(val_data,\n",
    "                         iou_threshold=iou_threshold,\n",
    "                         score_threshold=score_threshold,\n",
    "                         max_detections=max_detections,\n",
    "                         frames_per_batch=fpb,\n",
    "                         weighted_average=True),\n",
    "                prediction_model)\n",
    "        ])\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_datasets()\n",
    "\n",
    "DATA_DIR = '/data/training_data/tracking_benchmark_data'\n",
    "\n",
    "backbones = ['featurenet'] #, 'mobilenetv2', 'resnet50']\n",
    "fpbs = [5, 3, 1]\n",
    "all_data = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "datasets = [all_data]\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "\n",
    "n_epoch = 4\n",
    "seed = 808\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    num_classes=1\n",
    "    test_size = 0.1 # % of data saved as test\n",
    "    test_seed = 10\n",
    "\n",
    "    filename = os.path.join(DATA_DIR, dataset)\n",
    "    train_dict, test_dict = get_data(filename, seed=seed, test_size=test_size)\n",
    "    print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "    X_train, y_train = train_dict['X'], train_dict['y']\n",
    "    X_test, y_test = test_dict['X'], test_dict['y']\n",
    "    y_train_reshaped = y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4]))\n",
    "    print(\"y_train_reshaped shape:\", y_train_reshaped.shape)\n",
    "    optimal_params = get_anchor_parameters(y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4])))\n",
    "    backbone_levels, pyramid_levels, anchor_params = optimal_params\n",
    "    norm_method='whole_image'\n",
    "    print(\"optimal_params: \", optimal_params)\n",
    "\n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "            use_imagenet=False\n",
    "        else:\n",
    "            use_imagenet=True\n",
    "\n",
    "        for fpb in fpbs:\n",
    "            if fpb == 1:\n",
    "                train_dict = {'X':X_train.reshape((-1,X_train.shape[2], X_train.shape[3], X_train.shape[4])), \n",
    "                              'y': y_train.reshape((-1,y_train.shape[2], y_train.shape[3], y_train.shape[4]))}\n",
    "                test_dict = {'X':X_test.reshape((-1, X_test.shape[2], X_test.shape[3], X_test.shape[4])), \n",
    "                            'y': y_test.reshape((-1, y_test.shape[2], y_test.shape[3], y_test.shape[4]))}\n",
    "            else:\n",
    "                train_dict = {'X':X_train, 'y':y_train}\n",
    "                test_dict = {'X':X_test, 'y':y_test}\n",
    "            print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "\n",
    "\n",
    "            for temporal_mode in temporal_modes:\n",
    "                model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=X_train.shape[2:],\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "                prediction_model = model\n",
    "\n",
    "                model_dir = '/data/models'\n",
    "                model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + dataset\n",
    "\n",
    "                # Train model\n",
    "                print(\"Training model: \", model_name)\n",
    "                trained_model = train_model(model,\n",
    "                            model_dir=model_dir,\n",
    "                            model_name=model_name,\n",
    "                            train_dict=train_dict,\n",
    "                            test_dict=test_dict,\n",
    "                            fpb=fpb,\n",
    "                            backbone_levels=backbone_levels,\n",
    "                            pyramid_levels=pyramid_levels,\n",
    "                            anchor_params=anchor_params,\n",
    "                            n_epoch=n_epoch,\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data to load (raw images from trk test files)\n",
    "RAW_BASE_DIR = '/data/training_data/tracking_benchmark_data/test'\n",
    "\n",
    "raw_trks_3T3  = os.path.join(RAW_BASE_DIR, '3T3_NIH_test_BData.trks')\n",
    "raw_trks_HEK  = os.path.join(RAW_BASE_DIR, 'HEK293_generic_test_BData.trks')\n",
    "raw_trks_HeLa = os.path.join(RAW_BASE_DIR, 'HeLa_S3_test_BData.trks')\n",
    "raw_trks_RAW  = os.path.join(RAW_BASE_DIR, 'RAW264_generic_test_BData.trks')\n",
    "\n",
    "# raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa]\n",
    "raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa, raw_trks_RAW]\n",
    "\n",
    "model_dir = '/data/models'\n",
    "\n",
    "DATA_DIR = '/data/training_data/tracking_benchmark_data'\n",
    "dataset = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "filename = os.path.join(DATA_DIR, dataset)\n",
    "test_size = 0.1 # % of data saved as test\n",
    "seed = 808\n",
    "train_dict, test_dict = get_data(filename, seed=seed, test_size=test_size)\n",
    "X_train, y_train = train_dict['X'], train_dict['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  /data/training_data/tracking_benchmark_data/test/3T3_NIH_test_BData.trks\n",
      "frames per batch:  5\n",
      "featurenet_fpb5_conv\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "batch_num:  13\n",
      "batch_num:  14\n",
      "batch_num:  15\n",
      "batch_num:  16\n",
      "batch_num:  17\n",
      "batch_num:  18\n",
      "batch_num:  19\n",
      "batch_num:  20\n",
      "batch_num:  21\n",
      "batch_num:  22\n",
      "batch_num:  23\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               9.0  1.000000\n",
      "1               6.0  1.000000\n",
      "2               9.0  0.988889\n",
      "3              12.0  0.944205\n",
      "4               6.0  1.000000\n",
      "5               6.0  1.000000\n",
      "6               7.0  1.000000\n",
      "7               9.0  1.000000\n",
      "8              10.0  1.000000\n",
      "9              11.0  0.975758\n",
      "10             10.0  1.000000\n",
      "11              9.0  0.864198\n",
      "12             12.0  1.000000\n",
      "13             13.0  0.961767\n",
      "14              6.0  1.000000\n",
      "15              7.0  1.000000\n",
      "16             11.0  1.000000\n",
      "17              7.0  1.000000\n",
      "18             15.0  1.000000\n",
      "19              7.0  0.968254\n",
      "20             13.0  0.966555\n",
      "21              7.0  0.982143\n",
      "22              8.0  0.882177\n",
      "23             11.0  0.952763\n",
      "total_instances 221.0\n",
      "mAP 0.9786128475753446\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb5_gru\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "batch_num:  13\n",
      "batch_num:  14\n",
      "batch_num:  15\n",
      "batch_num:  16\n",
      "batch_num:  17\n",
      "batch_num:  18\n",
      "batch_num:  19\n",
      "batch_num:  20\n",
      "batch_num:  21\n",
      "batch_num:  22\n",
      "batch_num:  23\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               9.0  1.000000\n",
      "1               6.0  1.000000\n",
      "2               9.0  0.979798\n",
      "3              12.0  0.976389\n",
      "4               6.0  1.000000\n",
      "5               6.0  1.000000\n",
      "6               7.0  1.000000\n",
      "7               9.0  1.000000\n",
      "8              10.0  1.000000\n",
      "9              11.0  0.986014\n",
      "10             10.0  1.000000\n",
      "11              9.0  0.839506\n",
      "12             12.0  1.000000\n",
      "13             13.0  0.983826\n",
      "14              6.0  1.000000\n",
      "15              7.0  0.957143\n",
      "16             11.0  1.000000\n",
      "17              7.0  1.000000\n",
      "18             15.0  1.000000\n",
      "19              7.0  0.927438\n",
      "20             13.0  0.981900\n",
      "21              7.0  0.982143\n",
      "22              8.0  0.914423\n",
      "23             11.0  0.932850\n",
      "total_instances 221.0\n",
      "mAP 0.9775595769324671\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb5_lstm\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "batch_num:  13\n",
      "batch_num:  14\n",
      "batch_num:  15\n",
      "batch_num:  16\n",
      "batch_num:  17\n",
      "batch_num:  18\n",
      "batch_num:  19\n",
      "batch_num:  20\n",
      "batch_num:  21\n",
      "batch_num:  22\n",
      "batch_num:  23\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               9.0  1.000000\n",
      "1               6.0  1.000000\n",
      "2               9.0  1.000000\n",
      "3              12.0  0.937943\n",
      "4               6.0  1.000000\n",
      "5               6.0  1.000000\n",
      "6               7.0  1.000000\n",
      "7               9.0  1.000000\n",
      "8              10.0  1.000000\n",
      "9              11.0  0.975758\n",
      "10             10.0  1.000000\n",
      "11              9.0  0.891852\n",
      "12             12.0  1.000000\n",
      "13             13.0  0.994505\n",
      "14              6.0  1.000000\n",
      "15              7.0  0.982143\n",
      "16             11.0  1.000000\n",
      "17              7.0  1.000000\n",
      "18             15.0  1.000000\n",
      "19              7.0  0.968254\n",
      "20             13.0  0.945804\n",
      "21              7.0  0.982143\n",
      "22              8.0  0.875219\n",
      "23             11.0  0.938672\n",
      "total_instances 221.0\n",
      "mAP 0.97884554304213\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb5_None\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "batch_num:  13\n",
      "batch_num:  14\n",
      "batch_num:  15\n",
      "batch_num:  16\n",
      "batch_num:  17\n",
      "batch_num:  18\n",
      "batch_num:  19\n",
      "batch_num:  20\n",
      "batch_num:  21\n",
      "batch_num:  22\n",
      "batch_num:  23\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               9.0  1.000000\n",
      "1               6.0  1.000000\n",
      "2               9.0  1.000000\n",
      "3              12.0  0.909722\n",
      "4               6.0  1.000000\n",
      "5               6.0  1.000000\n",
      "6               7.0  0.895604\n",
      "7               9.0  1.000000\n",
      "8              10.0  1.000000\n",
      "9              11.0  0.986014\n",
      "10             10.0  1.000000\n",
      "11              9.0  0.916429\n",
      "12             12.0  1.000000\n",
      "13             13.0  1.000000\n",
      "14              6.0  1.000000\n",
      "15              7.0  0.982143\n",
      "16             11.0  1.000000\n",
      "17              7.0  1.000000\n",
      "18             15.0  1.000000\n",
      "19              7.0  0.946429\n",
      "20             13.0  0.950104\n",
      "21              7.0  0.982143\n",
      "22              8.0  0.864583\n",
      "23             11.0  0.956382\n",
      "total_instances 221.0\n",
      "mAP 0.9745647260246377\n",
      "\n",
      "\n",
      "\n",
      "frames per batch:  3\n",
      "featurenet_fpb3_conv\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "batch_num:  13\n",
      "batch_num:  14\n",
      "batch_num:  15\n",
      "batch_num:  16\n",
      "batch_num:  17\n",
      "batch_num:  18\n",
      "batch_num:  19\n",
      "batch_num:  20\n",
      "batch_num:  21\n",
      "batch_num:  22\n",
      "batch_num:  23\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               9.0  1.000000\n",
      "1               6.0  1.000000\n",
      "2               9.0  0.988889\n",
      "3              12.0  0.916667\n",
      "4               6.0  1.000000\n",
      "5               6.0  1.000000\n",
      "6               7.0  1.000000\n",
      "7               9.0  1.000000\n",
      "8              10.0  0.990909\n",
      "9              11.0  0.933566\n",
      "10             10.0  1.000000\n",
      "11              9.0  0.839506\n",
      "12             12.0  1.000000\n",
      "13             13.0  0.972527\n",
      "14              6.0  1.000000\n",
      "15              7.0  0.982143\n",
      "16             11.0  1.000000\n",
      "17              7.0  1.000000\n",
      "18             15.0  0.995833\n",
      "19              7.0  0.968254\n",
      "20             13.0  0.957560\n",
      "21              7.0  1.000000\n",
      "22              8.0  0.827048\n",
      "23             11.0  0.896897\n",
      "total_instances 221.0\n",
      "mAP 0.9695749664788896\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb3_gru\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "batch_num:  13\n",
      "batch_num:  14\n",
      "batch_num:  15\n",
      "batch_num:  16\n",
      "batch_num:  17\n",
      "batch_num:  18\n",
      "batch_num:  19\n",
      "batch_num:  20\n",
      "batch_num:  21\n",
      "batch_num:  22\n",
      "batch_num:  23\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               9.0  1.000000\n",
      "1               6.0  1.000000\n",
      "2               9.0  1.000000\n",
      "3              12.0  0.972222\n",
      "4               6.0  1.000000\n",
      "5               6.0  1.000000\n",
      "6               7.0  0.964286\n",
      "7               9.0  1.000000\n",
      "8              10.0  1.000000\n",
      "9              11.0  0.865909\n",
      "10             10.0  1.000000\n",
      "11              9.0  0.851852\n",
      "12             12.0  1.000000\n",
      "13             13.0  0.977909\n",
      "14              6.0  0.958333\n",
      "15              7.0  1.000000\n",
      "16             11.0  1.000000\n",
      "17              7.0  1.000000\n",
      "18             15.0  1.000000\n",
      "19              7.0  0.936735\n",
      "20             13.0  0.964744\n",
      "21              7.0  0.982143\n",
      "22              8.0  0.826705\n",
      "23             11.0  0.933333\n",
      "total_instances 221.0\n",
      "mAP 0.9680904375987939\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from deepcell.utils.retinanet_anchor_utils import evaluate\n",
    "\n",
    "from skimage.morphology import remove_small_objects\n",
    "import pandas as pd\n",
    "from deepcell import metrics\n",
    "from skimage.measure import label\n",
    "from skimage import morphology\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "\n",
    "iou_threshold = 0.5\n",
    "score_threshold = 0.01\n",
    "max_detections = 100\n",
    "num_classes=1\n",
    "\n",
    "backbones = ['featurenet'] #, 'mobilenetv2', 'resnet50']\n",
    "fpbs = [5, 3, 1]\n",
    "\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "training_optimal_params = get_anchor_parameters(y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4])))\n",
    "\n",
    "# Go through each Dataset (3T3, HEK293, HeLa, RAW264.7)\n",
    "for set_num, dataset in enumerate(raw_trks_files):\n",
    "    print(\"dataset: \", dataset)\n",
    "    # Load the trk file       \n",
    "    trks = load_trks(dataset)\n",
    "    lineages, raw, tracked = trks['lineages'], trks['X'], trks['y']\n",
    "    norm_method='whole_image'\n",
    "    backbone_levels, pyramid_levels, anchor_params = training_optimal_params\n",
    "    datagen_val = RetinaMovieDataGenerator()\n",
    "    \n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "                use_imagenet=False\n",
    "        else:\n",
    "            use_imagenet=True\n",
    "                \n",
    "        for fpb in fpbs:\n",
    "            print(\"frames per batch: \", fpb)\n",
    "            for temporal_mode in temporal_modes:\n",
    "                prediction_model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=trks['X'].shape[2:],\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "                # print(prediction_model.summary())\n",
    "\n",
    "                model_dir = '/data/models/'\n",
    "                model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "                print(backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode))\n",
    "                prediction_model.load_weights(os.path.join(model_dir, model_name + '.h5'))\n",
    "\n",
    "                Model_DF = pd.DataFrame(columns=['total_instances', 'mAP'])\n",
    "\n",
    "\n",
    "                # Go through each batch (movie) in each dataset\n",
    "                for batch_num, movie in enumerate(trks['X']):\n",
    "                    print(\"batch_num: \", batch_num)\n",
    "                    Lstats = []\n",
    "\n",
    "                    # Predict on the raw data\n",
    "                    X_test_temp = np.expand_dims(movie, axis=0)\n",
    "                    y_test_temp = np.expand_dims(trks['y'][batch_num], axis=0)\n",
    "                    # print(\"X_test_temp.shape\", X_test_temp.shape)\n",
    "                    \n",
    "                    val_data = datagen_val.flow(\n",
    "                                    {'X': X_test_temp, 'y': y_test_temp},\n",
    "                                    batch_size=1,\n",
    "                                    include_masks=True,\n",
    "                                    include_final_detection_layer=True,\n",
    "                                    frames_per_batch=fpb,\n",
    "                                    pyramid_levels=pyramid_levels,\n",
    "                                    anchor_params=anchor_params)\n",
    "                    \n",
    "                    recall, precision, average_precisions = evaluate(\n",
    "                                                                val_data,\n",
    "                                                                prediction_model,\n",
    "                                                                frames_per_batch=fpb,\n",
    "                                                                iou_threshold=iou_threshold,\n",
    "                                                                score_threshold=score_threshold,\n",
    "                                                                max_detections=max_detections,\n",
    "                                                            )\n",
    "                    # print(recall, precision, average_precisions)\n",
    "                    # print(\"Mean recall: \", np.mean(recall))\n",
    "                    # print(\"Mean precision: \", np.mean(precision))\n",
    "                    total_instances = []\n",
    "                    precisions = []\n",
    "\n",
    "                    for label, (average_precision, num_annotations) in average_precisions.items():\n",
    "#                         print('{:.0f} instances of class'.format(num_annotations),\n",
    "#                               label, 'with average precision: {:.4f}'.format(average_precision))\n",
    "                        total_instances.append(num_annotations)\n",
    "                        precisions.append(average_precision)\n",
    "\n",
    "                    if sum(total_instances) == 0:\n",
    "                        pass\n",
    "                        # print('No test instances found.')\n",
    "                    else:\n",
    "#                         print('mAP using the weighted average of precisions among classes: {:.4f}'.format(\n",
    "#                             sum([a * b for a, b in zip(total_instances, precisions)]) / sum(total_instances)))\n",
    "#                         print('mAP: {:.4f}'.format(sum(precisions) / sum(x > 0 for x in total_instances)))\n",
    "                        Model_DF = Model_DF.append({'total_instances': sum(total_instances),\n",
    "                                              'mAP': sum(precisions) / sum(x > 0 for x in total_instances)},\n",
    "                                             ignore_index=True)\n",
    "                print('\\n\\n')\n",
    "                print(Model_DF)\n",
    "                print('total_instances', Model_DF.sum(axis = 0, skipna = True)['total_instances'] )\n",
    "                print('mAP', Model_DF.mean(axis = 0, skipna = True)['mAP'] )\n",
    "                print('\\n\\n')      \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"featurenet_retinanet_mask\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 5, 154, 182, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_56 (TimeDistri (None, 5, 154, 182,  0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistri (None, 5, 154, 182,  6           time_distributed_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistri (None, 5, 39, 46, 32 29152       time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_60 (TimeDistri (None, 5, 20, 23, 32 47904       time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistri (None, 5, 77, 91, 32 10400       time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C2_reduced (Conv3D)             (None, 5, 39, 46, 25 8448        time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C3_reduced (Conv3D)             (None, 5, 20, 23, 25 8448        time_distributed_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C1_reduced (Conv3D)             (None, 5, 77, 91, 25 8448        time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "P2_upsampled (UpsampleLike)     (None, None, None, N 0           C2_reduced[0][0]                 \n",
      "                                                                 time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "P3_upsampled (UpsampleLike)     (None, None, None, N 0           C3_reduced[0][0]                 \n",
      "                                                                 time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "P1_merged (Add)                 (None, 5, 77, 91, 25 0           C1_reduced[0][0]                 \n",
      "                                                                 P2_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "P2_merged (Add)                 (None, 5, 39, 46, 25 0           C2_reduced[0][0]                 \n",
      "                                                                 P3_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "P1 (Conv3D)                     (None, 5, 77, 91, 25 590080      P1_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P2 (Conv3D)                     (None, 5, 39, 46, 25 590080      P2_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P3 (Conv3D)                     (None, 5, 20, 23, 25 590080      C3_reduced[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 5, 77, 91, 25 1769728     P1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 5, 39, 46, 25 1769728     P2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 5, 20, 23, 25 1769728     P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 5, 77, 91, 25 1024        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 5, 39, 46, 25 1024        conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 5, 20, 23, 25 1024        conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "regression_submodel (Model)     (None, 5, None, 4)   7493692     batch_normalization_62[0][0]     \n",
      "                                                                 batch_normalization_63[0][0]     \n",
      "                                                                 batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_67 (TimeDistri (None, 5, 105105, 4) 60          P1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_68 (TimeDistri (None, 5, 26910, 4)  60          P2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_69 (TimeDistri (None, 5, 6900, 4)   60          P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "regression (Concatenate)        (None, 5, None, 4)   0           regression_submodel[1][0]        \n",
      "                                                                 regression_submodel[2][0]        \n",
      "                                                                 regression_submodel[3][0]        \n",
      "__________________________________________________________________________________________________\n",
      "anchors (Concatenate)           (None, 5, 138915, 4) 0           time_distributed_67[0][0]        \n",
      "                                                                 time_distributed_68[0][0]        \n",
      "                                                                 time_distributed_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "classification_submodel (Model) (None, 5, None, 1)   7182607     batch_normalization_62[0][0]     \n",
      "                                                                 batch_normalization_63[0][0]     \n",
      "                                                                 batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "boxes (RegressBoxes)            (None, 5, 138915, 4) 0           anchors[0][0]                    \n",
      "                                                                 regression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "classification (Concatenate)    (None, 5, None, 1)   0           classification_submodel[1][0]    \n",
      "                                                                 classification_submodel[2][0]    \n",
      "                                                                 classification_submodel[3][0]    \n",
      "__________________________________________________________________________________________________\n",
      "clipped_boxes (ClipBoxes)       (None, 5, 138915, 4) 0           input_25[0][0]                   \n",
      "                                                                 boxes[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "filtered_detections (FilterDete [(None, None, 100, 4 0           clipped_boxes[0][0]              \n",
      "                                                                 classification[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "upsample_like_4 (UpsampleLike)  (None, None, None, N 0           P1[0][0]                         \n",
      "                                                                 input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "roi_align_4 (RoiAlign)          (None, None, None, N 0           filtered_detections[0][0]        \n",
      "                                                                 upsample_like_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_63 (TimeDistri (None, None, None, 2 2950657     roi_align_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_66 (TimeDistri (None, None, None, 1 2950657     roi_align_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "masks (ConcatenateBoxes)        (None, None, 100, No 0           filtered_detections[0][0]        \n",
      "                                                                 time_distributed_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "final_detection (ConcatenateBox (None, None, 100, No 0           filtered_detections[0][0]        \n",
      "                                                                 time_distributed_66[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 27,733,543\n",
      "Trainable params: 27,731,623\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "backbone = 'featurenet'\n",
    "fpbs = 5\n",
    "temporal_mode = 'conv'\n",
    "shape_mask = False\n",
    "\n",
    "prediction_model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=trks['X'].shape[2:],\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "print(prediction_model.summary())\n",
    "\n",
    "model_dir = '/data/models/'\n",
    "model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "prediction_model.load_weights(model_dir + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_25 to have 5 dimensions, but got array with shape (30, 154, 182, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4fb73f0caf00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;31m# generate symbolic tensors).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1060\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    374\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_25 to have 5 dimensions, but got array with shape (30, 154, 182, 1)"
     ]
    }
   ],
   "source": [
    "outputs = prediction_model.predict(X_test_temp[0])\n",
    "final_scores = outputs[-1]\n",
    "selection = np.where(final_scores[0, i] > 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_optimal_params = get_anchor_parameters(y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8. 16. 32.]\n",
      "[2. 4. 8.]\n",
      "[0.25 0.5  1.   2.   4.  ]\n",
      "[1, 1.2599210498948732, 1.5874010519681994]\n"
     ]
    }
   ],
   "source": [
    "print(training_optimal_params[2].sizes)\n",
    "print(training_optimal_params[2].strides)\n",
    "print(training_optimal_params[2].ratios)\n",
    "print(training_optimal_params[2].scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
