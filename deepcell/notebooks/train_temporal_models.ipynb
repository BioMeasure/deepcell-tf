{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "\n",
    "import deepcell\n",
    "from deepcell import model_zoo\n",
    "from deepcell import losses\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from deepcell.utils.tracking_utils import save_trks\n",
    "from deepcell.utils.retinanet_anchor_utils import get_anchor_parameters\n",
    "from deepcell.callbacks import RedirectModel, Evaluate\n",
    "from deepcell.image_generators import RetinaMovieDataGenerator, RetinaNetGenerator\n",
    "# from deepcell.model_zoo import shapemask_box\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "From `shape_mask` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                model_dir=None,\n",
    "                model_name=None,\n",
    "                train_dict=None,\n",
    "                test_dict=None,\n",
    "                batch_size=1,\n",
    "                num_classes=1,\n",
    "                fpb=1,\n",
    "                backbone_levels=None,\n",
    "                pyramid_levels=None,\n",
    "                anchor_params=None,\n",
    "                n_epoch=16,\n",
    "                optimizer=Adam(lr=1e-5, clipnorm=0.001),\n",
    "                lr_sched = rate_scheduler(lr=1e-5, decay=0.99)\n",
    "                ):\n",
    "    \n",
    "    if fpb == 1:\n",
    "        datagen = RetinaNetGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaNetGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "    \n",
    "    else:\n",
    "        datagen = RetinaMovieDataGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaMovieDataGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "    retinanet_losses = losses.RetinaNetLosses(\n",
    "        sigma=3.0,\n",
    "        alpha=0.25,\n",
    "        gamma=2.0,\n",
    "        iou_threshold=0.5,\n",
    "        mask_size=(28,28))\n",
    "\n",
    "    loss = {\n",
    "        'regression': retinanet_losses.regress_loss,\n",
    "        'classification': retinanet_losses.classification_loss,\n",
    "        'masks': retinanet_losses.mask_loss,\n",
    "        'final_detection': retinanet_losses.final_detection_loss\n",
    "        }\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    iou_threshold = 0.5\n",
    "    score_threshold = 0.01\n",
    "    max_detections = 100\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_data,\n",
    "        steps_per_epoch=X_train.shape[0] * X_train.shape[1]// batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=X_test.shape[0] * X_test.shape[1]// batch_size,\n",
    "        callbacks=[\n",
    "            callbacks.LearningRateScheduler(lr_sched),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                os.path.join(model_dir, model_name + '.h5'),\n",
    "                monitor='val_loss',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False),\n",
    "            RedirectModel(\n",
    "                Evaluate(val_data,\n",
    "                         iou_threshold=iou_threshold,\n",
    "                         score_threshold=score_threshold,\n",
    "                         max_detections=max_detections,\n",
    "                         frames_per_batch=fpb,\n",
    "                         weighted_average=True),\n",
    "                prediction_model)\n",
    "        ])\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -\n",
      "X.shape: (722, 30, 135, 160, 1)\n",
      "y.shape: (722, 30, 135, 160, 1)\n",
      "y_train_reshaped shape: (21660, 135, 160, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0110 22:30:00.568224 140563580065600 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_params:  (['C1', 'C2', 'C3'], ['P1', 'P2', 'P3'], <deepcell.utils.retinanet_anchor_utils.AnchorParameters object at 0x7fd778187860>)\n",
      " -\n",
      "X.shape: (722, 30, 135, 160, 1)\n",
      "y.shape: (722, 30, 135, 160, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0110 22:30:04.274227 140563580065600 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0110 22:30:11.921495 140563580065600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0110 22:30:13.010686 140563580065600 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  featurenet_fpb5_conv_3T3_HeLa_HEK_RAW_cropped.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0110 22:30:22.306921 140563580065600 retinanet.py:619] Removing 77 of 722 images with fewer than 3 objects.\n",
      "W0110 22:30:25.065605 140563580065600 retinanet.py:619] Removing 7 of 81 images with fewer than 3 objects.\n",
      "W0110 22:30:25.283152 140563580065600 training_utils.py:1101] Output filtered_detections missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to filtered_detections.\n",
      "W0110 22:30:25.284173 140563580065600 training_utils.py:1101] Output filtered_detections_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to filtered_detections_1.\n",
      "W0110 22:30:25.285067 140563580065600 training_utils.py:1101] Output filtered_detections_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to filtered_detections_2.\n",
      "W0110 22:30:25.285877 140563580065600 training_utils.py:1101] Output time_distributed_7 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to time_distributed_7.\n",
      "W0110 22:30:25.286661 140563580065600 training_utils.py:1101] Output time_distributed_10 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to time_distributed_10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      " 9836/21660 [============>.................] - ETA: 3:00:58 - loss: 2.0360 - regression_loss: 1.1410 - classification_loss: 0.2829 - masks_loss: 0.3185 - final_detection_loss: 0.2936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21659/21660 [============================>.] - ETA: 0s - loss: 1.7052 - regression_loss: 0.9588 - classification_loss: 0.2251 - masks_loss: 0.2964 - final_detection_loss: 0.2250\n",
      "Epoch 00001: val_loss improved from inf to 1.27951, saving model to /data/models/featurenet_fpb5_conv_3T3_HeLa_HEK_RAW_cropped.npz.h5\n",
      "718 instances of class 0 with average precision: 0.9117\n",
      "mAP: 0.9117\n",
      "21660/21660 [==============================] - 20875s 964ms/step - loss: 1.7053 - regression_loss: 0.9588 - classification_loss: 0.2251 - masks_loss: 0.2964 - final_detection_loss: 0.2250 - val_loss: 1.2795 - val_regression_loss: 0.7595 - val_classification_loss: 0.1161 - val_masks_loss: 0.2507 - val_final_detection_loss: 0.1532\n",
      "Epoch 2/4\n",
      " 4289/21660 [====>.........................] - ETA: 4:25:16 - loss: 1.3164 - regression_loss: 0.7413 - classification_loss: 0.1636 - masks_loss: 0.2677 - final_detection_loss: 0.1437"
     ]
    }
   ],
   "source": [
    "# download_datasets()\n",
    "\n",
    "DATA_DIR = '/data/training_data/tracking_benchmark_data'\n",
    "\n",
    "backbones = ['featurenet'] #, 'mobilenetv2', 'resnet50']\n",
    "fpbs = [5, 3, 1]\n",
    "all_data = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "datasets = [all_data]\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "\n",
    "n_epoch = 4\n",
    "seed = 808\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    num_classes=1\n",
    "    test_size = 0.1 # % of data saved as test\n",
    "    test_seed = 10\n",
    "\n",
    "    filename = os.path.join(DATA_DIR, dataset)\n",
    "    train_dict, test_dict = get_data(filename, seed=seed, test_size=test_size)\n",
    "    print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "    X_train, y_train = train_dict['X'], train_dict['y']\n",
    "    X_test, y_test = test_dict['X'], test_dict['y']\n",
    "    y_train_reshaped = y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4]))\n",
    "    print(\"y_train_reshaped shape:\", y_train_reshaped.shape)\n",
    "    optimal_params = get_anchor_parameters(y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4])))\n",
    "    backbone_levels, pyramid_levels, anchor_params = optimal_params\n",
    "    norm_method='whole_image'\n",
    "    print(\"optimal_params: \", optimal_params)\n",
    "\n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "            use_imagenet=False\n",
    "        else:\n",
    "            use_imagenet=True\n",
    "\n",
    "        for fpb in fpbs:\n",
    "            if fpb == 1:\n",
    "                train_dict = {'X':X_train.reshape((-1,X_train.shape[2], X_train.shape[3], X_train.shape[4])), \n",
    "                              'y': y_train.reshape((-1,y_train.shape[2], y_train.shape[3], y_train.shape[4]))}\n",
    "                test_dict = {'X':X_test.reshape((-1, X_test.shape[2], X_test.shape[3], X_test.shape[4])), \n",
    "                            'y': y_test.reshape((-1, y_test.shape[2], y_test.shape[3], y_test.shape[4]))}\n",
    "            else:\n",
    "                train_dict = {'X':X_train, 'y':y_train}\n",
    "                test_dict = {'X':X_test, 'y':y_test}\n",
    "            print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "\n",
    "\n",
    "            for temporal_mode in temporal_modes:\n",
    "                model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=X_train.shape[2:],\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "                prediction_model = model\n",
    "\n",
    "                model_dir = '/data/models'\n",
    "                model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + dataset\n",
    "\n",
    "                # Train model\n",
    "                print(\"Training model: \", model_name)\n",
    "                trained_model = train_model(model,\n",
    "                            model_dir=model_dir,\n",
    "                            model_name=model_name,\n",
    "                            train_dict=train_dict,\n",
    "                            test_dict=test_dict,\n",
    "                            fpb=fpb,\n",
    "                            backbone_levels=backbone_levels,\n",
    "                            pyramid_levels=pyramid_levels,\n",
    "                            anchor_params=anchor_params,\n",
    "                            n_epoch=n_epoch,\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data to load (raw images from trk test files)\n",
    "RAW_BASE_DIR = '/data/training_data/tracking_benchmark_data/test'\n",
    "\n",
    "raw_trks_3T3  = os.path.join(RAW_BASE_DIR, '3T3_NIH_test_BData.trks')\n",
    "raw_trks_HEK  = os.path.join(RAW_BASE_DIR, 'HEK293_generic_test_BData.trks')\n",
    "raw_trks_HeLa = os.path.join(RAW_BASE_DIR, 'HeLa_S3_test_BData.trks')\n",
    "raw_trks_RAW  = os.path.join(RAW_BASE_DIR, 'RAW264_generic_test_BData.trks')\n",
    "\n",
    "# raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa]\n",
    "raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa, raw_trks_RAW]\n",
    "\n",
    "model_dir = '/data/models'\n",
    "model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from skimage.morphology import remove_small_objects\n",
    "import pandas as pd\n",
    "from deepcell import metrics\n",
    "from skimage.measure import label\n",
    "from skimage import morphology\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "backbones = ['featurenet'] #, 'mobilenetv2', 'resnet50']\n",
    "fpbs = [5, 3, 1]\n",
    "all_data = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "datasets = [all_data]\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "\n",
    "n_epoch = 4\n",
    "seed = 808\n",
    "\n",
    "# Go through each Dataset (3T3, HEK293, HeLa, RAW264.7)\n",
    "for set_num, dataset in enumerate(raw_trks_files):\n",
    "    # Load the trk file       \n",
    "    trks = load_trks(dataset)\n",
    "    lineages, raw, tracked = trks['lineages'], trks['X'], trks['y']\n",
    "    optimal_params = get_anchor_parameters(trks['y'].reshape((-1,  trks['X'].shape[2], trks['X'].shape[3], trks['X'].shape[4])))\n",
    "    backbone_levels, pyramid_levels, anchor_params = optimal_params\n",
    "    \n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "                use_imagenet=False\n",
    "        else:\n",
    "            use_imagenet=True\n",
    "                \n",
    "        for fpb in fpbs:\n",
    "            for temporal_mode in temporal_modes:\n",
    "                model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=tuple(trks['X'].shape[2:]),\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "                prediction_model = model\n",
    "\n",
    "                model_dir = '/data/models/'\n",
    "                model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "                prediction_model.load_weights(model_dir + model_name + '.h5')\n",
    "\n",
    "                Lstats_allmovies = []\n",
    "\n",
    "                # Go through each batch (movie) in each dataset\n",
    "                for batch_num, movie in enumerate(trks['X']):\n",
    "                    print(\"batch_num: \", batch_num)\n",
    "                    Lstats = []\n",
    "\n",
    "                    # Predict on the raw data\n",
    "                    X_test_temp = np.expand_dims(movie, axis=0)\n",
    "                    y_test_temp = np.expand_dims(trks['y'][batch_num], axis=0)\n",
    "                    print(\"X_test_temp.shape\", X_test_temp.shape)\n",
    "                    test_images = run_watershed_model.predict(X_test_temp) #[-1]\n",
    "                    test_images_fgbg = run_fgbg_model.predict(X_test_temp) #[-1]\n",
    "                    # \n",
    "                    # Postprocessing\n",
    "                    # Collapse predictions into semantic segmentation mask\n",
    "                    argmax_images = []\n",
    "                    for frame_num, frame in enumerate(test_images):\n",
    "                        max_image = np.argmax(frame, axis=-1)\n",
    "                        argmax_images.append(max_image)\n",
    "                    argmax_images = np.array(argmax_images)\n",
    "                    argmax_images = np.expand_dims(argmax_images, axis=-1)\n",
    "\n",
    "                    # threshold the foreground/background\n",
    "                    # and remove background from watershed transform\n",
    "                    fg_thresh = test_images_fgbg[..., 1] > threshold\n",
    "                    fg_thresh = np.expand_dims(fg_thresh.astype('int16'), axis=-1)\n",
    "                    argmax_images_post_fgbg = argmax_images * fg_thresh\n",
    "                    watershed_images = []\n",
    "\n",
    "                    n_movies = argmax_images_post_fgbg.shape[0]\n",
    "                    n_frames = argmax_images_post_fgbg.shape[1]\n",
    "\n",
    "                    for i in range(n_movies):\n",
    "                        watershed_frames = []\n",
    "                        for j in range(n_frames):\n",
    "                            image = fg_thresh[i,j,...,0]\n",
    "                            semantic = fg_thresh[i,j,...]\n",
    "                            distance = argmax_images_post_fgbg[i,j,...,0]\n",
    "\n",
    "                            markers = label(distance == 3)\n",
    "                            labels = watershed(-distance, markers, mask=image)\n",
    "                            watershed_frames.append(labels)\n",
    "                        watershed_images.append(np.stack(watershed_frames, axis=0))\n",
    "\n",
    "                    watershed_images = np.stack(watershed_images, axis=0)\n",
    "                    watershed_images = np.expand_dims(watershed_images, axis=-1)\n",
    "                    print(\"watershed_images.shape\", watershed_images.shape)\n",
    "                    print(\"y_test_temp.shape\", y_test_temp.shape)\n",
    "\n",
    "                    # Remove small objects from GT for comparison\n",
    "                    small_objects_threshold=100\n",
    "                    for i in range(watershed_images.shape[0]):\n",
    "                        for j in range(watershed_images.shape[1]):\n",
    "                            # Remove small objects from GT for comparison\n",
    "                            GT_image = y_test_temp[i, j, :, :, :]\n",
    "                            watershed_image = watershed_images[i, j, :, :, :]\n",
    "                            GT_image = np.expand_dims(GT_image, axis=0)\n",
    "                            watershed_image = np.expand_dims(watershed_image, axis=0)\n",
    "                            GT_image = morphology.remove_small_objects(GT_image.astype('uint16'), min_size=small_objects_threshold)\n",
    "\n",
    "                            pp_watershed_image = morphology.remove_small_objects(\n",
    "                                                    watershed_image.astype('uint16'), \n",
    "                                                    min_size=small_objects_threshold)\n",
    "\n",
    "                            # Accuracy from metrics package\n",
    "                            filename = CELL_TYPE_NAME[set_num] + BASE_NAME + '{}'.format(i)\n",
    "\n",
    "                            m = metrics.Metrics(model_name = filename)\n",
    "                            m.calc_object_stats(GT_image, pp_watershed_image)\n",
    "\n",
    "                            Lstats.append(m.stats)\n",
    "\n",
    "                    Lstats_allmovies.append(Lstats)\n",
    "\n",
    "                Lstats_AllDatasets.append(Lstats_allmovies)\n",
    "            save_file_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_'\n",
    "            df_3T3    = pd.concat([pd.concat(Lstats_AllDatasets[0][i]) for i in range(len(Lstats_AllDatasets[0]))])\n",
    "            df_3T3.to_csv(save_file_name + '3T3', sep='\\t', encoding='utf-8')\n",
    "            df_HEK293 = pd.concat([pd.concat(Lstats_AllDatasets[1][i]) for i in range(len(Lstats_AllDatasets[1]))])\n",
    "            df_HEK293.to_csv(save_file_name + 'HEK293', sep='\\t', encoding='utf-8')\n",
    "            df_HeLa   = pd.concat([pd.concat(Lstats_AllDatasets[2][i]) for i in range(len(Lstats_AllDatasets[2]))])\n",
    "            df_HeLa.to_csv(save_file_name + 'HeLa', sep='\\t', encoding='utf-8')\n",
    "            df_RAW264 = pd.concat([pd.concat(Lstats_AllDatasets[3][i]) for i in range(len(Lstats_AllDatasets[3]))])\n",
    "            df_RAW264.to_csv(save_file_name + 'RAW264', sep='\\t', encoding='utf-8')\n",
    "        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
