{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "\n",
    "import deepcell\n",
    "from deepcell import model_zoo\n",
    "from deepcell import losses\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from deepcell.utils.tracking_utils import save_trks\n",
    "from deepcell.utils.retinanet_anchor_utils import get_anchor_parameters\n",
    "from deepcell.callbacks import RedirectModel, Evaluate\n",
    "from deepcell.image_generators import RetinaMovieDataGenerator, RetinaNetGenerator\n",
    "# from deepcell.model_zoo import shapemask_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "From `shape_mask` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                model_dir=None,\n",
    "                model_name=None,\n",
    "                train_dict=None,\n",
    "                test_dict=None,\n",
    "                batch_size=1,\n",
    "                num_classes=1,\n",
    "                fpb=1,\n",
    "                backbone_levels=None,\n",
    "                pyramid_levels=None,\n",
    "                anchor_params=None,\n",
    "                n_epoch=16,\n",
    "                optimizer=Adam(lr=1e-5, clipnorm=0.001),\n",
    "                lr_sched = rate_scheduler(lr=1e-5, decay=0.99)\n",
    "                ):\n",
    "    \n",
    "    if fpb == 1:\n",
    "        datagen = RetinaNetGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaNetGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "    \n",
    "    else:\n",
    "        datagen = RetinaMovieDataGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaMovieDataGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "    retinanet_losses = losses.RetinaNetLosses(\n",
    "        sigma=3.0,\n",
    "        alpha=0.25,\n",
    "        gamma=2.0,\n",
    "        iou_threshold=0.5,\n",
    "        mask_size=(28,28))\n",
    "\n",
    "    loss = {\n",
    "        'regression': retinanet_losses.regress_loss,\n",
    "        'classification': retinanet_losses.classification_loss,\n",
    "        'masks': retinanet_losses.mask_loss,\n",
    "        'final_detection': retinanet_losses.final_detection_loss\n",
    "        }\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    iou_threshold = 0.5\n",
    "    score_threshold = 0.01\n",
    "    max_detections = 100\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_data,\n",
    "        steps_per_epoch=X_train.shape[0] * X_train.shape[1]// batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=X_test.shape[0] * X_test.shape[1]// batch_size,\n",
    "        callbacks=[\n",
    "            callbacks.LearningRateScheduler(lr_sched),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                os.path.join(model_dir, model_name + '.h5'),\n",
    "                monitor='val_loss',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False),\n",
    "            RedirectModel(\n",
    "                Evaluate(val_data,\n",
    "                         iou_threshold=iou_threshold,\n",
    "                         score_threshold=score_threshold,\n",
    "                         max_detections=max_detections,\n",
    "                         frames_per_batch=fpb,\n",
    "                         weighted_average=True),\n",
    "                prediction_model)\n",
    "        ])\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -\n",
      "X.shape: (722, 30, 135, 160, 1)\n",
      "y.shape: (722, 30, 135, 160, 1)\n",
      "y_train_reshaped shape: (21660, 135, 160, 1)\n",
      "optimal_params:  (['C1', 'C2', 'C3'], ['P1', 'P2', 'P3'], <deepcell.utils.retinanet_anchor_utils.AnchorParameters object at 0x7f91f44bccc0>)\n",
      " -\n",
      "X.shape: (722, 30, 135, 160, 1)\n",
      "y.shape: (722, 30, 135, 160, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "retinanet() got an unexpected keyword argument 'temporal_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cd1ae2e23c52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                         \u001b[0mbackbone_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone_levels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                                         \u001b[0mpyramid_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpyramid_levels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                                         norm_method=norm_method)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/data/models'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepcell/model_zoo/maskrcnn.py\u001b[0m in \u001b[0;36mRetinaMask\u001b[0;34m(backbone, num_classes, input_shape, inputs, backbone_levels, pyramid_levels, norm_method, location, use_imagenet, crop_size, pooling, mask_dtype, required_channels, frames_per_batch, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mmask_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mframes_per_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframes_per_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         **kwargs)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepcell/model_zoo/maskrcnn.py\u001b[0m in \u001b[0;36mretinanet_mask\u001b[0;34m(inputs, backbone_dict, num_classes, frames_per_batch, backbone_levels, pyramid_levels, retinanet_model, anchor_params, nms, panoptic, class_specific_filter, crop_size, mask_size, name, roi_submodels, max_detections, score_threshold, nms_threshold, mask_dtype, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mnum_anchors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manchor_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mframes_per_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframes_per_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: retinanet() got an unexpected keyword argument 'temporal_mode'"
     ]
    }
   ],
   "source": [
    "# download_datasets()\n",
    "\n",
    "DATA_DIR = '/data/training_data/tracking_benchmark_data'\n",
    "\n",
    "backbones = ['featurenet', 'mobilenetv2', 'resnet50']\n",
    "fpbs = [5, 3, 1]\n",
    "all_data = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "datasets = [all_data]\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "\n",
    "n_epoch = 4\n",
    "seed = 808\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    num_classes=1\n",
    "    test_size = 0.1 # % of data saved as test\n",
    "    test_seed = 10\n",
    "\n",
    "    filename = os.path.join(DATA_DIR, dataset)\n",
    "    train_dict, test_dict = get_data(filename, seed=seed, test_size=test_size)\n",
    "    print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "    X_train, y_train = train_dict['X'], train_dict['y']\n",
    "    X_test, y_test = test_dict['X'], test_dict['y']\n",
    "    y_train_reshaped = y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4]))\n",
    "    print(\"y_train_reshaped shape:\", y_train_reshaped.shape)\n",
    "    optimal_params = get_anchor_parameters(y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4])))\n",
    "    backbone_levels, pyramid_levels, anchor_params = optimal_params\n",
    "    norm_method='whole_image'\n",
    "    print(\"optimal_params: \", optimal_params)\n",
    "\n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "            use_imagenet=False\n",
    "        else:\n",
    "            use_imagenet=True\n",
    "\n",
    "        for fpb in fpbs:\n",
    "            if fpb == 1:\n",
    "                train_dict = {'X':X_train.reshape((-1,X_train.shape[2], X_train.shape[3], X_train.shape[4])), \n",
    "                              'y': y_train.reshape((-1,y_train.shape[2], y_train.shape[3], y_train.shape[4]))}\n",
    "                test_dict = {'X':X_test.reshape((-1, X_test.shape[2], X_test.shape[3], X_test.shape[4])), \n",
    "                            'y': y_test.reshape((-1, y_test.shape[2], y_test.shape[3], y_test.shape[4]))}\n",
    "            else:\n",
    "                train_dict = {'X':X_train, 'y':y_train}\n",
    "                test_dict = {'X':X_test, 'y':y_test}\n",
    "            print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "\n",
    "\n",
    "            for temporal_mode in temporal_modes:\n",
    "                prediction_model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=X_train.shape[2:],\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "\n",
    "                model_dir = '/data/models'\n",
    "                model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + dataset\n",
    "\n",
    "                # Train model\n",
    "                print(\"Training model: \", model_name)\n",
    "                trained_model = train_model(model,\n",
    "                            model_dir=model_dir,\n",
    "                            model_name=model_name,\n",
    "                            train_dict=train_dict,\n",
    "                            test_dict=test_dict,\n",
    "                            fpb=fpb,\n",
    "                            backbone_levels=backbone_levels,\n",
    "                            pyramid_levels=pyramid_levels,\n",
    "                            anchor_params=anchor_params,\n",
    "                            n_epoch=n_epoch,\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data to load (raw images from trk test files)\n",
    "RAW_BASE_DIR = '/data/training_data/tracking_benchmark_data/test'\n",
    "\n",
    "raw_trks_3T3  = os.path.join(RAW_BASE_DIR, '3T3_NIH_test_BData.trks')\n",
    "raw_trks_HEK  = os.path.join(RAW_BASE_DIR, 'HEK293_generic_test_BData.trks')\n",
    "raw_trks_HeLa = os.path.join(RAW_BASE_DIR, 'HeLa_S3_test_BData.trks')\n",
    "raw_trks_RAW  = os.path.join(RAW_BASE_DIR, 'RAW264_generic_test_BData.trks')\n",
    "\n",
    "# raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa]\n",
    "raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa, raw_trks_RAW]\n",
    "\n",
    "model_dir = '/data/models'\n",
    "model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + dataset\n",
    "\n",
    "backbones = ['featurenet', 'mobilenetv2', 'resnet50']\n",
    "fpbs = [5, 3, 1]\n",
    "all_data = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "datasets = [all_data]\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "norm_method = 'whole_image'\n",
    "seed = 808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from skimage.morphology import remove_small_objects\n",
    "import pandas as pd\n",
    "from deepcell import metrics\n",
    "from skimage.measure import label\n",
    "from skimage import morphology\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "\n",
    "# Go through each Dataset (3T3, HEK293, HeLa, RAW264.7)\n",
    "for set_num, dataset in enumerate(raw_trks_files):\n",
    "    # Load the trk file       \n",
    "    trks = load_trks(dataset)\n",
    "    lineages, raw, tracked = trks['lineages'], trks['X'], trks['y']\n",
    "    optimal_params = determine_anchor_params(trks['y'].reshape((-1,  trks['X'].shape[2], trks['X'].shape[3], trks['X'].shape[4])))\n",
    "    backbone_levels, pyramid_levels, anchor_params = optimal_params\n",
    "    \n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "                use_imagenet=False\n",
    "            else:\n",
    "                use_imagenet=True\n",
    "\n",
    "            for fpb in fpbs:\n",
    "                for temporal_mode in temporal_modes:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
