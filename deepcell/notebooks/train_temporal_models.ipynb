{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "\n",
    "import deepcell\n",
    "from deepcell import model_zoo\n",
    "from deepcell import losses\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from deepcell.utils.tracking_utils import save_trks\n",
    "from deepcell.utils.retinanet_anchor_utils import get_anchor_parameters\n",
    "from deepcell.callbacks import RedirectModel, Evaluate\n",
    "from deepcell.image_generators import RetinaMovieDataGenerator, RetinaNetGenerator\n",
    "# from deepcell.model_zoo import shapemask_box\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "From `shape_mask` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                model_dir=None,\n",
    "                model_name=None,\n",
    "                train_dict=None,\n",
    "                test_dict=None,\n",
    "                batch_size=1,\n",
    "                num_classes=1,\n",
    "                fpb=1,\n",
    "                backbone_levels=None,\n",
    "                pyramid_levels=None,\n",
    "                anchor_params=None,\n",
    "                n_epoch=16,\n",
    "                optimizer=Adam(lr=1e-5, clipnorm=0.001),\n",
    "                lr_sched = rate_scheduler(lr=1e-5, decay=0.99)\n",
    "                ):\n",
    "    \n",
    "    if fpb == 1:\n",
    "        datagen = RetinaNetGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaNetGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "    \n",
    "    else:\n",
    "        datagen = RetinaMovieDataGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaMovieDataGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "    retinanet_losses = losses.RetinaNetLosses(\n",
    "        sigma=3.0,\n",
    "        alpha=0.25,\n",
    "        gamma=2.0,\n",
    "        iou_threshold=0.5,\n",
    "        mask_size=(28,28))\n",
    "\n",
    "    loss = {\n",
    "        'regression': retinanet_losses.regress_loss,\n",
    "        'classification': retinanet_losses.classification_loss,\n",
    "        'masks': retinanet_losses.mask_loss,\n",
    "        'final_detection': retinanet_losses.final_detection_loss\n",
    "        }\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    iou_threshold = 0.5\n",
    "    score_threshold = 0.01\n",
    "    max_detections = 100\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_data,\n",
    "        steps_per_epoch=X_train.shape[0] * X_train.shape[1]// batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=X_test.shape[0] * X_test.shape[1]// batch_size,\n",
    "        callbacks=[\n",
    "            callbacks.LearningRateScheduler(lr_sched),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                os.path.join(model_dir, model_name + '.h5'),\n",
    "                monitor='val_loss',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False),\n",
    "            RedirectModel(\n",
    "                Evaluate(val_data,\n",
    "                         iou_threshold=iou_threshold,\n",
    "                         score_threshold=score_threshold,\n",
    "                         max_detections=max_detections,\n",
    "                         frames_per_batch=fpb,\n",
    "                         weighted_average=True),\n",
    "                prediction_model)\n",
    "        ])\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_datasets()\n",
    "\n",
    "DATA_DIR = '/data/training_data/tracking_benchmark_data'\n",
    "\n",
    "backbones = ['featurenet'] #, 'mobilenetv2', 'resnet50']\n",
    "fpbs = [5, 3, 1]\n",
    "all_data = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "datasets = [all_data]\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "\n",
    "n_epoch = 4\n",
    "seed = 808\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    num_classes=1\n",
    "    test_size = 0.1 # % of data saved as test\n",
    "    test_seed = 10\n",
    "\n",
    "    filename = os.path.join(DATA_DIR, dataset)\n",
    "    train_dict, test_dict = get_data(filename, seed=seed, test_size=test_size)\n",
    "    print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "    X_train, y_train = train_dict['X'], train_dict['y']\n",
    "    X_test, y_test = test_dict['X'], test_dict['y']\n",
    "    y_train_reshaped = y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4]))\n",
    "    print(\"y_train_reshaped shape:\", y_train_reshaped.shape)\n",
    "    optimal_params = get_anchor_parameters(y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4])))\n",
    "    backbone_levels, pyramid_levels, anchor_params = optimal_params\n",
    "    norm_method='whole_image'\n",
    "    print(\"optimal_params: \", optimal_params)\n",
    "\n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "            use_imagenet=False\n",
    "        else:\n",
    "            use_imagenet=True\n",
    "\n",
    "        for fpb in fpbs:\n",
    "            if fpb == 1:\n",
    "                train_dict = {'X':X_train.reshape((-1,X_train.shape[2], X_train.shape[3], X_train.shape[4])), \n",
    "                              'y': y_train.reshape((-1,y_train.shape[2], y_train.shape[3], y_train.shape[4]))}\n",
    "                test_dict = {'X':X_test.reshape((-1, X_test.shape[2], X_test.shape[3], X_test.shape[4])), \n",
    "                            'y': y_test.reshape((-1, y_test.shape[2], y_test.shape[3], y_test.shape[4]))}\n",
    "            else:\n",
    "                train_dict = {'X':X_train, 'y':y_train}\n",
    "                test_dict = {'X':X_test, 'y':y_test}\n",
    "            print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "\n",
    "\n",
    "            for temporal_mode in temporal_modes:\n",
    "                model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=X_train.shape[2:],\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "                prediction_model = model\n",
    "\n",
    "                model_dir = '/data/models'\n",
    "                model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + dataset\n",
    "\n",
    "                # Train model\n",
    "                print(\"Training model: \", model_name)\n",
    "                trained_model = train_model(model,\n",
    "                            model_dir=model_dir,\n",
    "                            model_name=model_name,\n",
    "                            train_dict=train_dict,\n",
    "                            test_dict=test_dict,\n",
    "                            fpb=fpb,\n",
    "                            backbone_levels=backbone_levels,\n",
    "                            pyramid_levels=pyramid_levels,\n",
    "                            anchor_params=anchor_params,\n",
    "                            n_epoch=n_epoch,\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data to load (raw images from trk test files)\n",
    "RAW_BASE_DIR = '/data/training_data/tracking_benchmark_data/test'\n",
    "\n",
    "raw_trks_3T3  = os.path.join(RAW_BASE_DIR, '3T3_NIH_test_BData.trks')\n",
    "raw_trks_HEK  = os.path.join(RAW_BASE_DIR, 'HEK293_generic_test_BData.trks')\n",
    "raw_trks_HeLa = os.path.join(RAW_BASE_DIR, 'HeLa_S3_test_BData.trks')\n",
    "raw_trks_RAW  = os.path.join(RAW_BASE_DIR, 'RAW264_generic_test_BData.trks')\n",
    "\n",
    "# raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa]\n",
    "raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_RAW, raw_trks_HeLa]\n",
    "\n",
    "model_dir = '/data/models'\n",
    "\n",
    "DATA_DIR = '/data/training_data/tracking_benchmark_data'\n",
    "dataset = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "filename = os.path.join(DATA_DIR, dataset)\n",
    "test_size = 0.1 # % of data saved as test\n",
    "seed = 808\n",
    "train_dict, test_dict = get_data(filename, seed=seed, test_size=test_size)\n",
    "X_train, y_train = train_dict['X'], train_dict['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import relabel_sequential\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "def retinanet_to_label_image(retinanet_outputs,\n",
    "                             shape0,\n",
    "                             shape1,\n",
    "                             include_final_detection_layer=False,\n",
    "                             score_threshold=0.5,\n",
    "                             multi_iou_threshold=0.25,\n",
    "                             binarize_threshold=0.5,\n",
    "                             small_objects_threshold=100):\n",
    "\n",
    "    if include_final_detection_layer:\n",
    "        boxes_batch = retinanet_outputs[-5][0]\n",
    "        scores_batch = retinanet_outputs[-4][0]\n",
    "        labels_batch = retinanet_outputs[-3][0]\n",
    "        masks_batch = retinanet_outputs[-2][0]\n",
    "        final_scores = retinanet_outputs[-1][0]\n",
    "    else:\n",
    "        boxes_batch = retinanet_outputs[-4][0]\n",
    "        scores_batch = retinanet_outputs[-3][0]\n",
    "        labels_batch = retinanet_outputs[-2][0]\n",
    "        masks_batch = retinanet_outputs[-1][0]\n",
    "        \n",
    "    # Create empty label matrix\n",
    "    label_images = np.zeros(\n",
    "        (masks_batch.shape[0], shape0, shape1))\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i in range(boxes_batch.shape[0]):\n",
    "        boxes = boxes_batch[i]\n",
    "        scores = scores_batch[i]\n",
    "        labels = labels_batch[i]\n",
    "        masks = masks_batch[i]\n",
    "        \n",
    "        # Get good detections\n",
    "        selection = np.nonzero(scores > score_threshold)[0]\n",
    "        boxes = boxes[selection]\n",
    "        scores = scores[selection]\n",
    "        labels = labels[selection]\n",
    "        masks = masks[selection, ..., -1]\n",
    "\n",
    "        # Compute overlap of masks with each other\n",
    "        mask_image = np.zeros((masks.shape[0], shape0, shape1), dtype='float32')\n",
    "\n",
    "        for j in range(masks.shape[0]): # masks.shape[0] = fpb\n",
    "            mask = masks[j]\n",
    "            box = boxes[j].astype(int)\n",
    "            mask = resize(mask, (box[3] - box[1], box[2] - box[0]))\n",
    "            mask = (mask > binarize_threshold).astype('float32')\n",
    "            mask_image[j, box[1]:box[3], box[0]:box[2]] = mask\n",
    "            \n",
    "        all_masks = mask_image\n",
    "        range_mask = np.arange(1, all_masks.shape[0] + 1)\n",
    "        all_masks *= np.expand_dims(np.expand_dims(range_mask, axis=-1), axis=-1)\n",
    "\n",
    "        label_image = np.sum(all_masks, axis=0).astype(int)\n",
    "\n",
    "        # Remove small objects\n",
    "        label_image = morphology.remove_small_objects(\n",
    "            label_image, min_size=small_objects_threshold)\n",
    "\n",
    "        # Relabel the label image\n",
    "        label_image, _, _ = relabel_sequential(label_image)\n",
    "\n",
    "        # Store in batched array\n",
    "        label_images[i] = label_image\n",
    "\n",
    "    return label_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  /data/training_data/tracking_benchmark_data/test/RAW264_generic_test_BData.trks\n",
      "frames per batch:  5\n",
      "featurenet_fpb5_conv\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               8.0  0.986111\n",
      "1              28.0  0.928571\n",
      "2              16.0  0.993056\n",
      "3               6.0  1.000000\n",
      "4              17.0  0.937716\n",
      "5               6.0  0.976190\n",
      "6               6.0  1.000000\n",
      "7               5.0  0.902857\n",
      "8              12.0  0.993590\n",
      "9               8.0  1.000000\n",
      "10             11.0  1.000000\n",
      "11             24.0  0.913194\n",
      "12              7.0  0.857143\n",
      "total_instances 154.0\n",
      "mAP 0.9606483863414261\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb5_gru\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               8.0  0.986111\n",
      "1              28.0  0.928571\n",
      "2              16.0  1.000000\n",
      "3               6.0  1.000000\n",
      "4              17.0  0.941176\n",
      "5               6.0  0.976190\n",
      "6               6.0  1.000000\n",
      "7               5.0  0.553333\n",
      "8              12.0  1.000000\n",
      "9               8.0  1.000000\n",
      "10             11.0  0.946970\n",
      "11             24.0  0.908043\n",
      "12              7.0  0.857143\n",
      "total_instances 154.0\n",
      "mAP 0.9305799117052316\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb5_lstm\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               8.0  1.000000\n",
      "1              28.0  0.928571\n",
      "2              16.0  0.979167\n",
      "3               6.0  1.000000\n",
      "4              17.0  0.934641\n",
      "5               6.0  0.976190\n",
      "6               6.0  1.000000\n",
      "7               5.0  0.885714\n",
      "8              12.0  0.983333\n",
      "9               8.0  1.000000\n",
      "10             11.0  1.000000\n",
      "11             24.0  0.908043\n",
      "12              7.0  0.857143\n",
      "total_instances 154.0\n",
      "mAP 0.9579079268273643\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb5_None\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               8.0  0.899554\n",
      "1              28.0  0.928571\n",
      "2              16.0  0.993056\n",
      "3               6.0  1.000000\n",
      "4              17.0  0.941176\n",
      "5               6.0  1.000000\n",
      "6               6.0  1.000000\n",
      "7               5.0  0.737037\n",
      "8              12.0  0.975490\n",
      "9               8.0  1.000000\n",
      "10             11.0  0.992424\n",
      "11             24.0  0.907738\n",
      "12              7.0  0.857143\n",
      "total_instances 154.0\n",
      "mAP 0.9409376503126503\n",
      "\n",
      "\n",
      "\n",
      "frames per batch:  3\n",
      "featurenet_fpb3_conv\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               8.0  1.000000\n",
      "1              28.0  0.928571\n",
      "2              16.0  0.982955\n",
      "3               6.0  1.000000\n",
      "4              17.0  0.929412\n",
      "5               6.0  0.976190\n",
      "6               6.0  1.000000\n",
      "7               5.0  0.573333\n",
      "8              12.0  0.946970\n",
      "9               8.0  1.000000\n",
      "10             11.0  1.000000\n",
      "11             24.0  0.901190\n",
      "12              7.0  0.857143\n",
      "total_instances 154.0\n",
      "mAP 0.9304434291198997\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb3_gru\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               8.0  0.958333\n",
      "1              28.0  0.928571\n",
      "2              16.0  1.000000\n",
      "3               6.0  1.000000\n",
      "4              17.0  0.941176\n",
      "5               6.0  0.976190\n",
      "6               6.0  1.000000\n",
      "7               5.0  0.690000\n",
      "8              12.0  1.000000\n",
      "9               8.0  1.000000\n",
      "10             11.0  1.000000\n",
      "11             24.0  0.909722\n",
      "12              7.0  0.857143\n",
      "total_instances 154.0\n",
      "mAP 0.9431643683114271\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb3_lstm\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               8.0  1.000000\n",
      "1              28.0  0.928571\n",
      "2              16.0  0.987500\n",
      "3               6.0  1.000000\n",
      "4              17.0  0.941176\n",
      "5               6.0  0.976190\n",
      "6               6.0  1.000000\n",
      "7               5.0  0.733333\n",
      "8              12.0  1.000000\n",
      "9               8.0  1.000000\n",
      "10             11.0  1.000000\n",
      "11             24.0  0.913194\n",
      "12              7.0  0.857143\n",
      "total_instances 154.0\n",
      "mAP 0.9490083854054443\n",
      "\n",
      "\n",
      "\n",
      "featurenet_fpb3_None\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n",
      "batch_num:  8\n",
      "batch_num:  9\n",
      "batch_num:  10\n",
      "batch_num:  11\n",
      "batch_num:  12\n",
      "\n",
      "\n",
      "\n",
      "    total_instances       mAP\n",
      "0               8.0  0.958333\n",
      "1              28.0  0.928571\n",
      "2              16.0  0.993056\n",
      "3               6.0  1.000000\n",
      "4              17.0  0.934641\n",
      "5               6.0  1.000000\n",
      "6               6.0  1.000000\n",
      "7               5.0  0.730159\n",
      "8              12.0  0.952381\n",
      "9               8.0  1.000000\n",
      "10             11.0  1.000000\n",
      "11             24.0  0.908951\n",
      "12              7.0  0.857143\n",
      "total_instances 154.0\n",
      "mAP 0.943325692100202\n",
      "\n",
      "\n",
      "\n",
      "dataset:  /data/training_data/tracking_benchmark_data/test/HeLa_S3_test_BData.trks\n",
      "frames per batch:  5\n",
      "featurenet_fpb5_conv\n",
      "batch_num:  0\n",
      "batch_num:  1\n",
      "batch_num:  2\n",
      "batch_num:  3\n",
      "batch_num:  4\n",
      "batch_num:  5\n",
      "batch_num:  6\n",
      "batch_num:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0129 06:51:40.383850 139842123323200 retinanet.py:619] Removing 1 of 1 images with fewer than 3 objects.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_num:  8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f1c19139b16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                                                 \u001b[0miou_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miou_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                                                                 \u001b[0mscore_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                                                                 \u001b[0mmax_detections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_detections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                                                             )\n\u001b[1;32m     94\u001b[0m                     \u001b[0;31m# print(recall, precision, average_precisions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepcell/utils/retinanet_anchor_utils.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(generator, model, iou_threshold, score_threshold, frames_per_batch, max_detections)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0mframes_per_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframes_per_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0mscore_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         max_detections=max_detections)\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0mall_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_per_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0maverage_precisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepcell/utils/retinanet_anchor_utils.py\u001b[0m in \u001b[0;36m_get_detections\u001b[0;34m(generator, model, frames_per_batch, score_threshold, max_detections)\u001b[0m\n\u001b[1;32m    813\u001b[0m                         \u001b[0mlabels_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mbatch_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m         \u001b[0mbatch_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from deepcell.utils.retinanet_anchor_utils import evaluate\n",
    "\n",
    "from skimage.morphology import remove_small_objects\n",
    "import pandas as pd\n",
    "from deepcell import metrics\n",
    "from skimage.measure import label\n",
    "from skimage import morphology\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "\n",
    "iou_threshold = 0.5\n",
    "score_threshold = 0.01\n",
    "max_detections = 100\n",
    "num_classes=1\n",
    "\n",
    "backbones = ['featurenet']\n",
    "fpbs = [5, 3]\n",
    "\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "training_optimal_params = get_anchor_parameters(y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4])))\n",
    "\n",
    "# Go through each Dataset (3T3, HEK293, HeLa, RAW264.7)\n",
    "for set_num, dataset in enumerate(raw_trks_files):\n",
    "    print(\"dataset: \", dataset)\n",
    "    # Load the trk file       \n",
    "    trks = load_trks(dataset)\n",
    "    lineages, raw, tracked = trks['lineages'], trks['X'], trks['y']\n",
    "    norm_method='whole_image'\n",
    "    backbone_levels, pyramid_levels, anchor_params = training_optimal_params\n",
    "    datagen_val = RetinaMovieDataGenerator()\n",
    "    \n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "                use_imagenet=False\n",
    "        else:\n",
    "            use_imagenet=True\n",
    "                \n",
    "        for fpb in fpbs:\n",
    "            print(\"frames per batch: \", fpb)\n",
    "            for temporal_mode in temporal_modes:\n",
    "                prediction_model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=trks['X'].shape[2:],\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "                # print(prediction_model.summary())\n",
    "\n",
    "                model_dir = '/data/models/'\n",
    "                model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "                print(backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode))\n",
    "                prediction_model.load_weights(os.path.join(model_dir, model_name + '.h5'))\n",
    "\n",
    "                Model_DF = pd.DataFrame(columns=['total_instances', 'mAP'])\n",
    "                \n",
    "                Lstats_allmovies = []\n",
    "\n",
    "                # Go through each batch (movie) in each dataset\n",
    "                for batch_num, movie in enumerate(trks['X']):\n",
    "                    Lstats = []\n",
    "                    print(\"batch_num: \", batch_num)\n",
    "\n",
    "                    # Predict on the raw data\n",
    "                    X_test_temp = np.expand_dims(movie, axis=0)\n",
    "                    y_test_temp = np.expand_dims(trks['y'][batch_num], axis=0)\n",
    "                    y_pred = np.zeros(y_test_temp.shape)\n",
    "                    \n",
    "                    for index in range(X_test_temp.shape[0]):\n",
    "                        for frame in range(0, X_test_temp.shape[0], fpb):\n",
    "                            image = X_test_temp[index:index + 1, frame:frame + fpb]\n",
    "                            gt_mask = y_test_temp[index:index + 1, frame:frame + fpb]\n",
    "                            outputs = prediction_model.predict(image)\n",
    "                            label_images = retinanet_to_label_image(outputs, X_test_temp.shape[2], \n",
    "                                               X_test_temp.shape[3], include_final_detection_layer=True)\n",
    "                            \n",
    "                            for i in range(fpb):\n",
    "                                GT_image = y_test_temp[index, frame+i, :, :, 0]\n",
    "                                GT_image = np.expand_dims(GT_image, axis=0)\n",
    "                                pred = label_images[i]\n",
    "                                pred = np.expand_dims(pred, axis=0)\n",
    "                                m = metrics.Metrics(model_name = model_name)\n",
    "                                m.calc_object_stats(GT_image, pred)\n",
    "                                Lstats.append(m.stats)\n",
    "                                \n",
    "                            y_pred[index, frame:frame + fpb,...,0] = np.array(label_images)\n",
    "                            \n",
    "                    Lstats_allmovies.append(Lstats)\n",
    "                df = pd.concat([pd.concat(Lstats_allmovies[i]) for i in range(len(Lstats_allmovies))])\n",
    "                df.to_csv(os.getcwd() + '/' + backbone + '_' + \\\n",
    "                          'fpb' + str(fpb) + '_' + str(temporal_mode) + '.csv', index=False)\n",
    "                print('\\n')\n",
    "                print(backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode))\n",
    "                print('\\n')\n",
    "                # Total number of correct detections and incorrect detections\n",
    "                correct_det = int(df['correct_detections'].sum())\n",
    "                incorrect_det = int(df['n_pred'].sum() - df['correct_detections'].sum())\n",
    "\n",
    "                print('Correct Detections: ', correct_det)\n",
    "                print('Incorrect Detections: ', incorrect_det)\n",
    "\n",
    "                # Total number of splits, merges, and catastrophes\n",
    "                splits = df['split'].sum()\n",
    "                merges = df['merge'].sum()\n",
    "                catastrophes = df['catastrophe'].sum()\n",
    "\n",
    "                print('Splits: ', splits)\n",
    "                print('Merges: ', merges)\n",
    "                print('Catastrophes: ', catastrophes)\n",
    "\n",
    "                # Average Recall, Precision, and Jaccard Index\n",
    "                recall = 100 * df['correct_detections'].sum() / df['n_true'].sum()\n",
    "                precision = 100 * df['correct_detections'].sum() / df['n_pred'].sum()\n",
    "                jaccard = df['jaccard'].mean()\n",
    "\n",
    "                print('Recall: ', recall)\n",
    "                print('Precision: ', precision)\n",
    "                print('Average Jaccard Index: ', jaccard)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"featurenet_retinanet_mask\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 5, 154, 182, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_56 (TimeDistri (None, 5, 154, 182,  0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistri (None, 5, 154, 182,  6           time_distributed_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistri (None, 5, 39, 46, 32 29152       time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_60 (TimeDistri (None, 5, 20, 23, 32 47904       time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistri (None, 5, 77, 91, 32 10400       time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C2_reduced (Conv3D)             (None, 5, 39, 46, 25 8448        time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C3_reduced (Conv3D)             (None, 5, 20, 23, 25 8448        time_distributed_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C1_reduced (Conv3D)             (None, 5, 77, 91, 25 8448        time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "P2_upsampled (UpsampleLike)     (None, None, None, N 0           C2_reduced[0][0]                 \n",
      "                                                                 time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "P3_upsampled (UpsampleLike)     (None, None, None, N 0           C3_reduced[0][0]                 \n",
      "                                                                 time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "P1_merged (Add)                 (None, 5, 77, 91, 25 0           C1_reduced[0][0]                 \n",
      "                                                                 P2_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "P2_merged (Add)                 (None, 5, 39, 46, 25 0           C2_reduced[0][0]                 \n",
      "                                                                 P3_upsampled[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "P1 (Conv3D)                     (None, 5, 77, 91, 25 590080      P1_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P2 (Conv3D)                     (None, 5, 39, 46, 25 590080      P2_merged[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P3 (Conv3D)                     (None, 5, 20, 23, 25 590080      C3_reduced[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 5, 77, 91, 25 1769728     P1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 5, 39, 46, 25 1769728     P2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 5, 20, 23, 25 1769728     P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 5, 77, 91, 25 1024        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 5, 39, 46, 25 1024        conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 5, 20, 23, 25 1024        conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "regression_submodel (Model)     (None, 5, None, 4)   7493692     batch_normalization_62[0][0]     \n",
      "                                                                 batch_normalization_63[0][0]     \n",
      "                                                                 batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_67 (TimeDistri (None, 5, 105105, 4) 60          P1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_68 (TimeDistri (None, 5, 26910, 4)  60          P2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_69 (TimeDistri (None, 5, 6900, 4)   60          P3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "regression (Concatenate)        (None, 5, None, 4)   0           regression_submodel[1][0]        \n",
      "                                                                 regression_submodel[2][0]        \n",
      "                                                                 regression_submodel[3][0]        \n",
      "__________________________________________________________________________________________________\n",
      "anchors (Concatenate)           (None, 5, 138915, 4) 0           time_distributed_67[0][0]        \n",
      "                                                                 time_distributed_68[0][0]        \n",
      "                                                                 time_distributed_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "classification_submodel (Model) (None, 5, None, 1)   7182607     batch_normalization_62[0][0]     \n",
      "                                                                 batch_normalization_63[0][0]     \n",
      "                                                                 batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "boxes (RegressBoxes)            (None, 5, 138915, 4) 0           anchors[0][0]                    \n",
      "                                                                 regression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "classification (Concatenate)    (None, 5, None, 1)   0           classification_submodel[1][0]    \n",
      "                                                                 classification_submodel[2][0]    \n",
      "                                                                 classification_submodel[3][0]    \n",
      "__________________________________________________________________________________________________\n",
      "clipped_boxes (ClipBoxes)       (None, 5, 138915, 4) 0           input_25[0][0]                   \n",
      "                                                                 boxes[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "filtered_detections (FilterDete [(None, None, 100, 4 0           clipped_boxes[0][0]              \n",
      "                                                                 classification[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "upsample_like_4 (UpsampleLike)  (None, None, None, N 0           P1[0][0]                         \n",
      "                                                                 input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "roi_align_4 (RoiAlign)          (None, None, None, N 0           filtered_detections[0][0]        \n",
      "                                                                 upsample_like_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_63 (TimeDistri (None, None, None, 2 2950657     roi_align_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_66 (TimeDistri (None, None, None, 1 2950657     roi_align_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "masks (ConcatenateBoxes)        (None, None, 100, No 0           filtered_detections[0][0]        \n",
      "                                                                 time_distributed_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "final_detection (ConcatenateBox (None, None, 100, No 0           filtered_detections[0][0]        \n",
      "                                                                 time_distributed_66[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 27,733,543\n",
      "Trainable params: 27,731,623\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "backbone = 'featurenet'\n",
    "fpbs = 5\n",
    "temporal_mode = 'conv'\n",
    "shape_mask = False\n",
    "\n",
    "prediction_model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=trks['X'].shape[2:],\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "print(prediction_model.summary())\n",
    "\n",
    "model_dir = '/data/models/'\n",
    "model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "prediction_model.load_weights(model_dir + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_25 to have 5 dimensions, but got array with shape (30, 154, 182, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4fb73f0caf00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;31m# generate symbolic tensors).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1060\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    374\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_25 to have 5 dimensions, but got array with shape (30, 154, 182, 1)"
     ]
    }
   ],
   "source": [
    "outputs = prediction_model.predict(X_test_temp[0])\n",
    "final_scores = outputs[-1]\n",
    "selection = np.where(final_scores[0, i] > 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_optimal_params = get_anchor_parameters(y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8. 16. 32.]\n",
      "[2. 4. 8.]\n",
      "[0.25 0.5  1.   2.   4.  ]\n",
      "[1, 1.2599210498948732, 1.5874010519681994]\n"
     ]
    }
   ],
   "source": [
    "print(training_optimal_params[2].sizes)\n",
    "print(training_optimal_params[2].strides)\n",
    "print(training_optimal_params[2].ratios)\n",
    "print(training_optimal_params[2].scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
