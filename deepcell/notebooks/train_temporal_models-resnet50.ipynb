{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "\n",
    "import deepcell\n",
    "from deepcell import model_zoo\n",
    "from deepcell import losses\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from deepcell.utils.tracking_utils import save_trks\n",
    "from deepcell.utils.retinanet_anchor_utils import get_anchor_parameters\n",
    "from deepcell.callbacks import RedirectModel, Evaluate\n",
    "from deepcell.image_generators import RetinaMovieDataGenerator, RetinaNetGenerator\n",
    "# from deepcell.model_zoo import shapemask_box\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "From `shape_mask` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                model_dir=None,\n",
    "                model_name=None,\n",
    "                train_dict=None,\n",
    "                test_dict=None,\n",
    "                batch_size=1,\n",
    "                num_classes=1,\n",
    "                fpb=1,\n",
    "                backbone_levels=None,\n",
    "                pyramid_levels=None,\n",
    "                anchor_params=None,\n",
    "                n_epoch=16,\n",
    "                optimizer=Adam(lr=1e-5, clipnorm=0.001),\n",
    "                lr_sched = rate_scheduler(lr=1e-5, decay=0.99)\n",
    "                ):\n",
    "    \n",
    "    if fpb == 1:\n",
    "        datagen = RetinaNetGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaNetGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "    \n",
    "    else:\n",
    "        datagen = RetinaMovieDataGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=(0.8, 1.2),\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)\n",
    "\n",
    "        datagen_val = RetinaMovieDataGenerator()\n",
    "\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            batch_size=batch_size,\n",
    "            include_masks=True,\n",
    "            include_final_detection_layer=True,\n",
    "            frames_per_batch=fpb,\n",
    "            pyramid_levels=pyramid_levels,\n",
    "            anchor_params=anchor_params)\n",
    "\n",
    "    retinanet_losses = losses.RetinaNetLosses(\n",
    "        sigma=3.0,\n",
    "        alpha=0.25,\n",
    "        gamma=2.0,\n",
    "        iou_threshold=0.5,\n",
    "        mask_size=(28,28))\n",
    "\n",
    "    loss = {\n",
    "        'regression': retinanet_losses.regress_loss,\n",
    "        'classification': retinanet_losses.classification_loss,\n",
    "        'masks': retinanet_losses.mask_loss,\n",
    "        'final_detection': retinanet_losses.final_detection_loss\n",
    "        }\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    iou_threshold = 0.5\n",
    "    score_threshold = 0.01\n",
    "    max_detections = 100\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_data,\n",
    "        steps_per_epoch=X_train.shape[0] * X_train.shape[1]// batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=X_test.shape[0] * X_test.shape[1]// batch_size,\n",
    "        callbacks=[\n",
    "            callbacks.LearningRateScheduler(lr_sched),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                os.path.join(model_dir, model_name + '.h5'),\n",
    "                monitor='val_loss',\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False),\n",
    "            RedirectModel(\n",
    "                Evaluate(val_data,\n",
    "                         iou_threshold=iou_threshold,\n",
    "                         score_threshold=score_threshold,\n",
    "                         max_detections=max_detections,\n",
    "                         frames_per_batch=fpb,\n",
    "                         weighted_average=True),\n",
    "                prediction_model)\n",
    "        ])\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -\n",
      "X.shape: (722, 30, 135, 160, 1)\n",
      "y.shape: (722, 30, 135, 160, 1)\n",
      "y_train_reshaped shape: (21660, 135, 160, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0111 03:11:13.316836 140242619287360 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_params:  (['C1', 'C2', 'C3'], ['P1', 'P2', 'P3'], <deepcell.utils.retinanet_anchor_utils.AnchorParameters object at 0x7f8ca4023828>)\n",
      " -\n",
      "X.shape: (722, 30, 135, 160, 1)\n",
      "y.shape: (722, 30, 135, 160, 1)\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 4s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0111 03:11:59.796795 140242619287360 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0111 03:12:14.272167 140242619287360 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0111 03:12:15.545627 140242619287360 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  resnet50_fpb5_conv_3T3_HeLa_HEK_RAW_cropped.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0111 03:12:26.018308 140242619287360 retinanet.py:619] Removing 77 of 722 images with fewer than 3 objects.\n",
      "W0111 03:12:29.030066 140242619287360 retinanet.py:619] Removing 7 of 81 images with fewer than 3 objects.\n",
      "W0111 03:12:29.264892 140242619287360 training_utils.py:1101] Output filtered_detections missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to filtered_detections.\n",
      "W0111 03:12:29.265924 140242619287360 training_utils.py:1101] Output filtered_detections_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to filtered_detections_1.\n",
      "W0111 03:12:29.266691 140242619287360 training_utils.py:1101] Output filtered_detections_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to filtered_detections_2.\n",
      "W0111 03:12:29.267596 140242619287360 training_utils.py:1101] Output time_distributed_7 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to time_distributed_7.\n",
      "W0111 03:12:29.268368 140242619287360 training_utils.py:1101] Output time_distributed_10 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to time_distributed_10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "  472/21660 [..............................] - ETA: 5:54:43 - loss: 3.8637 - regression_loss: 2.2617 - classification_loss: 0.6959 - masks_loss: 0.4054 - final_detection_loss: 0.5006"
     ]
    }
   ],
   "source": [
    "# download_datasets()\n",
    "\n",
    "DATA_DIR = '/data/training_data/tracking_benchmark_data'\n",
    "\n",
    "backbones = ['resnet50']\n",
    "fpbs = [5, 3, 1]\n",
    "all_data = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "datasets = [all_data]\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "\n",
    "n_epoch = 4\n",
    "seed = 808\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    num_classes=1\n",
    "    test_size = 0.1 # % of data saved as test\n",
    "    test_seed = 10\n",
    "\n",
    "    filename = os.path.join(DATA_DIR, dataset)\n",
    "    train_dict, test_dict = get_data(filename, seed=seed, test_size=test_size)\n",
    "    print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "    X_train, y_train = train_dict['X'], train_dict['y']\n",
    "    X_test, y_test = test_dict['X'], test_dict['y']\n",
    "    y_train_reshaped = y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4]))\n",
    "    print(\"y_train_reshaped shape:\", y_train_reshaped.shape)\n",
    "    optimal_params = get_anchor_parameters(y_train.reshape((-1,  X_train.shape[2], X_train.shape[3], X_train.shape[4])))\n",
    "    backbone_levels, pyramid_levels, anchor_params = optimal_params\n",
    "    norm_method='whole_image'\n",
    "    print(\"optimal_params: \", optimal_params)\n",
    "\n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "            use_imagenet=False\n",
    "        else:\n",
    "            use_imagenet=True\n",
    "\n",
    "        for fpb in fpbs:\n",
    "            if fpb == 1:\n",
    "                train_dict = {'X':X_train.reshape((-1,X_train.shape[2], X_train.shape[3], X_train.shape[4])), \n",
    "                              'y': y_train.reshape((-1,y_train.shape[2], y_train.shape[3], y_train.shape[4]))}\n",
    "                test_dict = {'X':X_test.reshape((-1, X_test.shape[2], X_test.shape[3], X_test.shape[4])), \n",
    "                            'y': y_test.reshape((-1, y_test.shape[2], y_test.shape[3], y_test.shape[4]))}\n",
    "            else:\n",
    "                train_dict = {'X':X_train, 'y':y_train}\n",
    "                test_dict = {'X':X_test, 'y':y_test}\n",
    "            print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))\n",
    "\n",
    "\n",
    "            for temporal_mode in temporal_modes:\n",
    "                model = model_zoo.RetinaMask(backbone=backbone,\n",
    "                                        use_imagenet=use_imagenet,\n",
    "                                        panoptic=False,\n",
    "                                        frames_per_batch=fpb,\n",
    "                                        temporal_mode=temporal_mode,\n",
    "                                        num_classes=num_classes,\n",
    "                                        input_shape=X_train.shape[2:],\n",
    "                                        anchor_params=anchor_params,\n",
    "                                        class_specific_filter=False,\n",
    "                                        backbone_levels=backbone_levels,\n",
    "                                        pyramid_levels=pyramid_levels,\n",
    "                                        norm_method=norm_method)\n",
    "                prediction_model = model\n",
    "\n",
    "                model_dir = '/data/models'\n",
    "                model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + dataset\n",
    "\n",
    "                # Train model\n",
    "                print(\"Training model: \", model_name)\n",
    "                trained_model = train_model(model,\n",
    "                            model_dir=model_dir,\n",
    "                            model_name=model_name,\n",
    "                            train_dict=train_dict,\n",
    "                            test_dict=test_dict,\n",
    "                            fpb=fpb,\n",
    "                            backbone_levels=backbone_levels,\n",
    "                            pyramid_levels=pyramid_levels,\n",
    "                            anchor_params=anchor_params,\n",
    "                            n_epoch=n_epoch,\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data to load (raw images from trk test files)\n",
    "RAW_BASE_DIR = '/data/training_data/tracking_benchmark_data/test'\n",
    "\n",
    "raw_trks_3T3  = os.path.join(RAW_BASE_DIR, '3T3_NIH_test_BData.trks')\n",
    "raw_trks_HEK  = os.path.join(RAW_BASE_DIR, 'HEK293_generic_test_BData.trks')\n",
    "raw_trks_HeLa = os.path.join(RAW_BASE_DIR, 'HeLa_S3_test_BData.trks')\n",
    "raw_trks_RAW  = os.path.join(RAW_BASE_DIR, 'RAW264_generic_test_BData.trks')\n",
    "\n",
    "# raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa]\n",
    "raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa, raw_trks_RAW]\n",
    "\n",
    "model_dir = '/data/models'\n",
    "model_name = backbone + '_' + 'fpb' + str(fpb) + '_' + str(temporal_mode) + '_' + dataset\n",
    "\n",
    "backbones = ['featurenet', 'mobilenetv2', 'resnet50']\n",
    "fpbs = [5, 3, 1]\n",
    "all_data = '3T3_HeLa_HEK_RAW_cropped.npz'\n",
    "datasets = [all_data]\n",
    "temporal_modes = ['conv', 'gru', 'lstm', None]\n",
    "shape_mask = False\n",
    "norm_method = 'whole_image'\n",
    "seed = 808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from skimage.morphology import remove_small_objects\n",
    "import pandas as pd\n",
    "from deepcell import metrics\n",
    "from skimage.measure import label\n",
    "from skimage import morphology\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "\n",
    "# Go through each Dataset (3T3, HEK293, HeLa, RAW264.7)\n",
    "for set_num, dataset in enumerate(raw_trks_files):\n",
    "    # Load the trk file       \n",
    "    trks = load_trks(dataset)\n",
    "    lineages, raw, tracked = trks['lineages'], trks['X'], trks['y']\n",
    "    optimal_params = determine_anchor_params(trks['y'].reshape((-1,  trks['X'].shape[2], trks['X'].shape[3], trks['X'].shape[4])))\n",
    "    backbone_levels, pyramid_levels, anchor_params = optimal_params\n",
    "    \n",
    "    for backbone in backbones:\n",
    "        if backbone == 'featurenet':\n",
    "                use_imagenet=False\n",
    "            else:\n",
    "                use_imagenet=True\n",
    "\n",
    "            for fpb in fpbs:\n",
    "                for temporal_mode in temporal_modes:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
