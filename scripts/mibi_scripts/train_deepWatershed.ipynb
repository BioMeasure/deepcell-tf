{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import skimage.external.tifffile as tiff\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from deepcell import get_image_sizes\n",
    "from deepcell import make_training_data\n",
    "from deepcell import bn_feature_net_31x31\n",
    "from deepcell import dilated_bn_feature_net_31x31\n",
    "from deepcell import train_model_watershed\n",
    "from deepcell import train_model_watershed_sample\n",
    "from deepcell import bn_dense_feature_net\n",
    "from deepcell import rate_scheduler\n",
    "from deepcell import train_model_disc, train_model_conv, train_model_sample\n",
    "from deepcell import run_models_on_directory\n",
    "from deepcell import export_model\n",
    "from deepcell import get_data\n",
    "\n",
    "# data options\n",
    "#DATA_OUTPUT_MODE = 'conv'\n",
    "DATA_OUTPUT_MODE = 'sample'\n",
    "BORDER_MODE = 'valid' if DATA_OUTPUT_MODE == 'sample' else 'same'\n",
    "RESIZE = True                                                              #was True\n",
    "RESHAPE_SIZE = 512\n",
    "WINDOW_SIZE = (15,15)\n",
    "N_EPOCHS = 40\n",
    "BINS = 4\n",
    "MAX_TRAIN = 1e7\n",
    "CHANNEL_NAMES = ['dsDNA', 'Ca', 'H3K27me3', 'H3K9ac', 'Ta', 'P.','edge_pred', 'interior_pred']\n",
    "\n",
    "# Check for channels_first or channels_last\n",
    "IS_CHANNELS_FIRST = K.image_data_format() == 'channels_first'\n",
    "ROW_AXIS = 2 if IS_CHANNELS_FIRST else 1\n",
    "COL_AXIS = 3 if IS_CHANNELS_FIRST else 2\n",
    "CHANNEL_AXIS = 1 if IS_CHANNELS_FIRST else -1\n",
    "\n",
    "\n",
    "# filepath constants\n",
    "DATA_DIR = '/data/data'\n",
    "MODEL_DIR = '/data/models'\n",
    "NPZ_DIR = '/data/npz_data'\n",
    "RESULTS_DIR = '/data/results'\n",
    "EXPORT_DIR = '/data/exports'\n",
    "PREFIX = 'tissues/mibi/samir'\n",
    "FG_BG_DATA_FILE = 'mibi_watershedFB_{}_{}'.format(K.image_data_format(), DATA_OUTPUT_MODE)\n",
    "WATERSHED_DATA_FILE = 'mibi_watershed_{}_{}'.format(K.image_data_format(), DATA_OUTPUT_MODE)\n",
    "CONV_DATA_FILE = 'mibi_watershedconv_{}_{}'.format(K.image_data_format(), 'conv')\n",
    "RUN_DIR = 'set1'\n",
    "\n",
    "\n",
    "for d in (NPZ_DIR, MODEL_DIR, RESULTS_DIR):\n",
    "    try:\n",
    "        os.makedirs(os.path.join(d, PREFIX))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data():\n",
    "#    file_name_save = os.path.join(NPZ_DIR, PREFIX, DATA_FILE)\n",
    "    num_of_features = 1 # Specify the number of feature masks that are present\n",
    "    training_direcs = ['set1', 'set2']\n",
    "    channel_names = CHANNEL_NAMES\n",
    "    raw_image_direc = 'raw'\n",
    "    annotation_direc = 'annotated'\n",
    "    \n",
    "    # Create training data for watershed energy transform\n",
    "    make_training_data(\n",
    "        direc_name=os.path.join(DATA_DIR, PREFIX),\n",
    "        dimensionality=2,\n",
    "        max_training_examples=MAX_TRAIN, # Define maximum number of training examples\n",
    "        window_size_x=WINDOW_SIZE[0],\n",
    "        window_size_y=WINDOW_SIZE[1],\n",
    "        border_mode=BORDER_MODE,\n",
    "        file_name_save=os.path.join(NPZ_DIR, PREFIX, WATERSHED_DATA_FILE),\n",
    "        training_direcs=training_direcs,\n",
    "        distance_transform=True,\n",
    "        distance_bins=BINS,\n",
    "        channel_names=channel_names,\n",
    "        num_of_features=BINS,\n",
    "        raw_image_direc=raw_image_direc,\n",
    "        annotation_direc=annotation_direc,\n",
    "        reshape_size=RESHAPE_SIZE if RESIZE else None,\n",
    "        edge_feature=[1, 0, 0], # Specify which feature is the edge feature,\n",
    "        dilation_radius=1,\n",
    "        output_mode=DATA_OUTPUT_MODE,\n",
    "        display=False,\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_on_training_data():\n",
    "    direc_save = os.path.join(MODEL_DIR, PREFIX)\n",
    "    direc_data = os.path.join(NPZ_DIR, PREFIX)\n",
    "    training_data = np.load(os.path.join(direc_data,FG_BG_DATA_FILE + '.npz'))\n",
    "\n",
    "    #class_weights = training_data['class_weights']\n",
    "    X, y = training_data['X'], training_data['y']\n",
    "    print('X.shape: {}\\ny.shape: {}'.format(X.shape, y.shape))\n",
    "\n",
    "    batch_size = 32 if DATA_OUTPUT_MODE == 'sample' else 1\n",
    "    optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "    n_epoch=N_EPOCHS\n",
    "\n",
    "    distance_bins = 4\n",
    "\n",
    "    model_args = {\n",
    "        'norm_method': 'max',\n",
    "        'reg': 1e-5,\n",
    "        'n_features': distance_bins,\n",
    "        'n_channels' : len(CHANNEL_NAMES)\n",
    "    }\n",
    "\n",
    "    data_format = K.image_data_format()\n",
    "    row_axis = 2 if data_format == 'channels_first' else 1\n",
    "    col_axis = 3 if data_format == 'channels_first' else 2\n",
    "    channel_axis = 1 if data_format == 'channels_first' else 3\n",
    "\n",
    "    size = (RESHAPE_SIZE, RESHAPE_SIZE) if RESIZE else X.shape[row_axis:col_axis + 1]  #added\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        model_args['input_shape'] = (X.shape[channel_axis], size[0], size[1])\n",
    "    else:\n",
    "        model_args['input_shape'] = (size[0], size[1], X.shape[channel_axis])\n",
    "\n",
    "    #instantiate and train foreground/background separation model\n",
    "    fgbg_model = bn_feature_net_31x31(n_features=3, n_channels=len(CHANNEL_NAMES))\n",
    "    \n",
    "    # instantiate and train watershed model\n",
    "    watershed_model = bn_feature_net_31x31(n_features=BINS, n_channels=len(CHANNEL_NAMES))\n",
    "\n",
    "    train_model_watershed_sample(\n",
    "        model=watershed_model,\n",
    "        dataset=WATERSHED_DATA_FILE,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=batch_size,\n",
    "        n_epoch=n_epoch,\n",
    "        distance_bins=BINS,\n",
    "        direc_save=os.path.join(MODEL_DIR, PREFIX),\n",
    "        direc_data=os.path.join(NPZ_DIR, PREFIX),\n",
    "        expt='watershed',\n",
    "        lr_sched=lr_sched,\n",
    "        class_weight=training_data['class_weights'],\n",
    "        rotation_range=180,\n",
    "        flip=True,\n",
    "        shear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (2, 2048, 2048, 3) to (32, 512, 512, 3)\n",
      "Reshaped training data from (2, 2048, 2048, 8) to (32, 512, 512, 8)\n",
      "max_training_examples is: 10000000.0\n",
      "[0, 0, 0, 1]\n",
      "class list for set  1 is:  [     0. 188387.  29842.  14095.]\n",
      "class list for set  2 is:  [     0. 195474.  25078.  11772.]\n",
      "class list for set  3 is:  [     0. 199468.  22420.  10436.]\n",
      "class list for set  4 is:  [     0. 184873.  32360.  15091.]\n",
      "class list for set  5 is:  [     0. 191862.  27707.  12755.]\n",
      "class list for set  6 is:  [     0. 194965.  25663.  11696.]\n",
      "class list for set  7 is:  [     0. 197336.  24014.  10974.]\n",
      "class list for set  8 is:  [     0. 195436.  25346.  11542.]\n",
      "class list for set  9 is:  [     0. 194404.  25878.  12042.]\n",
      "class list for set  10 is:  [     0. 189583.  29305.  13436.]\n",
      "class list for set  11 is:  [     0. 193532.  26897.  11895.]\n",
      "class list for set  12 is:  [     0. 200977.  21453.   9894.]\n",
      "class list for set  13 is:  [     0. 200920.  21557.   9847.]\n",
      "class list for set  14 is:  [     0. 174435.  39696.  18193.]\n",
      "class list for set  15 is:  [     0. 179722.  36037.  16565.]\n",
      "class list for set  16 is:  [     0. 194464.  25786.  12074.]\n",
      "class list for set  17 is:  [     0. 196171.  24600.  11553.]\n",
      "class list for set  18 is:  [     0. 197426.  24145.  10753.]\n",
      "class list for set  19 is:  [     0. 198727.  22884.  10713.]\n",
      "class list for set  20 is:  [     0. 195299.  25376.  11649.]\n",
      "class list for set  21 is:  [     0. 200219.  22167.   9938.]\n",
      "class list for set  22 is:  [     0. 203281.  19965.   9078.]\n",
      "class list for set  23 is:  [     0. 203035.  20038.   9251.]\n",
      "class list for set  24 is:  [     0. 202060.  20619.   9645.]\n",
      "class list for set  25 is:  [     0. 200386.  21863.  10075.]\n",
      "class list for set  26 is:  [     0. 200845.  21608.   9871.]\n",
      "class list for set  27 is:  [     0. 198012.  23458.  10854.]\n",
      "class list for set  28 is:  [     0. 198836.  22798.  10690.]\n",
      "class list for set  29 is:  [     0. 200105.  22345.   9874.]\n",
      "class list for set  30 is:  [     0. 198396.  23215.  10713.]\n",
      "class list for set  31 is:  [     0. 198870.  22699.  10755.]\n",
      "class list for set  32 is:  [     0. 203598.  19382.   9344.]\n",
      "list_of_max is: [16476.375, 13818.75, 12321.0, 17794.125, 15173.25, 14009.625, 13120.5, 13833.0, 14220.0, 16027.875, 14547.0, 11755.125, 11776.5, 21708.375, 19725.75, 14197.5, 13557.375, 13086.75, 12598.875, 13884.375, 12039.375, 10891.125, 10983.375, 11349.0, 11976.75, 11804.625, 12867.0, 12558.0, 12082.125, 12723.0, 12545.25, 10772.25]\n",
      "list_of_max after mean-limiting is: [20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0, 20448.0]\n",
      "sample_label_matrix batch is:  [ 5 23 23 ...  1 28  1]\n",
      "Number of features: 4\n",
      "Number of training data points: 1672090\n",
      "Class weights: [0.85179989 0.85471934 1.5242958 ]\n"
     ]
    }
   ],
   "source": [
    "generate_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (32, 512, 512, 5)\n",
      "y.shape: (2583728,)\n",
      "Using feature net 31x31 with batch normalization\n",
      "Using feature net 31x31 with batch normalization\n",
      "batch in get_data is:  [ 5 23 23 ...  1 28  1]\n",
      "get_data batch_train is:  [20  8  9 ...  7  5 19]\n",
      "get_data batch_test is:  [28 20 23 ... 27 27 25]\n",
      "X_train shape: (32, 512, 512, 8)\n",
      "y_train shape: (1504881,)\n",
      "X_test shape: (32, 512, 512, 8)\n",
      "y_test shape: (167209,)\n",
      "Output Shape: (None, 4)\n",
      "Number of Classes: 4\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Training batches and labels should have the samelength. Found X.shape: (32, 512, 512, 8) y.shape: (1504881, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6c7bcb704767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model_on_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-66fe4ff65cb3>\u001b[0m in \u001b[0;36mtrain_model_on_training_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mrotation_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mflip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         shear=False)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/training.py\u001b[0m in \u001b[0;36mtrain_model_watershed_sample\u001b[0;34m(model, dataset, optimizer, expt, it, batch_size, n_epoch, distance_bins, direc_save, direc_data, lr_sched, rotation_range, flip, shear, class_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;31m# fit the model on the batches generated by datagen.flow()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     loss_history = model.fit_generator(\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/image_generators.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, train_dict, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0msave_to_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             save_format=save_format)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/image_generators.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_dict, image_data_generator, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format)\u001b[0m\n\u001b[1;32m    299\u001b[0m             raise ValueError('Training batches and labels should have the same'\n\u001b[1;32m    300\u001b[0m                              'length. Found X.shape: {} y.shape: {}'.format(\n\u001b[0;32m--> 301\u001b[0;31m                                  train_dict['X'].shape, train_dict['y'].shape))\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Training batches and labels should have the samelength. Found X.shape: (32, 512, 512, 8) y.shape: (1504881, 4)"
     ]
    }
   ],
   "source": [
    "train_model_on_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
