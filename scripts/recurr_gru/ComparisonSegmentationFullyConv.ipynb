{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Watershed Distance Transform for 2D Data\n",
    "---\n",
    "Implementation of papers:\n",
    "\n",
    "[Deep Watershed Transform for Instance Segmentation](http://openaccess.thecvf.com/content_cvpr_2017/papers/Bai_Deep_Watershed_Transform_CVPR_2017_paper.pdf)\n",
    "\n",
    "[Learn to segment single cells with deep distance estimator and deep cell detector](https://arxiv.org/abs/1803.10829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"/home/snn/deepcell-tf\")\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "\n",
    "from deepcell import losses\n",
    "import image_gen as image_gen\n",
    "from deepcell import image_generators\n",
    "from deepcell import model_zoo\n",
    "from deepcell.layers import TensorProduct, ReflectionPadding3D, DilatedMaxPool3D\n",
    "\n",
    "from deepcell.utils import train_utils\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.training import train_model_conv\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.layers import MaxPool3D\n",
    "from conv_gru_layer import ConvGRU2D\n",
    "from tensorflow.python.keras.layers import BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.python.keras.layers import Conv3D, ZeroPadding3D, ConvLSTM2D, Cropping3D\n",
    "from tensorflow.python.keras.layers import Input, Add, Concatenate, Flatten, Reshape\n",
    "from tensorflow.python.keras.engine.input_layer import InputLayer\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "from deepcell.layers import ImageNormalization2D, ImageNormalization3D\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Softmax\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Convert Trks data to npz\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "\n",
    "DATA_DIR = '/data/npz_data/tracking_benchmark_data'\n",
    "DATA_FILE = os.path.join(DATA_DIR, '3T3_HeLa_HEK_RAW_V2.trks')\n",
    "\n",
    "trks = load_trks(DATA_FILE)\n",
    "np.savez(os.path.join(DATA_DIR, '3T3_HeLa_HEK_RAW_V2.npz'), X=trks['X'], y=trks['y'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Crop and stack data to avoid OOM error\n",
    "\n",
    "DATA_DIR = '/data/npz_data/tracking_benchmark_data'\n",
    "DATA_FILE = os.path.join(DATA_DIR, '3T3_HeLa_HEK_RAW_V2.npz')\n",
    "\n",
    "training_data = np.load(DATA_FILE)\n",
    "X = training_data['X']\n",
    "y = training_data['y']\n",
    "\n",
    "X_stacked = np.concatenate((X[:, :, :108, :128, :], X[:, :, 108:, 128:,:]), axis=0)\n",
    "y_stacked = np.concatenate((y[:, :, :108, :128, :], y[:, :, 108:, 128:,:]), axis=0)\n",
    "\n",
    "print(' -\\nX.shape: {}\\ny.shape: {}'.format(X_stacked.shape, y_stacked.shape))\n",
    "\n",
    "np.savez(os.path.join(DATA_DIR, '3T3_HeLa_HEK_RAW_V2_stacked.npz'), X=X_stacked, y=y_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -\n",
      "X.shape: (642, 30, 135, 160, 1)\n",
      "y.shape: (642, 30, 135, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "# If DATA_FILE exists just run this cell\n",
    "\n",
    "from deepcell.utils.data_utils import get_data\n",
    "\n",
    "DATA_DIR = '/data/npz_data/tracking_benchmark_data'\n",
    "DATA_FILE = os.path.join(DATA_DIR, '3T3_HeLa_HEK_RAW_cropped.npz')\n",
    "# DATA_FILE = os.path.join(DATA_DIR, '3T3_HeLa_HEK_RAW_V2_stacked.npz')\n",
    "\n",
    "# Load Information for hardcoded image size training\n",
    "seed = 1\n",
    "test_size = .2\n",
    "train_dict, test_dict = get_data(DATA_FILE, seed=seed, test_size=test_size)\n",
    "X_train, y_train = train_dict['X'], train_dict['y']\n",
    "X_test, y_test = test_dict['X'], test_dict['y']\n",
    "\n",
    "print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up filepath constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up other required filepaths\n",
    "PREFIX = os.path.relpath(os.path.dirname(DATA_FILE), DATA_DIR)\n",
    "ROOT_DIR = '/data' # mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models', PREFIX))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs', PREFIX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define feature net models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature_net_3D is the gru analog of bn_feature_net_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_net_3D(receptive_field=61,\n",
    "                    n_frames=5,\n",
    "                    input_shape=(5, 256, 256, 1),\n",
    "                    n_features=3,\n",
    "                    n_channels=1,\n",
    "                    reg=1e-5,\n",
    "                    n_conv_filters=64,\n",
    "                    n_dense_filters=200,\n",
    "                    VGG_mode=False,\n",
    "                    init='he_normal',\n",
    "                    norm_method='std',\n",
    "                    location=False,\n",
    "                    dilated=False,\n",
    "                    padding=False,\n",
    "                    padding_mode='reflect',\n",
    "                    multires=False,\n",
    "                    include_top=True,\n",
    "                    gru=False,\n",
    "                    gru_kernel_size =3):\n",
    "    # Create layers list (x) to store all of the layers.\n",
    "    # We need to use the functional API to enable the multiresolution mode\n",
    "    x = []\n",
    "\n",
    "    win = (receptive_field - 1) // 2\n",
    "    win_z = (n_frames - 1) // 2\n",
    "\n",
    "    if dilated:\n",
    "        padding = True\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        time_axis = 2\n",
    "        row_axis = 3\n",
    "        col_axis = 4\n",
    "        if not dilated:\n",
    "            input_shape = (n_channels, n_frames, receptive_field, receptive_field)\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        time_axis = 1\n",
    "        row_axis = 2\n",
    "        col_axis = 3\n",
    "        if not dilated:\n",
    "            input_shape = (n_frames, receptive_field, receptive_field, n_channels)\n",
    "\n",
    "    x.append(Input(shape=input_shape))\n",
    "    x.append(ImageNormalization3D(norm_method=norm_method,\n",
    "                                  filter_size=receptive_field)(x[-1]))\n",
    "\n",
    "    if padding:\n",
    "        if padding_mode == 'reflect':\n",
    "            x.append(ReflectionPadding3D(padding=(win_z, win, win))(x[-1]))\n",
    "        elif padding_mode == 'zero':\n",
    "            x.append(ZeroPadding3D(padding=(win_z, win, win))(x[-1]))\n",
    "\n",
    "    if location:\n",
    "        x.append(Location3D(in_shape=tuple(x[-1].shape.as_list()[1:]))(x[-1]))\n",
    "        x.append(Concatenate(axis=channel_axis)([x[-2], x[-1]]))\n",
    "\n",
    "    layers_to_concat = []\n",
    "\n",
    "    rf_counter = receptive_field\n",
    "    block_counter = 0\n",
    "    d = 1\n",
    "\n",
    "    while rf_counter > 4:\n",
    "        filter_size = 3 if rf_counter % 2 == 0 else 4\n",
    "        x.append(Conv3D(n_conv_filters, (1, filter_size, filter_size),\n",
    "                        dilation_rate=(1, d, d), kernel_initializer=init,\n",
    "                        padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "        block_counter += 1\n",
    "        rf_counter -= filter_size - 1\n",
    "\n",
    "        if block_counter % 2 == 0:\n",
    "            if dilated:\n",
    "                x.append(DilatedMaxPool3D(dilation_rate=(1, d, d),\n",
    "                                          pool_size=(1, 2, 2))(x[-1]))\n",
    "                d *= 2\n",
    "            else:\n",
    "                x.append(MaxPool3D(pool_size=(1, 2, 2))(x[-1]))\n",
    "\n",
    "            if VGG_mode:\n",
    "                n_conv_filters *= 2\n",
    "\n",
    "            rf_counter = rf_counter // 2\n",
    "\n",
    "            if multires:\n",
    "                layers_to_concat.append(len(x) - 1)\n",
    "\n",
    "    if multires:\n",
    "        c = []\n",
    "        for l in layers_to_concat:\n",
    "            output_shape = x[l].get_shape().as_list()\n",
    "            target_shape = x[-1].get_shape().as_list()\n",
    "            time_crop = (0, 0)\n",
    "\n",
    "            row_crop = int(output_shape[row_axis] - target_shape[row_axis])\n",
    "\n",
    "            if row_crop % 2 == 0:\n",
    "                row_crop = (row_crop // 2, row_crop // 2)\n",
    "            else:\n",
    "                row_crop = (row_crop // 2, row_crop // 2 + 1)\n",
    "\n",
    "            col_crop = int(output_shape[col_axis] - target_shape[col_axis])\n",
    "\n",
    "            if col_crop % 2 == 0:\n",
    "                col_crop = (col_crop // 2, col_crop // 2)\n",
    "            else:\n",
    "                col_crop = (col_crop // 2, col_crop // 2 + 1)\n",
    "\n",
    "            cropping = (time_crop, row_crop, col_crop)\n",
    "\n",
    "            c.append(Cropping3D(cropping=cropping)(x[l]))\n",
    "        x.append(Concatenate(axis=channel_axis)(c))\n",
    "\n",
    "    x.append(Conv3D(n_dense_filters, (1, rf_counter, rf_counter),\n",
    "                    dilation_rate=(1, d, d), kernel_initializer=init,\n",
    "                    padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(Conv3D(n_dense_filters, (n_frames, 1, 1), dilation_rate=(1, d, d),\n",
    "                    kernel_initializer=init, padding='valid',\n",
    "                    kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "    \n",
    "    if gru is True:\n",
    "        x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=gru_kernel_size,\n",
    "                            padding='same', kernel_initializer=init, activation='relu',\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=gru_kernel_size+2,\n",
    "                            padding='same', kernel_initializer=init, activation='relu',\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    x.append(TensorProduct(n_dense_filters, kernel_initializer=init,\n",
    "                           kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(TensorProduct(n_features, kernel_initializer=init,\n",
    "                           kernel_regularizer=l2(reg))(x[-1]))\n",
    "\n",
    "    if not dilated:\n",
    "        x.append(Flatten()(x[-1]))\n",
    "\n",
    "    if include_top:\n",
    "        x.append(Softmax(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    model = Model(inputs=x[0], outputs=x[-1])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature_net_skip_3D is the gru analog of bn_feature_net_skip_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_net_skip_3D(receptive_field=61,\n",
    "                        input_shape=(5, 256, 256, 1),\n",
    "                        fgbg_model=None,\n",
    "                        gru=False,\n",
    "                        gru_kernel_size=3,\n",
    "                        last_only=True,\n",
    "                        n_skips=1,\n",
    "                        norm_method='whole_image',\n",
    "                        padding_mode='reflect',\n",
    "                        **kwargs):\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    inputs = Input(shape=input_shape)\n",
    "    img = ImageNormalization3D(norm_method=norm_method,\n",
    "                               filter_size=receptive_field)(inputs)\n",
    "\n",
    "    models = []\n",
    "    model_outputs = []\n",
    "\n",
    "    if fgbg_model is not None:\n",
    "        for layer in fgbg_model.layers:\n",
    "            layer.trainable = False\n",
    "        models.append(fgbg_model)\n",
    "        fgbg_output = fgbg_model(inputs)\n",
    "        if isinstance(fgbg_output, list):\n",
    "            fgbg_output = fgbg_output[-1]\n",
    "        model_outputs.append(fgbg_output)\n",
    "\n",
    "    for _ in range(n_skips + 1):\n",
    "        if model_outputs:\n",
    "            model_input = Concatenate(axis=channel_axis)([img, model_outputs[-1]])\n",
    "        else:\n",
    "            model_input = img\n",
    "\n",
    "        new_input_shape = model_input.get_shape().as_list()[1:]\n",
    "        models.append(feature_net_3D(receptive_field=receptive_field, \n",
    "                                     input_shape=new_input_shape, \n",
    "                                     norm_method=None, \n",
    "                                     dilated=True, \n",
    "                                     padding=True, \n",
    "                                     padding_mode=padding_mode, \n",
    "                                     gru=gru, \n",
    "                                     gru_kernel_size=gru_kernel_size, \n",
    "                                     **kwargs))\n",
    "        model_outputs.append(models[-1](model_input))\n",
    "\n",
    "    if last_only:\n",
    "        model = Model(inputs=inputs, outputs=model_outputs[-1])\n",
    "    elif fgbg_model is None:\n",
    "        model = Model(inputs=inputs, outputs=model_outputs)\n",
    "    else:\n",
    "        model = Model(inputs=inputs, outputs=model_outputs[1:])\n",
    "        \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator = image_generators.MovieDataGenerator\n",
    "\n",
    "datagen = DataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=False,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "datagen_val = DataGenerator(\n",
    "    rotation_range=0,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=0,\n",
    "    vertical_flip=0)\n",
    "\n",
    "\n",
    "train_data = datagen.flow(\n",
    "    train_dict,\n",
    "    skip=3,\n",
    "    seed=0,\n",
    "    batch_size=1,\n",
    "    transform='fgbg',\n",
    "    transform_kwargs={},\n",
    "    frames_per_batch=3)\n",
    "\n",
    "val_data = datagen_val.flow(\n",
    "    test_dict,\n",
    "    skip=3,\n",
    "    seed=0,\n",
    "    batch_size=1,\n",
    "    transform='fgbg',\n",
    "    transform_kwargs={},\n",
    "    frames_per_batch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(642, 30, 135, 160, 1)\n",
      "Image number: 456\n",
      "Frame number: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(train_data.x.shape)\n",
    "\n",
    "index = np.random.randint(low=0, high=train_data.x.shape[0])\n",
    "frame = np.random.randint(low=0, high=train_data.x.shape[1])\n",
    "print('Image number:', index)\n",
    "print('Frame number:', frame)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(10, 5), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(train_data.x[index, frame, ..., 0])\n",
    "ax[0].set_title('Source Image X')\n",
    "\n",
    "ax[1].imshow(train_data.y[index, frame, ..., 1])\n",
    "ax[1].set_title('Source Image Y')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "fgbg_model_name = 'trackingSEG_cropped_conv_fgbg_model'\n",
    "conv_model_name = 'trackingSEG_cropped_conv_watershed_model'\n",
    "\n",
    "n_epoch = 5  # Number of training epochs\n",
    "norm_method = 'whole_image'  # data normalization - `whole_image` for 3d conv\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# FC training settings\n",
    "n_skips = 3  # number of skip-connections (only for FC training)\n",
    "batch_size = 1  # FC training uses 1 image per batch\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'watershed'\n",
    "distance_bins = 4  # number of distance classes\n",
    "erosion_width = 1  # erode edges, improves segmentation when cells are close\n",
    "\n",
    "# 3D Settings\n",
    "frames_per_batch = 3\n",
    "\n",
    "# GRU Settings\n",
    "is_gru = False\n",
    "gru_kernel_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foreground Background Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Instantiate the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 135, 160,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d (ImageNor (None, 3, 135, 160,  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 3, 135, 160,  213570      image_normalization3d[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 135, 160,  0           image_normalization3d[0][0]      \n",
      "                                                                 model[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 3, 135, 160,  214594      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 135, 160,  0           image_normalization3d[0][0]      \n",
      "                                                                 model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 3, 135, 160,  214594      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 135, 160,  0           image_normalization3d[0][0]      \n",
      "                                                                 model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 3, 135, 160,  214594      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 857,352\n",
      "Trainable params: 852,744\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fgbg_model = feature_net_skip_3D(\n",
    "            n_features=2,  # segmentation mask (is_cell, is_not_cell)\n",
    "            receptive_field=receptive_field,\n",
    "            n_skips=n_skips,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=is_gru,\n",
    "            gru_kernel_size=gru_kernel_size,\n",
    "            input_shape=tuple([frames_per_batch] + list(train_dict['X'].shape[2:])),\n",
    "            last_only=False,\n",
    "            norm_method=norm_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Train the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (642, 30, 135, 160, 1)\n",
      "y_train shape: (642, 30, 135, 160, 1)\n",
      "X_test shape: (161, 30, 135, 160, 1)\n",
      "y_test shape: (161, 30, 135, 160, 1)\n",
      "Output Shape: (None, 3, 135, 160, 2)\n",
      "Number of Classes: 2\n",
      "Training on 1 GPUs\n",
      "Epoch 1/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.7067 - model_loss: 0.1737 - model_1_loss: 0.1658 - model_2_loss: 0.1641 - model_3_loss: 0.1564 - model_acc: 0.9234 - model_1_acc: 0.9266 - model_2_acc: 0.9266 - model_3_acc: 0.9310\n",
      "Epoch 00001: val_loss improved from inf to 0.50586, saving model to /data/models/trackingSEG_cropped_conv_fgbg_model.h5\n",
      "642/642 [==============================] - 366s 570ms/step - loss: 0.7059 - model_loss: 0.1735 - model_1_loss: 0.1656 - model_2_loss: 0.1639 - model_3_loss: 0.1562 - model_acc: 0.9235 - model_1_acc: 0.9267 - model_2_acc: 0.9267 - model_3_acc: 0.9311 - val_loss: 0.5059 - val_model_loss: 0.1220 - val_model_1_loss: 0.1187 - val_model_2_loss: 0.1111 - val_model_3_loss: 0.1072 - val_model_acc: 0.9666 - val_model_1_acc: 0.9611 - val_model_2_acc: 0.9614 - val_model_3_acc: 0.9633\n",
      "Epoch 2/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.4828 - model_loss: 0.1118 - model_1_loss: 0.1161 - model_2_loss: 0.1064 - model_3_loss: 0.1017 - model_acc: 0.9534 - model_1_acc: 0.9507 - model_2_acc: 0.9553 - model_3_acc: 0.9574\n",
      "Epoch 00002: val_loss improved from 0.50586 to 0.48646, saving model to /data/models/trackingSEG_cropped_conv_fgbg_model.h5\n",
      "642/642 [==============================] - 346s 538ms/step - loss: 0.4825 - model_loss: 0.1117 - model_1_loss: 0.1160 - model_2_loss: 0.1063 - model_3_loss: 0.1016 - model_acc: 0.9533 - model_1_acc: 0.9506 - model_2_acc: 0.9554 - model_3_acc: 0.9575 - val_loss: 0.4865 - val_model_loss: 0.1059 - val_model_1_loss: 0.1238 - val_model_2_loss: 0.1064 - val_model_3_loss: 0.1035 - val_model_acc: 0.9608 - val_model_1_acc: 0.9684 - val_model_2_acc: 0.9651 - val_model_3_acc: 0.9612\n",
      "Epoch 3/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.4724 - model_loss: 0.1098 - model_1_loss: 0.1076 - model_2_loss: 0.1051 - model_3_loss: 0.1030 - model_acc: 0.9539 - model_1_acc: 0.9545 - model_2_acc: 0.9560 - model_3_acc: 0.9561\n",
      "Epoch 00003: val_loss did not improve from 0.48646\n",
      "642/642 [==============================] - 345s 537ms/step - loss: 0.4724 - model_loss: 0.1098 - model_1_loss: 0.1076 - model_2_loss: 0.1051 - model_3_loss: 0.1030 - model_acc: 0.9540 - model_1_acc: 0.9545 - model_2_acc: 0.9560 - model_3_acc: 0.9561 - val_loss: 0.5035 - val_model_loss: 0.1164 - val_model_1_loss: 0.1218 - val_model_2_loss: 0.1159 - val_model_3_loss: 0.1025 - val_model_acc: 0.9501 - val_model_1_acc: 0.9660 - val_model_2_acc: 0.9592 - val_model_3_acc: 0.9579\n",
      "Epoch 4/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.4663 - model_loss: 0.1067 - model_1_loss: 0.1010 - model_2_loss: 0.1072 - model_3_loss: 0.1044 - model_acc: 0.9561 - model_1_acc: 0.9578 - model_2_acc: 0.9566 - model_3_acc: 0.9569\n",
      "Epoch 00004: val_loss improved from 0.48646 to 0.48053, saving model to /data/models/trackingSEG_cropped_conv_fgbg_model.h5\n",
      "642/642 [==============================] - 346s 539ms/step - loss: 0.4659 - model_loss: 0.1065 - model_1_loss: 0.1009 - model_2_loss: 0.1071 - model_3_loss: 0.1043 - model_acc: 0.9562 - model_1_acc: 0.9579 - model_2_acc: 0.9567 - model_3_acc: 0.9569 - val_loss: 0.4805 - val_model_loss: 0.1085 - val_model_1_loss: 0.1084 - val_model_2_loss: 0.1088 - val_model_3_loss: 0.1078 - val_model_acc: 0.9681 - val_model_1_acc: 0.9649 - val_model_2_acc: 0.9651 - val_model_3_acc: 0.9669\n",
      "Epoch 5/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 0.4716 - model_loss: 0.1057 - model_1_loss: 0.0988 - model_2_loss: 0.1066 - model_3_loss: 0.1133 - model_acc: 0.9566 - model_1_acc: 0.9587 - model_2_acc: 0.9585 - model_3_acc: 0.9545\n",
      "Epoch 00005: val_loss did not improve from 0.48053\n",
      "642/642 [==============================] - 344s 536ms/step - loss: 0.4719 - model_loss: 0.1057 - model_1_loss: 0.0989 - model_2_loss: 0.1066 - model_3_loss: 0.1133 - model_acc: 0.9566 - model_1_acc: 0.9586 - model_2_acc: 0.9585 - model_3_acc: 0.9545 - val_loss: 0.7730 - val_model_loss: 0.1608 - val_model_1_loss: 0.2361 - val_model_2_loss: 0.1921 - val_model_3_loss: 0.1367 - val_model_acc: 0.9589 - val_model_1_acc: 0.9645 - val_model_2_acc: 0.9659 - val_model_3_acc: 0.9699\n"
     ]
    }
   ],
   "source": [
    "from deepcell.training import train_model_conv\n",
    "\n",
    "fgbg_model = train_model_conv(\n",
    "        model=fgbg_model,\n",
    "        train_dict=train_dict,\n",
    "        test_dict=test_dict,\n",
    "        model_name=fgbg_model_name,\n",
    "        log_dir=LOG_DIR,\n",
    "        transform='fgbg',\n",
    "        optimizer=optimizer,\n",
    "        batch_size=batch_size,\n",
    "        frames_per_batch=frames_per_batch,\n",
    "        n_epoch=n_epoch,\n",
    "        model_dir=MODEL_DIR,\n",
    "        lr_sched=lr_sched,\n",
    "        rotation_range=180,\n",
    "        flip=True,\n",
    "        shear=False,\n",
    "        zoom_range=(0.8, 1.2))\n",
    "\n",
    "fgbg_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_model_name))\n",
    "fgbg_model.save_weights(fgbg_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed energy transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Load weights for fgbg model if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 3, 135, 160,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_15 (Image (None, 3, 135, 160,  0           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_15 (Model)                (None, 3, 135, 160,  213570      image_normalization3d_15[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 3, 135, 160,  0           image_normalization3d_15[0][0]   \n",
      "                                                                 model_15[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_16 (Model)                (None, 3, 135, 160,  214594      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 3, 135, 160,  0           image_normalization3d_15[0][0]   \n",
      "                                                                 model_16[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_17 (Model)                (None, 3, 135, 160,  214594      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 3, 135, 160,  0           image_normalization3d_15[0][0]   \n",
      "                                                                 model_17[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_18 (Model)                (None, 3, 135, 160,  214594      concatenate_11[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 857,352\n",
      "Trainable params: 852,744\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fgbg_model = feature_net_skip_3D(\n",
    "            n_features=2,  # segmentation mask (is_cell, is_not_cell)\n",
    "            receptive_field=receptive_field,\n",
    "            n_skips=n_skips,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=is_gru,\n",
    "            gru_kernel_size=gru_kernel_size,\n",
    "            input_shape=tuple([frames_per_batch] + list(train_dict['X'].shape[2:])),\n",
    "            last_only=False)\n",
    "\n",
    "fgbg_model.load_weights('/data/models/trackingSEG_cropped_conv_fgbg_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Instantiate the distance transform model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 3, 135, 160,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_5 (ImageN (None, 3, 135, 160,  0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 [(None, 3, 135, 160, 857352      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 135, 160,  0           image_normalization3d_5[0][0]    \n",
      "                                                                 model_4[1][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 3, 135, 160,  182084      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 135, 160,  0           image_normalization3d_5[0][0]    \n",
      "                                                                 model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_6 (Model)                 (None, 3, 135, 160,  183108      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 135, 160,  0           image_normalization3d_5[0][0]    \n",
      "                                                                 model_6[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_7 (Model)                 (None, 3, 135, 160,  183108      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 3, 135, 160,  0           image_normalization3d_5[0][0]    \n",
      "                                                                 model_7[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_8 (Model)                 (None, 3, 135, 160,  183108      concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,588,760\n",
      "Trainable params: 726,800\n",
      "Non-trainable params: 861,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from deepcell import model_zoo\n",
    "\n",
    "# watershed_model = model_zoo.bn_feature_net_skip_3D(\n",
    "#     fgbg_model=fgbg_model,\n",
    "#     receptive_field=receptive_field,\n",
    "#     n_skips=n_skips,\n",
    "#     n_features=distance_bins,\n",
    "#     n_frames=frames_per_batch,\n",
    "#     n_conv_filters=32,\n",
    "#     n_dense_filters=128,\n",
    "#     multires=False,\n",
    "#     last_only=False,\n",
    "#     input_shape=tuple([frames_per_batch] + list(X_train.shape[2:])),\n",
    "#     norm_method='whole_image')\n",
    "\n",
    "watershed_model = feature_net_skip_3D(\n",
    "    fgbg_model=fgbg_model,\n",
    "    receptive_field=receptive_field,\n",
    "    n_skips=n_skips,\n",
    "    n_features=distance_bins,  # (background edge, interior edge, cell interior, background)\n",
    "    n_frames=frames_per_batch,\n",
    "    n_conv_filters=32,\n",
    "    n_dense_filters=128,\n",
    "    gru=is_gru,\n",
    "    gru_kernel_size=gru_kernel_size,\n",
    "    multires=False,\n",
    "    last_only=False,\n",
    "    input_shape=tuple([frames_per_batch] + list(train_dict['X'].shape[2:])),\n",
    "    norm_method=norm_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Train the distance transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (642, 30, 135, 160, 1)\n",
      "y_train shape: (642, 30, 135, 160, 1)\n",
      "X_test shape: (161, 30, 135, 160, 1)\n",
      "y_test shape: (161, 30, 135, 160, 1)\n",
      "Output Shape: (None, 3, 135, 160, 4)\n",
      "Number of Classes: 4\n",
      "Training on 1 GPUs\n",
      "Epoch 1/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 3.2458 - model_5_loss: 0.8078 - model_6_loss: 0.7833 - model_7_loss: 0.7890 - model_8_loss: 0.7689 - model_5_acc: 0.8392 - model_6_acc: 0.8396 - model_7_acc: 0.8383 - model_8_acc: 0.8390\n",
      "Epoch 00001: val_loss improved from inf to 3.07554, saving model to /data/models/trackingSEG_cropped_conv_watershed_model.h5\n",
      "642/642 [==============================] - 397s 618ms/step - loss: 3.2445 - model_5_loss: 0.8076 - model_6_loss: 0.7830 - model_7_loss: 0.7886 - model_8_loss: 0.7686 - model_5_acc: 0.8394 - model_6_acc: 0.8397 - model_7_acc: 0.8384 - model_8_acc: 0.8392 - val_loss: 3.0755 - val_model_5_loss: 0.8408 - val_model_6_loss: 0.6780 - val_model_7_loss: 0.7599 - val_model_8_loss: 0.6999 - val_model_5_acc: 0.8770 - val_model_6_acc: 0.8874 - val_model_7_acc: 0.8877 - val_model_8_acc: 0.8819\n",
      "Epoch 2/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 2.7919 - model_5_loss: 0.6852 - model_6_loss: 0.6692 - model_7_loss: 0.6728 - model_8_loss: 0.6677 - model_5_acc: 0.8682 - model_6_acc: 0.8701 - model_7_acc: 0.8691 - model_8_acc: 0.8684\n",
      "Epoch 00002: val_loss improved from 3.07554 to 3.01062, saving model to /data/models/trackingSEG_cropped_conv_watershed_model.h5\n",
      "642/642 [==============================] - 374s 582ms/step - loss: 2.7925 - model_5_loss: 0.6853 - model_6_loss: 0.6693 - model_7_loss: 0.6729 - model_8_loss: 0.6678 - model_5_acc: 0.8682 - model_6_acc: 0.8702 - model_7_acc: 0.8692 - model_8_acc: 0.8684 - val_loss: 3.0106 - val_model_5_loss: 0.7416 - val_model_6_loss: 0.6765 - val_model_7_loss: 0.7473 - val_model_8_loss: 0.7480 - val_model_5_acc: 0.8004 - val_model_6_acc: 0.8196 - val_model_7_acc: 0.7919 - val_model_8_acc: 0.7715\n",
      "Epoch 3/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 2.7423 - model_5_loss: 0.6724 - model_6_loss: 0.6565 - model_7_loss: 0.6593 - model_8_loss: 0.6569 - model_5_acc: 0.8726 - model_6_acc: 0.8757 - model_7_acc: 0.8745 - model_8_acc: 0.8727\n",
      "Epoch 00003: val_loss improved from 3.01062 to 2.45896, saving model to /data/models/trackingSEG_cropped_conv_watershed_model.h5\n",
      "642/642 [==============================] - 375s 584ms/step - loss: 2.7415 - model_5_loss: 0.6722 - model_6_loss: 0.6563 - model_7_loss: 0.6590 - model_8_loss: 0.6567 - model_5_acc: 0.8727 - model_6_acc: 0.8758 - model_7_acc: 0.8745 - model_8_acc: 0.8728 - val_loss: 2.4590 - val_model_5_loss: 0.6011 - val_model_6_loss: 0.5860 - val_model_7_loss: 0.5816 - val_model_8_loss: 0.5929 - val_model_5_acc: 0.8782 - val_model_6_acc: 0.8857 - val_model_7_acc: 0.8788 - val_model_8_acc: 0.8869\n",
      "Epoch 4/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 2.6491 - model_5_loss: 0.6451 - model_6_loss: 0.6362 - model_7_loss: 0.6360 - model_8_loss: 0.6344 - model_5_acc: 0.8771 - model_6_acc: 0.8795 - model_7_acc: 0.8786 - model_8_acc: 0.8790\n",
      "Epoch 00004: val_loss did not improve from 2.45896\n",
      "642/642 [==============================] - 374s 583ms/step - loss: 2.6497 - model_5_loss: 0.6452 - model_6_loss: 0.6364 - model_7_loss: 0.6361 - model_8_loss: 0.6345 - model_5_acc: 0.8770 - model_6_acc: 0.8794 - model_7_acc: 0.8785 - model_8_acc: 0.8789 - val_loss: 2.5531 - val_model_5_loss: 0.6367 - val_model_6_loss: 0.6076 - val_model_7_loss: 0.6191 - val_model_8_loss: 0.5922 - val_model_5_acc: 0.8900 - val_model_6_acc: 0.8898 - val_model_7_acc: 0.8965 - val_model_8_acc: 0.8935\n",
      "Epoch 5/5\n",
      "641/642 [============================>.] - ETA: 0s - loss: 2.6166 - model_5_loss: 0.6394 - model_6_loss: 0.6262 - model_7_loss: 0.6294 - model_8_loss: 0.6240 - model_5_acc: 0.8787 - model_6_acc: 0.8816 - model_7_acc: 0.8806 - model_8_acc: 0.8813\n",
      "Epoch 00005: val_loss did not improve from 2.45896\n",
      "642/642 [==============================] - 377s 587ms/step - loss: 2.6163 - model_5_loss: 0.6393 - model_6_loss: 0.6262 - model_7_loss: 0.6293 - model_8_loss: 0.6240 - model_5_acc: 0.8788 - model_6_acc: 0.8817 - model_7_acc: 0.8807 - model_8_acc: 0.8814 - val_loss: 2.5523 - val_model_5_loss: 0.6285 - val_model_6_loss: 0.6063 - val_model_7_loss: 0.6050 - val_model_8_loss: 0.6149 - val_model_5_acc: 0.8917 - val_model_6_acc: 0.8950 - val_model_7_acc: 0.8906 - val_model_8_acc: 0.8941\n"
     ]
    }
   ],
   "source": [
    "watershed_model = train_model_conv(\n",
    "        model=watershed_model,\n",
    "        train_dict=train_dict,\n",
    "        test_dict=test_dict,\n",
    "        model_name=conv_model_name,\n",
    "        test_size=test_size,\n",
    "        seed=seed,\n",
    "        transform=transform,\n",
    "        distance_bins=distance_bins,\n",
    "        erosion_width=erosion_width,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=batch_size,\n",
    "        n_epoch=n_epoch,\n",
    "        frames_per_batch=frames_per_batch,\n",
    "        model_dir=MODEL_DIR,\n",
    "        lr_sched=lr_sched,\n",
    "        rotation_range=180,\n",
    "        flip=True,\n",
    "        shear=False,\n",
    "        zoom_range=(0.8, 1.2))\n",
    "\n",
    "watershed_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_model_name))\n",
    "watershed_model.save_weights(watershed_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model\n",
    "\n",
    "#### Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_61 (InputLayer)           (None, 30, 135, 160, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_60 (Image (None, 30, 135, 160, 0           input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_60 (Model)                (None, 30, 135, 160, 213570      image_normalization3d_60[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_60[0][0]   \n",
      "                                                                 model_60[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_61 (Model)                (None, 30, 135, 160, 214594      concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_60[0][0]   \n",
      "                                                                 model_61[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_62 (Model)                (None, 30, 135, 160, 214594      concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_60[0][0]   \n",
      "                                                                 model_62[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_63 (Model)                (None, 30, 135, 160, 214594      concatenate_41[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 857,352\n",
      "Trainable params: 852,744\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_66 (InputLayer)           (None, 30, 135, 160, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_65 (Image (None, 30, 135, 160, 0           input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_64 (Model)                [(None, 30, 135, 160 857352      input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_65[0][0]   \n",
      "                                                                 model_64[1][3]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_65 (Model)                (None, 30, 135, 160, 182084      concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_65[0][0]   \n",
      "                                                                 model_65[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_66 (Model)                (None, 30, 135, 160, 183108      concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_65[0][0]   \n",
      "                                                                 model_66[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_67 (Model)                (None, 30, 135, 160, 183108      concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_65[0][0]   \n",
      "                                                                 model_67[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_68 (Model)                (None, 30, 135, 160, 183108      concatenate_45[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,588,760\n",
      "Trainable params: 726,800\n",
      "Non-trainable params: 861,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "run_fgbg_model = feature_net_skip_3D(\n",
    "            n_features=2,  # segmentation mask (is_cell, is_not_cell)\n",
    "            receptive_field=receptive_field,\n",
    "            n_skips=n_skips,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=is_gru,\n",
    "            gru_kernel_size=gru_kernel_size,\n",
    "            input_shape=tuple(X_test.shape[1:]),\n",
    "            last_only=False,\n",
    "            norm_method=norm_method)\n",
    "\n",
    "run_fgbg_model.load_weights('/data/models/trackingSEG_cropped_conv_fgbg_model.h5')\n",
    "\n",
    "run_watershed_model = feature_net_skip_3D(\n",
    "                        fgbg_model=run_fgbg_model,\n",
    "                        receptive_field=receptive_field,\n",
    "                        n_skips=n_skips,\n",
    "                        n_features=distance_bins,\n",
    "                        n_frames=frames_per_batch,\n",
    "                        n_conv_filters=32,\n",
    "                        n_dense_filters=128,\n",
    "                        multires=False,\n",
    "                        last_only=False,\n",
    "                        input_shape=tuple(X_test.shape[1:]),\n",
    "                        norm_method=norm_method,\n",
    "                        gru=False,\n",
    "                        gru_kernel_size=3)\n",
    "\n",
    "run_watershed_model.load_weights('/data/models/trackingSEG_cropped_conv_watershed_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed transform shape: (6, 30, 135, 160, 4)\n",
      "segmentation mask shape: (6, 30, 135, 160, 2)\n"
     ]
    }
   ],
   "source": [
    "# make predictions on testing data\n",
    "test_images = run_watershed_model.predict(X_test[:6, :, :, :, :])[-1]\n",
    "test_images_fgbg = run_fgbg_model.predict(X_test[:6, :, :, :, :])[-1]\n",
    "\n",
    "print('watershed transform shape:', test_images.shape)\n",
    "print('segmentation mask shape:', test_images_fgbg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed argmax shape: (6, 30, 135, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "# Collapse predictions into semantic segmentation mask\n",
    "\n",
    "argmax_images = []\n",
    "for i in range(test_images.shape[0]):\n",
    "    max_image = np.argmax(test_images[i], axis=-1)\n",
    "    argmax_images.append(max_image)\n",
    "argmax_images = np.array(argmax_images)\n",
    "argmax_images = np.expand_dims(argmax_images, axis=-1)\n",
    "\n",
    "print('watershed argmax shape:', argmax_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold the foreground/background\n",
    "# and remove background from watershed transform\n",
    "threshold = 0.5\n",
    "fg_thresh = test_images_fgbg[..., 1] > threshold\n",
    "\n",
    "fg_thresh = np.expand_dims(fg_thresh.astype('int16'), axis=-1)\n",
    "argmax_images_post_fgbg = argmax_images * fg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply watershed method with the distance transform as seed\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import watershed\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "watershed_images = []\n",
    "for i in range(argmax_images_post_fgbg.shape[0]):\n",
    "    image = fg_thresh[i, ..., 0]\n",
    "    distance = argmax_images_post_fgbg[i, ..., 0]\n",
    "\n",
    "    local_maxi = peak_local_max(test_images[i, ..., -1], min_distance=15, \n",
    "                                exclude_border=False, indices=False, labels=image)\n",
    "\n",
    "    markers = label(local_maxi)\n",
    "    segments = watershed(-distance, markers, mask=image)\n",
    "    watershed_images.append(segments)\n",
    "\n",
    "watershed_images = np.array(watershed_images)\n",
    "watershed_images = remove_small_objects(watershed_images[:, :, :, :].astype('uint16'), min_size=400)\n",
    "watershed_images = np.expand_dims(watershed_images, axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image number: 3\n",
      "Frame: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = np.random.randint(low=0, high=6)\n",
    "frame = np.random.randint(low=0, high=X_test.shape[1])\n",
    "print('Image number:', index)\n",
    "print('Frame:', frame)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(15, 10), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(X_test[index, frame, ..., 0])\n",
    "ax[0].set_title('Source Image')\n",
    "\n",
    "ax[1].imshow(test_images_fgbg[index, frame, ..., 1])\n",
    "ax[1].set_title('Segmentation Prediction')\n",
    "\n",
    "ax[2].imshow(fg_thresh[index, frame, ..., 0], cmap='jet')\n",
    "ax[2].set_title('FGBG Threshold {}%'.format(threshold * 100))\n",
    "\n",
    "ax[3].imshow(argmax_images[index, frame, ..., 0], cmap='jet')\n",
    "ax[3].set_title('Distance Transform')\n",
    "\n",
    "ax[4].imshow(argmax_images_post_fgbg[index, frame, ..., 0], cmap='jet')\n",
    "ax[4].set_title('Distance Transform w/o Background')\n",
    "\n",
    "ax[5].imshow(watershed_images[index, frame, ..., 0], cmap='jet')\n",
    "ax[5].set_title('Watershed Segmentation')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model Iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Datasets\n",
    "\n",
    "###### For Deepcell Datasets\n",
    "\n",
    "# Define data to load (raw images from trk test files)\n",
    "RAW_BASE_DIR = '/data/npz_data/tracking_benchmark_data/test'\n",
    "\n",
    "raw_trks_3T3  = os.path.join(RAW_BASE_DIR, '3T3_NIH_test_BData.trks')\n",
    "raw_trks_HEK  = os.path.join(RAW_BASE_DIR, 'HEK293_generic_test_BData.trks')\n",
    "raw_trks_HeLa = os.path.join(RAW_BASE_DIR, 'HeLa_S3_test_BData.trks')\n",
    "raw_trks_RAW  = os.path.join(RAW_BASE_DIR, 'RAW264_generic_test_BData.trks')\n",
    "\n",
    "# raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa]\n",
    "raw_trks_files = [raw_trks_3T3, raw_trks_HEK, raw_trks_HeLa, raw_trks_RAW]\n",
    "\n",
    "# Define a base file name for the output\n",
    "BASE_NAME = 'batch_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           (None, 30, 154, 182, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_70 (Image (None, 30, 154, 182, 0           input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_70 (Model)                (None, 30, 154, 182, 213570      image_normalization3d_70[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 30, 154, 182, 0           image_normalization3d_70[0][0]   \n",
      "                                                                 model_70[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_71 (Model)                (None, 30, 154, 182, 214594      concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 30, 154, 182, 0           image_normalization3d_70[0][0]   \n",
      "                                                                 model_71[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_72 (Model)                (None, 30, 154, 182, 214594      concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 30, 154, 182, 0           image_normalization3d_70[0][0]   \n",
      "                                                                 model_72[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_73 (Model)                (None, 30, 154, 182, 214594      concatenate_48[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 857,352\n",
      "Trainable params: 852,744\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_76 (InputLayer)           (None, 30, 154, 182, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_75 (Image (None, 30, 154, 182, 0           input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_74 (Model)                [(None, 30, 154, 182 857352      input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 30, 154, 182, 0           image_normalization3d_75[0][0]   \n",
      "                                                                 model_74[1][3]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_75 (Model)                (None, 30, 154, 182, 182084      concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 30, 154, 182, 0           image_normalization3d_75[0][0]   \n",
      "                                                                 model_75[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_76 (Model)                (None, 30, 154, 182, 183108      concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 30, 154, 182, 0           image_normalization3d_75[0][0]   \n",
      "                                                                 model_76[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_77 (Model)                (None, 30, 154, 182, 183108      concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 30, 154, 182, 0           image_normalization3d_75[0][0]   \n",
      "                                                                 model_77[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_78 (Model)                (None, 30, 154, 182, 183108      concatenate_52[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,588,760\n",
      "Trainable params: 726,800\n",
      "Non-trainable params: 861,960\n",
      "__________________________________________________________________________________________________\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 15\n",
      "Number of predicted cells:\t 16\n",
      "\n",
      "Correct detections:  2\tRecall: 13.3333333333333339254522798000834882259368896484375%\n",
      "Incorrect detections: 14\tPrecision: 12.5%\n",
      "\n",
      "Gained detections: 12\tPerc Error: 48%\n",
      "Missed detections: 12\tPerc Error: 48%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 4%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.86621815523729595032165207157959230244159698486328125 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 8\n",
      "Number of predicted cells:\t 11\n",
      "\n",
      "Correct detections:  1\tRecall: 12.5%\n",
      "Incorrect detections: 10\tPrecision: 9.0909090909090917165258360910229384899139404296875%\n",
      "\n",
      "Gained detections: 10\tPerc Error: 58.82352941176470295658873510546982288360595703125%\n",
      "Missed detections: 7\tPerc Error: 41.17647058823529704341126489453017711639404296875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.87080020396985780006815502929384820163249969482421875 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 11\n",
      "Number of predicted cells:\t 17\n",
      "\n",
      "Correct detections:  2\tRecall: 18.181818181818183433051672182045876979827880859375%\n",
      "Incorrect detections: 15\tPrecision: 11.7647058823529420124032185412943363189697265625%\n",
      "\n",
      "Gained detections: 13\tPerc Error: 59.090909090909093492882675491273403167724609375%\n",
      "Missed detections: 8\tPerc Error: 36.36363636363636686610334436409175395965576171875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 4.54545454545454585826291804551146924495697021484375%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.89805952600740435176618348123156465590000152587890625 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 17\n",
      "Number of predicted cells:\t 21\n",
      "\n",
      "Correct detections:  4\tRecall: 23.529411764705884024806437082588672637939453125%\n",
      "Incorrect detections: 17\tPrecision: 19.047619047619047449870777199976146221160888671875%\n",
      "\n",
      "Gained detections: 15\tPerc Error: 53.5714285714285693984493263997137546539306640625%\n",
      "Missed detections: 12\tPerc Error: 42.85714285714285409767398959957063198089599609375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.571428571428571618895375650026835501194000244140625%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.90468725684072281989500652343849651515483856201171875 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 10\n",
      "Number of predicted cells:\t 9\n",
      "\n",
      "Correct detections:  3\tRecall: 30%\n",
      "Incorrect detections: 6\tPrecision: 33.33333333333333570180911920033395290374755859375%\n",
      "\n",
      "Gained detections: 6\tPerc Error: 46.15384615384615329958251095376908779144287109375%\n",
      "Missed detections: 7\tPerc Error: 53.84615384615384670041748904623091220855712890625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.88343950760279599254687354914494790136814117431640625 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 9\n",
      "Number of predicted cells:\t 10\n",
      "\n",
      "Correct detections:  1\tRecall: 11.111111111111110716365146799944341182708740234375%\n",
      "Incorrect detections: 9\tPrecision: 10%\n",
      "\n",
      "Gained detections: 9\tPerc Error: 52.94117647058823195038712583482265472412109375%\n",
      "Missed detections: 8\tPerc Error: 47.05882352941176804961287416517734527587890625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.84021107739156730698226738240919075906276702880859375 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 10\n",
      "Number of predicted cells:\t 11\n",
      "\n",
      "Correct detections:  3\tRecall: 30%\n",
      "Incorrect detections: 8\tPrecision: 27.27272727272727337322066887281835079193115234375%\n",
      "\n",
      "Gained detections: 8\tPerc Error: 53.33333333333333570180911920033395290374755859375%\n",
      "Missed detections: 7\tPerc Error: 46.66666666666666429819088079966604709625244140625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8464172750838308001419818538124673068523406982421875 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 9\n",
      "Number of predicted cells:\t 10\n",
      "\n",
      "Correct detections:  3\tRecall: 33.33333333333333570180911920033395290374755859375%\n",
      "Incorrect detections: 7\tPrecision: 30%\n",
      "\n",
      "Gained detections: 7\tPerc Error: 53.84615384615384670041748904623091220855712890625%\n",
      "Missed detections: 6\tPerc Error: 46.15384615384615329958251095376908779144287109375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.877352672994924365212909833644516766071319580078125 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 10\n",
      "Number of predicted cells:\t 12\n",
      "\n",
      "Correct detections:  3\tRecall: 30%\n",
      "Incorrect detections: 9\tPrecision: 25%\n",
      "\n",
      "Gained detections: 9\tPerc Error: 56.25%\n",
      "Missed detections: 7\tPerc Error: 43.75%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8779298671670898723817799691460095345973968505859375 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 13\n",
      "Number of predicted cells:\t 19\n",
      "\n",
      "Correct detections:  2\tRecall: 15.3846153846153850253131167846731841564178466796875%\n",
      "Incorrect detections: 17\tPrecision: 10.5263157894736849584660376422107219696044921875%\n",
      "\n",
      "Gained detections: 15\tPerc Error: 57.6923076923076934008349780924618244171142578125%\n",
      "Missed detections: 10\tPerc Error: 38.46153846153845989874753286130726337432861328125%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.846153846153846256328279196168296039104461669921875%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.72563246955574844943015477838343940675258636474609375 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 13\n",
      "Number of predicted cells:\t 13\n",
      "\n",
      "Correct detections:  3\tRecall: 23.076923076923076649791255476884543895721435546875%\n",
      "Incorrect detections: 10\tPrecision: 23.076923076923076649791255476884543895721435546875%\n",
      "\n",
      "Gained detections: 10\tPerc Error: 50%\n",
      "Missed detections: 10\tPerc Error: 50%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.87819603024975112504080243525095283985137939453125 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 14\n",
      "Number of predicted cells:\t 20\n",
      "\n",
      "Correct detections:  2\tRecall: 14.2857142857142864755815026001073420047760009765625%\n",
      "Incorrect detections: 18\tPrecision: 10%\n",
      "\n",
      "Gained detections: 16\tPerc Error: 57.14285714285714590232601040042936801910400390625%\n",
      "Missed detections: 11\tPerc Error: 39.28571428571428469922466319985687732696533203125%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.571428571428571618895375650026835501194000244140625%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.6858889821364344552279135314165614545345306396484375 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 13\n",
      "Number of predicted cells:\t 18\n",
      "\n",
      "Correct detections:  3\tRecall: 23.076923076923076649791255476884543895721435546875%\n",
      "Incorrect detections: 15\tPrecision: 16.666666666666667850904559600166976451873779296875%\n",
      "\n",
      "Gained detections: 15\tPerc Error: 60%\n",
      "Missed detections: 10\tPerc Error: 40%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8585482698147910429753437711042352020740509033203125 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 15\n",
      "Number of predicted cells:\t 25\n",
      "\n",
      "Correct detections:  3\tRecall: 20%\n",
      "Incorrect detections: 22\tPrecision: 12%\n",
      "\n",
      "Gained detections: 20\tPerc Error: 62.5%\n",
      "Missed detections: 11\tPerc Error: 34.375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.125%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.82478119100737945501577996765263378620147705078125 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 6\n",
      "Number of predicted cells:\t 9\n",
      "\n",
      "Correct detections:  1\tRecall: 16.666666666666667850904559600166976451873779296875%\n",
      "Incorrect detections: 8\tPrecision: 11.111111111111110716365146799944341182708740234375%\n",
      "\n",
      "Gained detections: 8\tPerc Error: 61.53846153846154010125246713869273662567138671875%\n",
      "Missed detections: 5\tPerc Error: 38.46153846153845989874753286130726337432861328125%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.84098113805674434839687592102563939988613128662109375 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 7\n",
      "Number of predicted cells:\t 8\n",
      "\n",
      "Correct detections:  1\tRecall: 14.2857142857142864755815026001073420047760009765625%\n",
      "Incorrect detections: 7\tPrecision: 12.5%\n",
      "\n",
      "Gained detections: 7\tPerc Error: 53.84615384615384670041748904623091220855712890625%\n",
      "Missed detections: 6\tPerc Error: 46.15384615384615329958251095376908779144287109375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.87488059877262080998860938052530400454998016357421875 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 13\n",
      "Number of predicted cells:\t 18\n",
      "\n",
      "Correct detections:  2\tRecall: 15.3846153846153850253131167846731841564178466796875%\n",
      "Incorrect detections: 16\tPrecision: 11.111111111111110716365146799944341182708740234375%\n",
      "\n",
      "Gained detections: 16\tPerc Error: 59.25925925925925952242323546670377254486083984375%\n",
      "Missed detections: 11\tPerc Error: 40.74074074074074047757676453329622745513916015625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8531698300107901644651064998470246791839599609375 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 12\n",
      "Number of predicted cells:\t 13\n",
      "\n",
      "Correct detections:  1\tRecall: 8.3333333333333339254522798000834882259368896484375%\n",
      "Incorrect detections: 12\tPrecision: 7.69230769230769251265655839233659207820892333984375%\n",
      "\n",
      "Gained detections: 9\tPerc Error: 47.36842105263158231309716938994824886322021484375%\n",
      "Missed detections: 8\tPerc Error: 42.10526315789473983386415056884288787841796875%\n",
      "Merges: 1\t\tPerc Error: 5.26315789473684247923301882110536098480224609375%\n",
      "Splits: 1\t\tPerc Error: 5.26315789473684247923301882110536098480224609375%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.80353574354953749558916342721204273402690887451171875 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 17\n",
      "Number of predicted cells:\t 19\n",
      "\n",
      "Correct detections:  3\tRecall: 17.64705882352941301860482781194150447845458984375%\n",
      "Incorrect detections: 16\tPrecision: 15.7894736842105256613422170630656182765960693359375%\n",
      "\n",
      "Gained detections: 16\tPerc Error: 53.33333333333333570180911920033395290374755859375%\n",
      "Missed detections: 14\tPerc Error: 46.66666666666666429819088079966604709625244140625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8740485645735087683050323903444223105907440185546875 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 11\n",
      "Number of predicted cells:\t 12\n",
      "\n",
      "Correct detections:  3\tRecall: 27.27272727272727337322066887281835079193115234375%\n",
      "Incorrect detections: 9\tPrecision: 25%\n",
      "\n",
      "Gained detections: 9\tPerc Error: 52.94117647058823195038712583482265472412109375%\n",
      "Missed detections: 8\tPerc Error: 47.05882352941176804961287416517734527587890625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8380734627109822643120651264325715601444244384765625 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 16\n",
      "Number of predicted cells:\t 19\n",
      "\n",
      "Correct detections:  2\tRecall: 12.5%\n",
      "Incorrect detections: 17\tPrecision: 10.5263157894736849584660376422107219696044921875%\n",
      "\n",
      "Gained detections: 13\tPerc Error: 48.14814814814814525334440986625850200653076171875%\n",
      "Missed detections: 12\tPerc Error: 44.4444444444444428654605871997773647308349609375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 2\t\tPerc Error: 7.40740740740740744030290443333797156810760498046875%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 2\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.86430359990756844279502502104151062667369842529296875 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 12\n",
      "Number of predicted cells:\t 16\n",
      "\n",
      "Correct detections:  2\tRecall: 16.666666666666667850904559600166976451873779296875%\n",
      "Incorrect detections: 14\tPrecision: 12.5%\n",
      "\n",
      "Gained detections: 14\tPerc Error: 58.33333333333333570180911920033395290374755859375%\n",
      "Missed detections: 10\tPerc Error: 41.66666666666666429819088079966604709625244140625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.81286176688132349976712021089042536914348602294921875 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 10\n",
      "Number of predicted cells:\t 16\n",
      "\n",
      "Correct detections:  1\tRecall: 10%\n",
      "Incorrect detections: 15\tPrecision: 6.25%\n",
      "\n",
      "Gained detections: 11\tPerc Error: 55%\n",
      "Missed detections: 7\tPerc Error: 35%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 2\t\tPerc Error: 10%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 2\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.87727629073804458403884609651868231594562530517578125 \n",
      "\n",
      "X_test.shape (1, 30, 154, 182, 1)\n",
      "watershed_images.shape (1, 30, 154, 182, 1)\n",
      "GT_image.shape (1, 30, 154, 182)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 17\n",
      "Number of predicted cells:\t 19\n",
      "\n",
      "Correct detections:  4\tRecall: 23.529411764705884024806437082588672637939453125%\n",
      "Incorrect detections: 15\tPrecision: 21.052631578947369916932075284421443939208984375%\n",
      "\n",
      "Gained detections: 15\tPerc Error: 53.5714285714285693984493263997137546539306640625%\n",
      "Missed detections: 13\tPerc Error: 46.4285714285714306015506736002862453460693359375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.80299455457817214831806040820083580911159515380859375 \n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_81 (InputLayer)           (None, 30, 135, 160, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_80 (Image (None, 30, 135, 160, 0           input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_80 (Model)                (None, 30, 135, 160, 213570      image_normalization3d_80[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_80[0][0]   \n",
      "                                                                 model_80[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_81 (Model)                (None, 30, 135, 160, 214594      concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_80[0][0]   \n",
      "                                                                 model_81[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_82 (Model)                (None, 30, 135, 160, 214594      concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_80[0][0]   \n",
      "                                                                 model_82[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_83 (Model)                (None, 30, 135, 160, 214594      concatenate_55[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 857,352\n",
      "Trainable params: 852,744\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_86 (InputLayer)           (None, 30, 135, 160, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_85 (Image (None, 30, 135, 160, 0           input_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_84 (Model)                [(None, 30, 135, 160 857352      input_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_85[0][0]   \n",
      "                                                                 model_84[1][3]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_85 (Model)                (None, 30, 135, 160, 182084      concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_85[0][0]   \n",
      "                                                                 model_85[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_86 (Model)                (None, 30, 135, 160, 183108      concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_85[0][0]   \n",
      "                                                                 model_86[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_87 (Model)                (None, 30, 135, 160, 183108      concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 30, 135, 160, 0           image_normalization3d_85[0][0]   \n",
      "                                                                 model_87[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_88 (Model)                (None, 30, 135, 160, 183108      concatenate_59[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,588,760\n",
      "Trainable params: 726,800\n",
      "Non-trainable params: 861,960\n",
      "__________________________________________________________________________________________________\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 26\n",
      "Number of predicted cells:\t 23\n",
      "\n",
      "Correct detections:  3\tRecall: 11.5384615384615383248956277384422719478607177734375%\n",
      "Incorrect detections: 20\tPrecision: 13.0434782608695645222951497999019920825958251953125%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 43.58974358974359120111330412328243255615234375%\n",
      "Missed detections: 20\tPerc Error: 51.2820512820512846019482822157442569732666015625%\n",
      "Merges: 1\t\tPerc Error: 2.564102564102564318915256080799736082553863525390625%\n",
      "Splits: 1\t\tPerc Error: 2.564102564102564318915256080799736082553863525390625%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8836459227262432047922402489348314702510833740234375 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 28\n",
      "Number of predicted cells:\t 22\n",
      "\n",
      "Correct detections:  4\tRecall: 14.2857142857142864755815026001073420047760009765625%\n",
      "Incorrect detections: 18\tPrecision: 18.181818181818183433051672182045876979827880859375%\n",
      "\n",
      "Gained detections: 16\tPerc Error: 42.10526315789473983386415056884288787841796875%\n",
      "Missed detections: 21\tPerc Error: 55.26315789473684247923301882110536098480224609375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 1\t\tPerc Error: 2.631578947368421239616509410552680492401123046875%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 3\n",
      "Predicted detections involved in catastrophes: 2 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.870597714981403925094127771444618701934814453125 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 19\n",
      "Number of predicted cells:\t 21\n",
      "\n",
      "Correct detections:  5\tRecall: 26.315789473684208843451415305025875568389892578125%\n",
      "Incorrect detections: 16\tPrecision: 23.8095238095238102005168912000954151153564453125%\n",
      "\n",
      "Gained detections: 13\tPerc Error: 48.14814814814814525334440986625850200653076171875%\n",
      "Missed detections: 13\tPerc Error: 48.14814814814814525334440986625850200653076171875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.703703703703703720151452216668985784053802490234375%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 2\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.92021278253363292254363159372587688267230987548828125 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 20\n",
      "Number of predicted cells:\t 20\n",
      "\n",
      "Correct detections:  5\tRecall: 25%\n",
      "Incorrect detections: 15\tPrecision: 25%\n",
      "\n",
      "Gained detections: 15\tPerc Error: 50%\n",
      "Missed detections: 15\tPerc Error: 50%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.89485488276588409650713629162055440247058868408203125 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 27\n",
      "Number of predicted cells:\t 21\n",
      "\n",
      "Correct detections:  4\tRecall: 14.8148148148148148806058088666759431362152099609375%\n",
      "Incorrect detections: 17\tPrecision: 19.047619047619047449870777199976146221160888671875%\n",
      "\n",
      "Gained detections: 15\tPerc Error: 40.54054054054054034850196330808103084564208984375%\n",
      "Missed detections: 21\tPerc Error: 56.7567567567567579089882201515138149261474609375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 1\t\tPerc Error: 2.70270270270270263068823624053038656711578369140625%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 2\n",
      "Predicted detections involved in catastrophes: 2 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8655419575455434166855184230371378362178802490234375 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 22\n",
      "Number of predicted cells:\t 22\n",
      "\n",
      "Correct detections:  6\tRecall: 27.27272727272727337322066887281835079193115234375%\n",
      "Incorrect detections: 16\tPrecision: 27.27272727272727337322066887281835079193115234375%\n",
      "\n",
      "Gained detections: 14\tPerc Error: 46.66666666666666429819088079966604709625244140625%\n",
      "Missed detections: 15\tPerc Error: 50%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.333333333333333481363069950020872056484222412109375%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8611091369957122321210363224963657557964324951171875 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 19\n",
      "Number of predicted cells:\t 18\n",
      "\n",
      "Correct detections:  2\tRecall: 10.5263157894736849584660376422107219696044921875%\n",
      "Incorrect detections: 16\tPrecision: 11.111111111111110716365146799944341182708740234375%\n",
      "\n",
      "Gained detections: 12\tPerc Error: 42.85714285714285409767398959957063198089599609375%\n",
      "Missed detections: 14\tPerc Error: 50%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.571428571428571618895375650026835501194000244140625%\n",
      "Catastrophes: 1\t\tPerc Error: 3.571428571428571618895375650026835501194000244140625%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 2\n",
      "Predicted detections involved in catastrophes: 2 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.88778712059064812667230626175296492874622344970703125 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 19\n",
      "Number of predicted cells:\t 20\n",
      "\n",
      "Correct detections:  4\tRecall: 21.052631578947369916932075284421443939208984375%\n",
      "Incorrect detections: 16\tPrecision: 20%\n",
      "\n",
      "Gained detections: 13\tPerc Error: 48.14814814814814525334440986625850200653076171875%\n",
      "Missed detections: 12\tPerc Error: 44.4444444444444428654605871997773647308349609375%\n",
      "Merges: 1\t\tPerc Error: 3.703703703703703720151452216668985784053802490234375%\n",
      "Splits: 1\t\tPerc Error: 3.703703703703703720151452216668985784053802490234375%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8241423486152401611803952619084157049655914306640625 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 24\n",
      "Number of predicted cells:\t 29\n",
      "\n",
      "Correct detections:  1\tRecall: 4.16666666666666696272613990004174411296844482421875%\n",
      "Incorrect detections: 28\tPrecision: 3.44827586206896530285348489996977150440216064453125%\n",
      "\n",
      "Gained detections: 22\tPerc Error: 51.16279069767441711746869259513914585113525390625%\n",
      "Missed detections: 18\tPerc Error: 41.860465116279073072291794233024120330810546875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 2\t\tPerc Error: 4.65116279069767468712370828143320977687835693359375%\n",
      "Catastrophes: 1\t\tPerc Error: 2.325581395348837343561854140716604888439178466796875%\n",
      "\n",
      "Gained detections from splits: 2\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 3\n",
      "Predicted detections involved in catastrophes: 2 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.87955866101030266701599202860961668193340301513671875 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 21\n",
      "Number of predicted cells:\t 20\n",
      "\n",
      "Correct detections:  2\tRecall: 9.5238095238095237249353885999880731105804443359375%\n",
      "Incorrect detections: 18\tPrecision: 10%\n",
      "\n",
      "Gained detections: 16\tPerc Error: 45.71428571428571530077533680014312267303466796875%\n",
      "Missed detections: 18\tPerc Error: 51.4285714285714306015506736002862453460693359375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 2.857142857142857206298458550008945167064666748046875%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.85598165030094508498592631440260447561740875244140625 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 19\n",
      "Number of predicted cells:\t 21\n",
      "\n",
      "Correct detections:  3\tRecall: 15.7894736842105256613422170630656182765960693359375%\n",
      "Incorrect detections: 18\tPrecision: 14.2857142857142864755815026001073420047760009765625%\n",
      "\n",
      "Gained detections: 16\tPerc Error: 50%\n",
      "Missed detections: 15\tPerc Error: 46.875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.125%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8749432609381371239720692756236530840396881103515625 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 19\n",
      "Number of predicted cells:\t 27\n",
      "\n",
      "Correct detections:  3\tRecall: 15.7894736842105256613422170630656182765960693359375%\n",
      "Incorrect detections: 24\tPrecision: 11.111111111111110716365146799944341182708740234375%\n",
      "\n",
      "Gained detections: 14\tPerc Error: 48.27586206896551601630562799982726573944091796875%\n",
      "Missed detections: 11\tPerc Error: 37.9310344827586192195667535997927188873291015625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 3\t\tPerc Error: 10.34482758620689679673887440003454685211181640625%\n",
      "Catastrophes: 1\t\tPerc Error: 3.44827586206896530285348489996977150440216064453125%\n",
      "\n",
      "Gained detections from splits: 3\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 2\n",
      "Predicted detections involved in catastrophes: 4 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.89438727430359232783985135029070079326629638671875 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 17\n",
      "Number of predicted cells:\t 16\n",
      "\n",
      "Correct detections:  4\tRecall: 23.529411764705884024806437082588672637939453125%\n",
      "Incorrect detections: 12\tPrecision: 25%\n",
      "\n",
      "Gained detections: 12\tPerc Error: 48%\n",
      "Missed detections: 13\tPerc Error: 52%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.84526334530592028837503448812640272080898284912109375 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 27\n",
      "Number of predicted cells:\t 22\n",
      "\n",
      "Correct detections:  6\tRecall: 22.22222222222222143273029359988868236541748046875%\n",
      "Incorrect detections: 16\tPrecision: 27.27272727272727337322066887281835079193115234375%\n",
      "\n",
      "Gained detections: 16\tPerc Error: 43.2432432432432420910117798484861850738525390625%\n",
      "Missed detections: 21\tPerc Error: 56.7567567567567579089882201515138149261474609375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.85505986867516414751122511006542481482028961181640625 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 24\n",
      "Number of predicted cells:\t 23\n",
      "\n",
      "Correct detections:  4\tRecall: 16.666666666666667850904559600166976451873779296875%\n",
      "Incorrect detections: 19\tPrecision: 17.39130434782608602972686639986932277679443359375%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 45.94594594594594383352159638889133930206298828125%\n",
      "Missed detections: 19\tPerc Error: 51.3513513513513544239685870707035064697265625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 2.70270270270270263068823624053038656711578369140625%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8622789897919946877635766213643364608287811279296875 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 27\n",
      "Number of predicted cells:\t 24\n",
      "\n",
      "Correct detections:  4\tRecall: 14.8148148148148148806058088666759431362152099609375%\n",
      "Incorrect detections: 20\tPrecision: 16.666666666666667850904559600166976451873779296875%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 43.58974358974359120111330412328243255615234375%\n",
      "Missed detections: 20\tPerc Error: 51.2820512820512846019482822157442569732666015625%\n",
      "Merges: 1\t\tPerc Error: 2.564102564102564318915256080799736082553863525390625%\n",
      "Splits: 1\t\tPerc Error: 2.564102564102564318915256080799736082553863525390625%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.88820485728048226281572397056152112782001495361328125 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 22\n",
      "Number of predicted cells:\t 26\n",
      "\n",
      "Correct detections:  6\tRecall: 27.27272727272727337322066887281835079193115234375%\n",
      "Incorrect detections: 20\tPrecision: 23.076923076923076649791255476884543895721435546875%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 53.125%\n",
      "Missed detections: 13\tPerc Error: 40.625%\n",
      "Merges: 1\t\tPerc Error: 3.125%\n",
      "Splits: 1\t\tPerc Error: 3.125%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8822623961356139687950417282991111278533935546875 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 26\n",
      "Number of predicted cells:\t 23\n",
      "\n",
      "Correct detections:  1\tRecall: 3.846153846153846256328279196168296039104461669921875%\n",
      "Incorrect detections: 22\tPrecision: 4.3478260869565215074317165999673306941986083984375%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 42.5%\n",
      "Missed detections: 20\tPerc Error: 50%\n",
      "Merges: 1\t\tPerc Error: 2.5%\n",
      "Splits: 1\t\tPerc Error: 2.5%\n",
      "Catastrophes: 1\t\tPerc Error: 2.5%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 2\n",
      "Predicted detections involved in catastrophes: 2 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.89718106438233513610924774184240959584712982177734375 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 22\n",
      "Number of predicted cells:\t 21\n",
      "\n",
      "Correct detections:  3\tRecall: 13.636363636363636686610334436409175395965576171875%\n",
      "Incorrect detections: 18\tPrecision: 14.2857142857142864755815026001073420047760009765625%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 48.5714285714285693984493263997137546539306640625%\n",
      "Missed detections: 17\tPerc Error: 48.5714285714285693984493263997137546539306640625%\n",
      "Merges: 1\t\tPerc Error: 2.857142857142857206298458550008945167064666748046875%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8622455910438457937772227523964829742908477783203125 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 21\n",
      "Number of predicted cells:\t 26\n",
      "\n",
      "Correct detections:  5\tRecall: 23.8095238095238102005168912000954151153564453125%\n",
      "Incorrect detections: 21\tPrecision: 19.230769230769229949373766430653631687164306640625%\n",
      "\n",
      "Gained detections: 18\tPerc Error: 54.5454545454545467464413377456367015838623046875%\n",
      "Missed detections: 13\tPerc Error: 39.3939393939393909249702119268476963043212890625%\n",
      "Merges: 1\t\tPerc Error: 3.03030303030303027611580546363256871700286865234375%\n",
      "Splits: 1\t\tPerc Error: 3.03030303030303027611580546363256871700286865234375%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.87581737084458044506618534796871244907379150390625 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 24\n",
      "Number of predicted cells:\t 22\n",
      "\n",
      "Correct detections:  6\tRecall: 25%\n",
      "Incorrect detections: 16\tPrecision: 27.27272727272727337322066887281835079193115234375%\n",
      "\n",
      "Gained detections: 14\tPerc Error: 43.75%\n",
      "Missed detections: 17\tPerc Error: 53.125%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.125%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.86454835307381772135926212285994552075862884521484375 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 22\n",
      "Number of predicted cells:\t 19\n",
      "\n",
      "Correct detections:  5\tRecall: 22.72727272727272662677933112718164920806884765625%\n",
      "Incorrect detections: 14\tPrecision: 26.315789473684208843451415305025875568389892578125%\n",
      "\n",
      "Gained detections: 14\tPerc Error: 45.16129032258064768257099785842001438140869140625%\n",
      "Missed detections: 17\tPerc Error: 54.83870967741935231742900214157998561859130859375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.87082052181507740851174048657412640750408172607421875 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 18\n",
      "Number of predicted cells:\t 22\n",
      "\n",
      "Correct detections:  3\tRecall: 16.666666666666667850904559600166976451873779296875%\n",
      "Incorrect detections: 19\tPrecision: 13.636363636363636686610334436409175395965576171875%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 53.125%\n",
      "Missed detections: 14\tPerc Error: 43.75%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.125%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.89635940298965477435189086463651619851589202880859375 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 16\n",
      "Number of predicted cells:\t 16\n",
      "\n",
      "Correct detections:  3\tRecall: 18.75%\n",
      "Incorrect detections: 13\tPrecision: 18.75%\n",
      "\n",
      "Gained detections: 11\tPerc Error: 47.82608695652174191081940080039203166961669921875%\n",
      "Missed detections: 11\tPerc Error: 47.82608695652174191081940080039203166961669921875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 1\t\tPerc Error: 4.3478260869565215074317165999673306941986083984375%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 2\n",
      "Predicted detections involved in catastrophes: 2 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.89615603856353320821881425217725336551666259765625 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 24\n",
      "Number of predicted cells:\t 23\n",
      "\n",
      "Correct detections:  6\tRecall: 25%\n",
      "Incorrect detections: 17\tPrecision: 26.086956521739129044590299599803984165191650390625%\n",
      "\n",
      "Gained detections: 16\tPerc Error: 48.4848484848484844178528874181210994720458984375%\n",
      "Missed detections: 16\tPerc Error: 48.4848484848484844178528874181210994720458984375%\n",
      "Merges: 1\t\tPerc Error: 3.03030303030303027611580546363256871700286865234375%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.883550577102820700048368962598033249378204345703125 \n",
      "\n",
      "X_test.shape (1, 30, 135, 160, 1)\n",
      "watershed_images.shape (1, 30, 135, 160, 1)\n",
      "GT_image.shape (1, 30, 135, 160)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 32\n",
      "Number of predicted cells:\t 21\n",
      "\n",
      "Correct detections:  2\tRecall: 6.25%\n",
      "Incorrect detections: 19\tPrecision: 9.5238095238095237249353885999880731105804443359375%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 40.47619047619047449870777199976146221160888671875%\n",
      "Missed detections: 23\tPerc Error: 54.76190476190475919793243519961833953857421875%\n",
      "Merges: 2\t\tPerc Error: 4.76190476190476186246769429999403655529022216796875%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 5\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.88410364356841719679636071305139921605587005615234375 \n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_91 (InputLayer)           (None, 40, 216, 256, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_90 (Image (None, 40, 216, 256, 0           input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_90 (Model)                (None, 40, 216, 256, 213570      image_normalization3d_90[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_90[0][0]   \n",
      "                                                                 model_90[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_91 (Model)                (None, 40, 216, 256, 214594      concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_90[0][0]   \n",
      "                                                                 model_91[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_92 (Model)                (None, 40, 216, 256, 214594      concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_90[0][0]   \n",
      "                                                                 model_92[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_93 (Model)                (None, 40, 216, 256, 214594      concatenate_62[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 857,352\n",
      "Trainable params: 852,744\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_96 (InputLayer)           (None, 40, 216, 256, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_95 (Image (None, 40, 216, 256, 0           input_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_94 (Model)                [(None, 40, 216, 256 857352      input_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_95[0][0]   \n",
      "                                                                 model_94[1][3]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_95 (Model)                (None, 40, 216, 256, 182084      concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_95[0][0]   \n",
      "                                                                 model_95[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_96 (Model)                (None, 40, 216, 256, 183108      concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_95[0][0]   \n",
      "                                                                 model_96[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_97 (Model)                (None, 40, 216, 256, 183108      concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_95[0][0]   \n",
      "                                                                 model_97[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_98 (Model)                (None, 40, 216, 256, 183108      concatenate_66[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,588,760\n",
      "Trainable params: 726,800\n",
      "Non-trainable params: 861,960\n",
      "__________________________________________________________________________________________________\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 10\n",
      "Number of predicted cells:\t 12\n",
      "\n",
      "Correct detections:  1\tRecall: 10%\n",
      "Incorrect detections: 11\tPrecision: 8.3333333333333339254522798000834882259368896484375%\n",
      "\n",
      "Gained detections: 9\tPerc Error: 50%\n",
      "Missed detections: 8\tPerc Error: 44.4444444444444428654605871997773647308349609375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 5.5555555555555553581825733999721705913543701171875%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.69099311560542175936205921971122734248638153076171875 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 14\n",
      "Number of predicted cells:\t 24\n",
      "\n",
      "Correct detections:  1\tRecall: 7.14285714285714323779075130005367100238800048828125%\n",
      "Incorrect detections: 23\tPrecision: 4.16666666666666696272613990004174411296844482421875%\n",
      "\n",
      "Gained detections: 19\tPerc Error: 59.375%\n",
      "Missed detections: 11\tPerc Error: 34.375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 2\t\tPerc Error: 6.25%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 2\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.779516280369727088128684044932015240192413330078125 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 9\n",
      "Number of predicted cells:\t 13\n",
      "\n",
      "Correct detections:  1\tRecall: 11.111111111111110716365146799944341182708740234375%\n",
      "Incorrect detections: 12\tPrecision: 7.69230769230769251265655839233659207820892333984375%\n",
      "\n",
      "Gained detections: 12\tPerc Error: 60%\n",
      "Missed detections: 8\tPerc Error: 40%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8433193161238834445470047285198234021663665771484375 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 10\n",
      "Number of predicted cells:\t 18\n",
      "\n",
      "Correct detections:  0\tRecall: 0%\n",
      "Incorrect detections: 18\tPrecision: 0%\n",
      "\n",
      "Gained detections: 18\tPerc Error: 64.2857142857142918046520208008587360382080078125%\n",
      "Missed detections: 10\tPerc Error: 35.71428571428571530077533680014312267303466796875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8381989783836811813699796402943320572376251220703125 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 21\n",
      "Number of predicted cells:\t 26\n",
      "\n",
      "Correct detections:  3\tRecall: 14.2857142857142864755815026001073420047760009765625%\n",
      "Incorrect detections: 23\tPrecision: 11.5384615384615383248956277384422719478607177734375%\n",
      "\n",
      "Gained detections: 23\tPerc Error: 56.097560975609752631498849950730800628662109375%\n",
      "Missed detections: 18\tPerc Error: 43.902439024390247368501150049269199371337890625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.63676373796957463913059882543166168034076690673828125 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 6\n",
      "Number of predicted cells:\t 8\n",
      "\n",
      "Correct detections:  0\tRecall: 0%\n",
      "Incorrect detections: 8\tPrecision: 0%\n",
      "\n",
      "Gained detections: 6\tPerc Error: 50%\n",
      "Missed detections: 5\tPerc Error: 41.66666666666666429819088079966604709625244140625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 8.3333333333333339254522798000834882259368896484375%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.83364654727688114466133129099034704267978668212890625 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 8\n",
      "Number of predicted cells:\t 20\n",
      "\n",
      "Correct detections:  0\tRecall: 0%\n",
      "Incorrect detections: 20\tPrecision: 0%\n",
      "\n",
      "Gained detections: 18\tPerc Error: 69.23076923076922639666008763015270233154296875%\n",
      "Missed detections: 7\tPerc Error: 26.923076923076923350208744523115456104278564453125%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.846153846153846256328279196168296039104461669921875%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.80287175682798739284606881483341567218303680419921875 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 21\n",
      "Number of predicted cells:\t 29\n",
      "\n",
      "Correct detections:  5\tRecall: 23.8095238095238102005168912000954151153564453125%\n",
      "Incorrect detections: 24\tPrecision: 17.241379310344829178802683600224554538726806640625%\n",
      "\n",
      "Gained detections: 24\tPerc Error: 60%\n",
      "Missed detections: 16\tPerc Error: 40%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8650700395814869825272808157023973762989044189453125 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2\n",
      "Number of predicted cells:\t 5\n",
      "\n",
      "Correct detections:  0\tRecall: 0%\n",
      "Incorrect detections: 5\tPrecision: 0%\n",
      "\n",
      "Gained detections: 5\tPerc Error: 71.4285714285714306015506736002862453460693359375%\n",
      "Missed detections: 2\tPerc Error: 28.571428571428572951163005200214684009552001953125%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8512883609776873417018805412226356565952301025390625 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 11\n",
      "Number of predicted cells:\t 23\n",
      "\n",
      "Correct detections:  1\tRecall: 9.0909090909090917165258360910229384899139404296875%\n",
      "Incorrect detections: 22\tPrecision: 4.3478260869565215074317165999673306941986083984375%\n",
      "\n",
      "Gained detections: 22\tPerc Error: 68.75%\n",
      "Missed detections: 10\tPerc Error: 31.25%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.86601770731933436220373323521926067769527435302734375 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 9\n",
      "Number of predicted cells:\t 14\n",
      "\n",
      "Correct detections:  0\tRecall: 0%\n",
      "Incorrect detections: 14\tPrecision: 0%\n",
      "\n",
      "Gained detections: 10\tPerc Error: 52.63157894736841768690283061005175113677978515625%\n",
      "Missed detections: 7\tPerc Error: 36.84210526315789735463113174773752689361572265625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 2\t\tPerc Error: 10.5263157894736849584660376422107219696044921875%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 2\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.84206978389610964708111850995919667184352874755859375 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 8\n",
      "Number of predicted cells:\t 9\n",
      "\n",
      "Correct detections:  1\tRecall: 12.5%\n",
      "Incorrect detections: 8\tPrecision: 11.111111111111110716365146799944341182708740234375%\n",
      "\n",
      "Gained detections: 8\tPerc Error: 53.33333333333333570180911920033395290374755859375%\n",
      "Missed detections: 7\tPerc Error: 46.66666666666666429819088079966604709625244140625%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8189765834896183260838142814463935792446136474609375 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 5\n",
      "Number of predicted cells:\t 8\n",
      "\n",
      "Correct detections:  0\tRecall: 0%\n",
      "Incorrect detections: 8\tPrecision: 0%\n",
      "\n",
      "Gained detections: 8\tPerc Error: 61.53846153846154010125246713869273662567138671875%\n",
      "Missed detections: 5\tPerc Error: 38.46153846153845989874753286130726337432861328125%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.81814813834713806528498025727458298206329345703125 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 7\n",
      "Number of predicted cells:\t 10\n",
      "\n",
      "Correct detections:  6\tRecall: 85.7142857142857081953479791991412639617919921875%\n",
      "Incorrect detections: 4\tPrecision: 60%\n",
      "\n",
      "Gained detections: 4\tPerc Error: 80%\n",
      "Missed detections: 1\tPerc Error: 20%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.82783832586334760161861368032987229526042938232421875 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 4\n",
      "Number of predicted cells:\t 7\n",
      "\n",
      "Correct detections:  2\tRecall: 50%\n",
      "Incorrect detections: 5\tPrecision: 28.571428571428572951163005200214684009552001953125%\n",
      "\n",
      "Gained detections: 5\tPerc Error: 71.4285714285714306015506736002862453460693359375%\n",
      "Missed detections: 2\tPerc Error: 28.571428571428572951163005200214684009552001953125%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.88360219819180996214669221444637514650821685791015625 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 16\n",
      "Number of predicted cells:\t 22\n",
      "\n",
      "Correct detections:  5\tRecall: 31.25%\n",
      "Incorrect detections: 17\tPrecision: 22.72727272727272662677933112718164920806884765625%\n",
      "\n",
      "Gained detections: 15\tPerc Error: 57.6923076923076934008349780924618244171142578125%\n",
      "Missed detections: 10\tPerc Error: 38.46153846153845989874753286130726337432861328125%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.846153846153846256328279196168296039104461669921875%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.85080404018548072553329575384850613772869110107421875 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 6\n",
      "Number of predicted cells:\t 12\n",
      "\n",
      "Correct detections:  1\tRecall: 16.666666666666667850904559600166976451873779296875%\n",
      "Incorrect detections: 11\tPrecision: 8.3333333333333339254522798000834882259368896484375%\n",
      "\n",
      "Gained detections: 11\tPerc Error: 68.75%\n",
      "Missed detections: 5\tPerc Error: 31.25%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8453005627905711971692426232038997113704681396484375 \n",
      "\n",
      "X_test.shape (1, 40, 216, 256, 1)\n",
      "watershed_images.shape (1, 40, 216, 256, 1)\n",
      "GT_image.shape (1, 40, 216, 256)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2\n",
      "Number of predicted cells:\t 3\n",
      "\n",
      "Correct detections:  0\tRecall: 0%\n",
      "Incorrect detections: 3\tPrecision: 0%\n",
      "\n",
      "Gained detections: 3\tPerc Error: 60%\n",
      "Missed detections: 2\tPerc Error: 40%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.88917349726775951612722792560816742479801177978515625 \n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_101 (InputLayer)          (None, 30, 202, 240, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_100 (Imag (None, 30, 202, 240, 0           input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_100 (Model)               (None, 30, 202, 240, 213570      image_normalization3d_100[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 30, 202, 240, 0           image_normalization3d_100[0][0]  \n",
      "                                                                 model_100[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_101 (Model)               (None, 30, 202, 240, 214594      concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 30, 202, 240, 0           image_normalization3d_100[0][0]  \n",
      "                                                                 model_101[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_102 (Model)               (None, 30, 202, 240, 214594      concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 30, 202, 240, 0           image_normalization3d_100[0][0]  \n",
      "                                                                 model_102[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_103 (Model)               (None, 30, 202, 240, 214594      concatenate_69[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 857,352\n",
      "Trainable params: 852,744\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_106 (InputLayer)          (None, 30, 202, 240, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_105 (Imag (None, 30, 202, 240, 0           input_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_104 (Model)               [(None, 30, 202, 240 857352      input_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 30, 202, 240, 0           image_normalization3d_105[0][0]  \n",
      "                                                                 model_104[1][3]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_105 (Model)               (None, 30, 202, 240, 182084      concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 30, 202, 240, 0           image_normalization3d_105[0][0]  \n",
      "                                                                 model_105[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_106 (Model)               (None, 30, 202, 240, 183108      concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 30, 202, 240, 0           image_normalization3d_105[0][0]  \n",
      "                                                                 model_106[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_107 (Model)               (None, 30, 202, 240, 183108      concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 30, 202, 240, 0           image_normalization3d_105[0][0]  \n",
      "                                                                 model_107[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_108 (Model)               (None, 30, 202, 240, 183108      concatenate_73[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,588,760\n",
      "Trainable params: 726,800\n",
      "Non-trainable params: 861,960\n",
      "__________________________________________________________________________________________________\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 13\n",
      "Number of predicted cells:\t 15\n",
      "\n",
      "Correct detections:  1\tRecall: 7.69230769230769251265655839233659207820892333984375%\n",
      "Incorrect detections: 14\tPrecision: 6.66666666666666696272613990004174411296844482421875%\n",
      "\n",
      "Gained detections: 12\tPerc Error: 50%\n",
      "Missed detections: 11\tPerc Error: 45.83333333333333570180911920033395290374755859375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 4.16666666666666696272613990004174411296844482421875%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.85061397474519850891994110497762449085712432861328125 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 43\n",
      "Number of predicted cells:\t 40\n",
      "\n",
      "Correct detections:  3\tRecall: 6.9767441860465115865963525720871984958648681640625%\n",
      "Incorrect detections: 37\tPrecision: 7.5%\n",
      "\n",
      "Gained detections: 36\tPerc Error: 48%\n",
      "Missed detections: 38\tPerc Error: 50.66666666666666429819088079966604709625244140625%\n",
      "Merges: 1\t\tPerc Error: 1.3333333333333332593184650249895639717578887939453125%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 1\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.872960733821171341872968696407042443752288818359375 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 19\n",
      "Number of predicted cells:\t 23\n",
      "\n",
      "Correct detections:  4\tRecall: 21.052631578947369916932075284421443939208984375%\n",
      "Incorrect detections: 19\tPrecision: 17.39130434782608602972686639986932277679443359375%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 53.125%\n",
      "Missed detections: 14\tPerc Error: 43.75%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 3.125%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8809388122981662849753092814353294670581817626953125 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 7\n",
      "Number of predicted cells:\t 11\n",
      "\n",
      "Correct detections:  2\tRecall: 28.571428571428572951163005200214684009552001953125%\n",
      "Incorrect detections: 9\tPrecision: 18.181818181818183433051672182045876979827880859375%\n",
      "\n",
      "Gained detections: 9\tPerc Error: 64.2857142857142918046520208008587360382080078125%\n",
      "Missed detections: 5\tPerc Error: 35.71428571428571530077533680014312267303466796875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.85312017881655510809224551849183626472949981689453125 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 27\n",
      "Number of predicted cells:\t 25\n",
      "\n",
      "Correct detections:  4\tRecall: 14.8148148148148148806058088666759431362152099609375%\n",
      "Incorrect detections: 21\tPrecision: 16%\n",
      "\n",
      "Gained detections: 19\tPerc Error: 45.23809523809524080206756480038166046142578125%\n",
      "Missed detections: 22\tPerc Error: 52.380952380952379598966217599809169769287109375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 2.380952380952380931233847149997018277645111083984375%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 1\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8837660347790332604489549339632503688335418701171875 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 7\n",
      "Number of predicted cells:\t 8\n",
      "\n",
      "Correct detections:  0\tRecall: 0%\n",
      "Incorrect detections: 8\tPrecision: 0%\n",
      "\n",
      "Gained detections: 6\tPerc Error: 54.5454545454545467464413377456367015838623046875%\n",
      "Missed detections: 4\tPerc Error: 36.36363636363636686610334436409175395965576171875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 1\t\tPerc Error: 9.0909090909090917165258360910229384899139404296875%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 3\n",
      "Predicted detections involved in catastrophes: 2 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8605430875645634358761526527814567089080810546875 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 8\n",
      "Number of predicted cells:\t 17\n",
      "\n",
      "Correct detections:  0\tRecall: 0%\n",
      "Incorrect detections: 17\tPrecision: 0%\n",
      "\n",
      "Gained detections: 17\tPerc Error: 68%\n",
      "Missed detections: 8\tPerc Error: 32%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.7893946354737251258626429262221790850162506103515625 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 6\n",
      "Number of predicted cells:\t 7\n",
      "\n",
      "Correct detections:  2\tRecall: 33.33333333333333570180911920033395290374755859375%\n",
      "Incorrect detections: 5\tPrecision: 28.571428571428572951163005200214684009552001953125%\n",
      "\n",
      "Gained detections: 5\tPerc Error: 55.5555555555555571345394128002226352691650390625%\n",
      "Missed detections: 4\tPerc Error: 44.4444444444444428654605871997773647308349609375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.79183993831070476066003038795315660536289215087890625 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 13\n",
      "Number of predicted cells:\t 18\n",
      "\n",
      "Correct detections:  3\tRecall: 23.076923076923076649791255476884543895721435546875%\n",
      "Incorrect detections: 15\tPrecision: 16.666666666666667850904559600166976451873779296875%\n",
      "\n",
      "Gained detections: 15\tPerc Error: 60%\n",
      "Missed detections: 10\tPerc Error: 40%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.84837229109491818501709303745883516967296600341796875 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 10\n",
      "Number of predicted cells:\t 11\n",
      "\n",
      "Correct detections:  1\tRecall: 10%\n",
      "Incorrect detections: 10\tPrecision: 9.0909090909090917165258360910229384899139404296875%\n",
      "\n",
      "Gained detections: 8\tPerc Error: 50%\n",
      "Missed detections: 7\tPerc Error: 43.75%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 1\t\tPerc Error: 6.25%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 2\n",
      "Predicted detections involved in catastrophes: 2 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.86153705047068729339088122287648729979991912841796875 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 13\n",
      "Number of predicted cells:\t 14\n",
      "\n",
      "Correct detections:  2\tRecall: 15.3846153846153850253131167846731841564178466796875%\n",
      "Incorrect detections: 12\tPrecision: 14.2857142857142864755815026001073420047760009765625%\n",
      "\n",
      "Gained detections: 12\tPerc Error: 52.17391304347825808918059919960796833038330078125%\n",
      "Missed detections: 11\tPerc Error: 47.82608695652174191081940080039203166961669921875%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8593414695880883247269821367808617651462554931640625 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 31\n",
      "Number of predicted cells:\t 32\n",
      "\n",
      "Correct detections:  3\tRecall: 9.6774193548387099639285224839113652706146240234375%\n",
      "Incorrect detections: 29\tPrecision: 9.375%\n",
      "\n",
      "Gained detections: 26\tPerc Error: 48.14814814814814525334440986625850200653076171875%\n",
      "Missed detections: 27\tPerc Error: 50%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 1\t\tPerc Error: 1.8518518518518518600757261083344928920269012451171875%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 2\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.8865202242275260768877842565416358411312103271484375 \n",
      "\n",
      "X_test.shape (1, 30, 202, 240, 1)\n",
      "watershed_images.shape (1, 30, 202, 240, 1)\n",
      "GT_image.shape (1, 30, 202, 240)\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 13\n",
      "Number of predicted cells:\t 15\n",
      "\n",
      "Correct detections:  2\tRecall: 15.3846153846153850253131167846731841564178466796875%\n",
      "Incorrect detections: 13\tPrecision: 13.3333333333333339254522798000834882259368896484375%\n",
      "\n",
      "Gained detections: 11\tPerc Error: 52.380952380952379598966217599809169769287109375%\n",
      "Missed detections: 9\tPerc Error: 42.85714285714285409767398959957063198089599609375%\n",
      "Merges: 0\t\tPerc Error: 0%\n",
      "Splits: 0\t\tPerc Error: 0%\n",
      "Catastrophes: 1\t\tPerc Error: 4.76190476190476186246769429999403655529022216796875%\n",
      "\n",
      "Gained detections from splits: 0\n",
      "Missed detections from merges: 0\n",
      "True detections involved in catastrophes: 2\n",
      "Predicted detections involved in catastrophes: 2 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): 0.883578277763850561399294747388921678066253662109375 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from skimage.morphology import remove_small_objects\n",
    "import pandas as pd\n",
    "from deepcell import metrics\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "# CELL_TYPE_NAME = ['3T3', 'HEK293', 'HeLa']\n",
    "CELL_TYPE_NAME = ['3T3', 'HEK293', 'HeLa', 'RAW264']\n",
    "\n",
    "# threshold the foreground/background\n",
    "# and remove back ground from edge transform\n",
    "threshold = 0.5\n",
    "Lstats_AllDatasets = []\n",
    "# Go through each Dataset (3T3, HEK293, HeLa, RAW264.7)\n",
    "for set_num, dataset in enumerate(raw_trks_files):\n",
    "    # Load the trk file       \n",
    "    trks = load_trks(dataset)\n",
    "    lineages, raw, tracked = trks['lineages'], trks['X'], trks['y']\n",
    "    \n",
    "    run_fgbg_model = feature_net_skip_3D(\n",
    "            n_features=2,  # segmentation mask (is_cell, is_not_cell)\n",
    "            receptive_field=receptive_field,\n",
    "            n_skips=n_skips,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=is_gru,\n",
    "            gru_kernel_size=gru_kernel_size,\n",
    "            input_shape=tuple(trks['X'].shape[1:]),\n",
    "            last_only=False,\n",
    "            norm_method=norm_method)\n",
    "\n",
    "    run_fgbg_model.load_weights('/data/models/trackingSEG_cropped_conv_fgbg_model.h5')\n",
    "\n",
    "    run_watershed_model = feature_net_skip_3D(\n",
    "                        fgbg_model=run_fgbg_model,\n",
    "                        receptive_field=receptive_field,\n",
    "                        n_skips=n_skips,\n",
    "                        n_features=distance_bins,\n",
    "                        n_frames=frames_per_batch,\n",
    "                        n_conv_filters=32,\n",
    "                        n_dense_filters=128,\n",
    "                        multires=False,\n",
    "                        last_only=False,\n",
    "                        input_shape=tuple(trks['X'].shape[1:]),\n",
    "                        norm_method=norm_method,\n",
    "                        gru=False,\n",
    "                        gru_kernel_size=3)\n",
    "\n",
    "    run_watershed_model.load_weights('/data/models/trackingSEG_cropped_conv_watershed_model.h5')\n",
    "    \n",
    "    # Create an array for the new annotations\n",
    "    y_new = np.zeros(tracked.shape)\n",
    "    Lstats = []\n",
    "    # Go through each batch (movie) in each dataset\n",
    "    # Predict on the raw data\n",
    "    for j in range(len(trks['y'])):\n",
    "        X_test, y_test = trks['X'][j:j+1, ...], trks['y'][j:j+1,...]\n",
    "        print(\"X_test.shape\", X_test.shape)\n",
    "        test_images = run_watershed_model.predict(X_test)[-1]\n",
    "        test_images_fgbg = run_fgbg_model.predict(X_test)[-1]\n",
    "        # Postprocessing\n",
    "        # Collapse predictions into semantic segmentation mask\n",
    "        argmax_images = []\n",
    "        for i in range(test_images.shape[0]):\n",
    "            max_image = np.argmax(test_images[i], axis=-1)\n",
    "            argmax_images.append(max_image)\n",
    "        argmax_images = np.array(argmax_images)\n",
    "        argmax_images = np.expand_dims(argmax_images, axis=-1)\n",
    "        # threshold the foreground/background\n",
    "        # and remove background from watershed transform\n",
    "        fg_thresh = test_images_fgbg[..., 1] > threshold\n",
    "        fg_thresh = np.expand_dims(fg_thresh.astype('int16'), axis=-1)\n",
    "        argmax_images_post_fgbg = argmax_images * fg_thresh\n",
    "        watershed_images = []\n",
    "        for i in range(argmax_images_post_fgbg.shape[0]):\n",
    "            image = fg_thresh[i, ..., 0]\n",
    "            distance = argmax_images_post_fgbg[i, ..., 0]\n",
    "            local_maxi = peak_local_max(test_images[i, ..., -1], min_distance=15, \n",
    "                                        exclude_border=False, indices=False, labels=image)\n",
    "            markers = label(local_maxi)\n",
    "            segments = watershed(-distance, markers, mask=image)\n",
    "            watershed_images.append(segments)\n",
    "        watershed_images = np.array(watershed_images)\n",
    "        watershed_images = np.expand_dims(watershed_images, axis=-1)\n",
    "        print(\"watershed_images.shape\", watershed_images.shape)\n",
    "        # Accuracy from metrics package\n",
    "        batch_num = j\n",
    "        filename = CELL_TYPE_NAME[set_num] + BASE_NAME + '{}'.format(batch_num)\n",
    "        # Remove small objects from GT for comparison\n",
    "        small_objects_threshold=100        \n",
    "        GT_image = remove_small_objects(tracked[j:j+1, :, :, :, 0].astype('uint16'), min_size=small_objects_threshold)\n",
    "        print(\"GT_image.shape\", GT_image.shape)\n",
    "        #GT_image = tracked[batch_num, :, :, :, :].astype('uint16')\n",
    "        m = metrics.Metrics(model_name = filename)\n",
    "        m.calc_object_stats(GT_image, watershed_images[:,:,:,:, 0])\n",
    "        #m.save_to_json(m.output)    \n",
    "        Lstats.append(m.stats)                \n",
    "    Lstats_AllDatasets.append(Lstats)\n",
    "df_3T3    = pd.concat(Lstats_AllDatasets[0]) \n",
    "df_HEK293 = pd.concat(Lstats_AllDatasets[1])\n",
    "df_HeLa   = pd.concat(Lstats_AllDatasets[2])\n",
    "df_RAW264 = pd.concat(Lstats_AllDatasets[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3T3\n",
      "\n",
      "\n",
      "Correct Detections:  55\n",
      "Incorrect Detections:  306\n",
      "Splits:  11\n",
      "Merges:  1\n",
      "Catastrophes:  0\n",
      "Recall:  19.09722222222222\n",
      "Precision:  15.23545706371191\n",
      "Average Jaccard Index:  0.8450120014516203\n",
      "\n",
      "\n",
      "HEK293\n",
      "\n",
      "\n",
      "Correct Detections:  100\n",
      "Incorrect Detections:  468\n",
      "Splits:  19\n",
      "Merges:  10\n",
      "Catastrophes:  7\n",
      "Recall:  17.094017094017094\n",
      "Precision:  17.6056338028169\n",
      "Average Jaccard Index:  0.8760236436107901\n",
      "\n",
      "\n",
      "HeLa\n",
      "\n",
      "\n",
      "Correct Detections:  27\n",
      "Incorrect Detections:  236\n",
      "Splits:  8\n",
      "Merges:  0\n",
      "Catastrophes:  0\n",
      "Recall:  15.976331360946746\n",
      "Precision:  10.26615969581749\n",
      "Average Jaccard Index:  0.8213110539148611\n",
      "\n",
      "\n",
      "RAW264\n",
      "\n",
      "\n",
      "Correct Detections:  27\n",
      "Incorrect Detections:  209\n",
      "Splits:  4\n",
      "Merges:  1\n",
      "Catastrophes:  3\n",
      "Recall:  12.857142857142858\n",
      "Precision:  11.440677966101696\n",
      "Average Jaccard Index:  0.8555789776118606\n"
     ]
    }
   ],
   "source": [
    "# CELL_TYPE_DF = [df_3T3, df_HEK293, df_HeLa]\n",
    "\n",
    "CELL_TYPE_DF = [df_3T3, df_HEK293, df_HeLa, df_RAW264]\n",
    "\n",
    "for cell_type, df in zip(CELL_TYPE_NAME, CELL_TYPE_DF):\n",
    "    print('\\n')\n",
    "    print(cell_type)\n",
    "    print('\\n')\n",
    "    # Total number of correct detections and incorrect detections\n",
    "    correct_det = int(df['correct_detections'].sum())\n",
    "    incorrect_det = int(df['n_pred'].sum() - df['correct_detections'].sum())\n",
    "\n",
    "    print('Correct Detections: ', correct_det)\n",
    "    print('Incorrect Detections: ', incorrect_det)\n",
    "    \n",
    "    # Total number of splits, merges, and catastrophes\n",
    "    splits = df['split'].sum()\n",
    "    merges = df['merge'].sum()\n",
    "    catastrophes = df['catastrophe'].sum()\n",
    "    \n",
    "    print('Splits: ', splits)\n",
    "    print('Merges: ', merges)\n",
    "    print('Catastrophes: ', catastrophes)\n",
    "\n",
    "    # Average Recall, Precision, and Jaccard Index\n",
    "    recall = 100 * df['correct_detections'].sum() / df['n_true'].sum()\n",
    "    precision = 100 * df['correct_detections'].sum() / df['n_pred'].sum()\n",
    "    jaccard = df['jaccard'].mean()\n",
    "\n",
    "    print('Recall: ', recall)\n",
    "    print('Precision: ', precision)\n",
    "    print('Average Jaccard Index: ', jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See what it looks like on the different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_BASE_DIR = '/data/npz_data/tracking_benchmark_data/test'\n",
    "\n",
    "raw_trks_3T3  = os.path.join(RAW_BASE_DIR, '3T3_NIH_test_BData.trks')\n",
    "raw_trks_HEK  = os.path.join(RAW_BASE_DIR, 'HEK293_generic_test_BData.trks')\n",
    "raw_trks_HeLa = os.path.join(RAW_BASE_DIR, 'HeLa_S3_test_BData.trks')\n",
    "raw_trks_RAW  = os.path.join(RAW_BASE_DIR, 'RAW264_generic_test_BData.trks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_141 (InputLayer)          (None, 40, 216, 256, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_normalization3d_140 (Imag (None, 40, 216, 256, 0           input_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_140 (Model)               (None, 40, 216, 256, 213570      image_normalization3d_140[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_140[0][0]  \n",
      "                                                                 model_140[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_141 (Model)               (None, 40, 216, 256, 214594      concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_140[0][0]  \n",
      "                                                                 model_141[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_142 (Model)               (None, 40, 216, 256, 214594      concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 40, 216, 256, 0           image_normalization3d_140[0][0]  \n",
      "                                                                 model_142[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_143 (Model)               (None, 40, 216, 256, 214594      concatenate_97[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 857,352\n",
      "Trainable params: 852,744\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from skimage.morphology import remove_small_objects\n",
    "import pandas as pd\n",
    "from deepcell import metrics\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "trks = load_trks(raw_trks_HeLa)\n",
    "lineages, X_test, y_test = trks['lineages'], trks['X'], trks['y']\n",
    "\n",
    "run_fgbg_model = feature_net_skip_3D(\n",
    "            n_features=2,  # segmentation mask (is_cell, is_not_cell)\n",
    "            receptive_field=receptive_field,\n",
    "            n_skips=n_skips,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=is_gru,\n",
    "            gru_kernel_size=gru_kernel_size,\n",
    "            input_shape=tuple(X_test.shape[1:]),\n",
    "            last_only=False,\n",
    "            norm_method=norm_method)\n",
    "\n",
    "run_fgbg_model.load_weights('/data/models/trackingSEG_cropped_conv_fgbg_model.h5')\n",
    "\n",
    "run_watershed_model = feature_net_skip_3D(\n",
    "                    fgbg_model=run_fgbg_model,\n",
    "                    receptive_field=receptive_field,\n",
    "                    n_skips=n_skips,\n",
    "                    n_features=distance_bins,\n",
    "                    n_frames=frames_per_batch,\n",
    "                    n_conv_filters=32,\n",
    "                    n_dense_filters=128,\n",
    "                    multires=False,\n",
    "                    last_only=False,\n",
    "                    input_shape=tuple(X_test.shape[1:]),\n",
    "                    norm_method=norm_method,\n",
    "                    gru=False,\n",
    "                    gru_kernel_size=3)\n",
    "\n",
    "run_watershed_model.load_weights('/data/models/trackingSEG_cropped_conv_watershed_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on testing data\n",
    "test_images = run_watershed_model.predict(X_test[:2, :, :, :, :])[-1]\n",
    "test_images_fgbg = run_fgbg_model.predict(X_test[:2, :, :, :, :])[-1]\n",
    "\n",
    "print('watershed transform shape:', test_images.shape)\n",
    "print('segmentation mask shape:', test_images_fgbg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse predictions into semantic segmentation mask\n",
    "\n",
    "argmax_images = []\n",
    "for i in range(test_images.shape[0]):\n",
    "    max_image = np.argmax(test_images[i], axis=-1)\n",
    "    argmax_images.append(max_image)\n",
    "argmax_images = np.array(argmax_images)\n",
    "argmax_images = np.expand_dims(argmax_images, axis=-1)\n",
    "\n",
    "print('watershed argmax shape:', argmax_images.shape)\n",
    "\n",
    "# threshold the foreground/background\n",
    "# and remove background from watershed transform\n",
    "threshold = 0.5\n",
    "fg_thresh = test_images_fgbg[..., 1] > threshold\n",
    "\n",
    "fg_thresh = np.expand_dims(fg_thresh.astype('int16'), axis=-1)\n",
    "argmax_images_post_fgbg = argmax_images * fg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply watershed method with the distance transform as seed\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import watershed\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "watershed_images = []\n",
    "for i in range(argmax_images_post_fgbg.shape[0]):\n",
    "    image = fg_thresh[i, ..., 0]\n",
    "    distance = argmax_images_post_fgbg[i, ..., 0]\n",
    "\n",
    "    local_maxi = peak_local_max(test_images[i, ..., -1], min_distance=15, \n",
    "                                exclude_border=False, indices=False, labels=image)\n",
    "\n",
    "    markers = label(local_maxi)\n",
    "    segments = watershed(-distance, markers, mask=image)\n",
    "    watershed_images.append(segments)\n",
    "\n",
    "watershed_images = np.array(watershed_images)\n",
    "# watershed_images = remove_small_objects(watershed_images[:, :, :, :].astype('uint16'), min_size=400)\n",
    "watershed_images = np.expand_dims(watershed_images, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = np.random.randint(low=0, high=2)\n",
    "frame = np.random.randint(low=0, high=X_test.shape[1])\n",
    "print('Image number:', index)\n",
    "print('Frame:', frame)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=4, nrows=2, figsize=(15, 10), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(X_test[index, frame, ..., 0])\n",
    "ax[0].set_title('Source Image')\n",
    "\n",
    "ax[1].imshow(test_images_fgbg[index, frame, ..., 1])\n",
    "ax[1].set_title('Segmentation Prediction')\n",
    "\n",
    "ax[2].imshow(fg_thresh[index, frame, ..., 0], cmap='jet')\n",
    "ax[2].set_title('FGBG Threshold {}%'.format(threshold * 100))\n",
    "\n",
    "fg_thresh_90 = test_images_fgbg[..., 1] > 0.5\n",
    "fg_thresh_90 = np.expand_dims(fg_thresh_90.astype('int16'), axis=-1)\n",
    "ax[3].imshow(fg_thresh_90[index, frame, ..., 0], cmap='jet')\n",
    "ax[3].set_title('FGBG Threshold {}%'.format(0.5 * 100))\n",
    "\n",
    "ax[4].imshow(argmax_images[index, frame, ..., 0], cmap='jet')\n",
    "ax[4].set_title('Distance Transform')\n",
    "\n",
    "ax[5].imshow(argmax_images_post_fgbg[index, frame, ..., 0], cmap='jet')\n",
    "ax[5].set_title('Distance Transform w/o Background')\n",
    "\n",
    "ax[6].imshow(watershed_images[index, frame, ..., 0], cmap='jet')\n",
    "ax[6].set_title('Watershed Segmentation')\n",
    "\n",
    "ax[7].imshow(y_test[index, frame, ..., 0], cmap='jet')\n",
    "ax[7].set_title('Ground truth')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions on ISBI Data for Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FOR ISBI Challenge Datasets\n",
    "\n",
    "# Define data to load (raw images from trk test files)  \n",
    "RAW_BASE_DIR = '/data/data/ISBI_Tracking_Challenge/tracks'\n",
    "\n",
    "raw_trks_HeLa = os.path.join(RAW_BASE_DIR, 'ISBI_HeLa_Chal_GT.trks')\n",
    "raw_trks_MSC  = os.path.join(RAW_BASE_DIR, 'ISBI_MSC_resized_Chal_GT_normalized.trks')\n",
    "raw_trks_U373 = os.path.join(RAW_BASE_DIR, 'ISBI_U373_Chal_GT.trks')\n",
    "\n",
    "#raw_trks_files = [raw_trks_HeLa, raw_trks_MSC, raw_trks_U373]\n",
    "raw_trks_files = [raw_trks_HeLa]\n",
    "\n",
    "# Define where segmentations will be saved\n",
    "SEG_BASE_DIR = '/data/track_data/Final_Benchmarks/ISBI_DC_SEG/Watershed/HeLa_segmentations'\n",
    "                             \n",
    "DC_seg_HeLa  = os.path.join(SEG_BASE_DIR, 'HeLa/')\n",
    "DC_seg_MSC   = os.path.join(SEG_BASE_DIR, 'MSC/')\n",
    "DC_seg_U373  = os.path.join(SEG_BASE_DIR, 'U373/')\n",
    "\n",
    "#DC_seg_folders = [DC_seg_HeLa, DC_seg_MSC, DC_seg_U373]\n",
    "DC_seg_folders = [DC_seg_HeLa]\n",
    "\n",
    "# Define a base file name for the output\n",
    "BASE_NAME = 'batch_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate new models for any image size\n",
    "\n",
    "from deepcell import model_zoo\n",
    "\n",
    "fgbg_model = model_zoo.bn_feature_net_skip_2D(\n",
    "    n_features=2,  # segmentation mask (is_cell, is_not_cell)\n",
    "    receptive_field=receptive_field,\n",
    "    n_skips=n_skips,\n",
    "    n_conv_filters=32,\n",
    "    n_dense_filters=128,\n",
    "    input_shape=(None, None, 1),\n",
    "    last_only=False)\n",
    "\n",
    "fgbg_model.load_weights('/data/models/trackingSEG_cropped_conv_gru_fgbg_model.h5')\n",
    "\n",
    "\n",
    "watershed_model = model_zoo.bn_feature_net_skip_2D(\n",
    "    fgbg_model=fgbg_model,\n",
    "    receptive_field=receptive_field,\n",
    "    n_skips=n_skips,\n",
    "    n_features=distance_bins,\n",
    "    n_conv_filters=32,\n",
    "    n_dense_filters=128,\n",
    "    last_only=False,\n",
    "    input_shape=(None, None, 1))\n",
    "\n",
    "watershed_model.load_weights('/data/models/trackingSEG_cropped_conv_gru_watershed_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Predict for metric information only\n",
    "\n",
    "CELL_TYPE_NAME = ['HeLa']\n",
    "threshold = 0.9\n",
    "\n",
    "from deepcell import metrics\n",
    "from skimage.measure import label\n",
    "from skimage import morphology\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "import tarfile\n",
    "import pathlib\n",
    "import tempfile\n",
    "import json\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def load_trks(filename):\n",
    "    \"\"\"Load a trk/trks file.\n",
    "\n",
    "    Args:\n",
    "        trks_file: full path to the file including .trk/.trks\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with raw, tracked, and lineage data\n",
    "    \"\"\"\n",
    "    with tarfile.open(filename, 'r') as trks:\n",
    "\n",
    "        # numpy can't read these from disk...\n",
    "        array_file = BytesIO()\n",
    "        array_file.write(trks.extractfile('raw.npy').read())\n",
    "        array_file.seek(0)\n",
    "        raw = np.load(array_file)\n",
    "        array_file.close()\n",
    "\n",
    "        array_file = BytesIO()\n",
    "        array_file.write(trks.extractfile('tracked.npy').read())\n",
    "        array_file.seek(0)\n",
    "        tracked = np.load(array_file)\n",
    "        array_file.close()\n",
    "\n",
    "    return {'X': raw, 'y': tracked}\n",
    "\n",
    "\n",
    "Lstats_AllDatasets = []\n",
    "\n",
    "# Go through each Dataset\n",
    "for set_num, dataset in enumerate(raw_trks_files):\n",
    "    # Load the trk file       \n",
    "    trks = load_trks(dataset)\n",
    "    raw, tracked = trks['X'], trks['y']\n",
    "    \n",
    "    # Create an array for the new annotations\n",
    "    y_new = np.zeros(tracked.shape)\n",
    "                \n",
    "    Lstats_allmovies = []\n",
    "\n",
    "    # Go through each batch (movie) in each dataset\n",
    "    for batch_num, movie in enumerate(trks['X']):\n",
    "\n",
    "        Lstats = []\n",
    "        # Predict on the raw data\n",
    "        for frame_num, frame in enumerate(movie):\n",
    "            \n",
    "            image = np.expand_dims(frame, axis=0)\n",
    "             \n",
    "            test_image = watershed_model.predict(image)[-1]\n",
    "            test_image_fgbg = fgbg_model.predict(image)[-1]\n",
    "\n",
    "            # Postprocessing\n",
    "            # Collapse predictions into semantic segmentation mask        \n",
    "            max_image = np.argmax(test_image, axis=-1)\n",
    "            argmax_image = np.expand_dims(max_image, axis=-1)\n",
    "        \n",
    "            # threshold the foreground/background\n",
    "            # and remove background from watershed transform\n",
    "            fg_thresh = test_image_fgbg[..., 1] > threshold\n",
    "\n",
    "            fg_thresh = np.expand_dims(fg_thresh.astype('int16'), axis=-1)\n",
    "            argmax_image_post_fgbg = argmax_image * fg_thresh\n",
    "        \n",
    "            # Apply watershed method with the distance transform as seed\n",
    "            image = fg_thresh[..., 0]\n",
    "            distance = argmax_image_post_fgbg[..., 0]\n",
    "\n",
    "            local_maxi = peak_local_max(test_image[..., -1], min_distance=15, \n",
    "                                        exclude_border=False, indices=False, labels=image)\n",
    "\n",
    "            markers = label(local_maxi)\n",
    "            segments = watershed(-distance, markers, mask=image)\n",
    "            watershed_image = np.expand_dims(segments, axis=-1)\n",
    "            \n",
    "            # Remove small objects from GT for comparison\n",
    "            small_objects_threshold=50\n",
    "            GT_image = trks['y'][batch_num, frame_num, :, :, :]\n",
    "            GT_image = np.expand_dims(GT_image, axis=0)\n",
    "            GT_image = morphology.remove_small_objects(GT_image.astype('uint16'), min_size=small_objects_threshold)\n",
    "            \n",
    "            # Accuracy from metrics package\n",
    "            filename = CELL_TYPE_NAME[set_num] + BASE_NAME + '{}'.format(batch_num)\n",
    "            \n",
    "            m = metrics.Metrics(model_name = filename)\n",
    "            m.calc_object_stats(GT_image, watershed_image)\n",
    "            \n",
    "            # Store results\n",
    "            y_new[batch_num, frame_num, :, :, :] = watershed_image\n",
    "\n",
    "            Lstats.append(m.stats)\n",
    "            \n",
    "    # Save results of this batch before moving on to the next\n",
    "    filename = os.path.join(DC_seg_folders[set_num], 'all_batches.trks')\n",
    "    filename = pathlib.Path(filename)\n",
    "\n",
    "    with tarfile.open(str(filename), 'w') as trks:\n",
    "        with tempfile.NamedTemporaryFile() as raw_file:\n",
    "            np.save(raw_file, raw)\n",
    "            raw_file.flush()\n",
    "            trks.add(raw_file.name, 'raw.npy')\n",
    "\n",
    "        with tempfile.NamedTemporaryFile() as tracked_file:\n",
    "            np.save(tracked_file, y_new)\n",
    "            tracked_file.flush()\n",
    "            trks.add(tracked_file.name, 'tracked.npy')\n",
    "                \n",
    "        \n",
    "        Lstats_allmovies.append(Lstats)\n",
    "        \n",
    "    Lstats_AllDatasets.append(Lstats_allmovies)\n",
    "    \n",
    "    \n",
    "#df_HeLa   = pd.concat(Lstats_AllDatasets[0])\n",
    "df_HeLa = pd.concat([pd.concat(Lstats_AllDatasets[0][0]) , pd.concat(Lstats_AllDatasets[0][1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_TYPE_DF = [df_HeLa]\n",
    "\n",
    "for cell_type, df in zip(CELL_TYPE_NAME, CELL_TYPE_DF):\n",
    "    print('\\n')\n",
    "    print(cell_type)\n",
    "    print('\\n')\n",
    "    # Total number of correct detections and incorrect detections\n",
    "    correct_det = int(df['correct_detections'].sum())\n",
    "    incorrect_det = int(df['n_pred'].sum() - df['correct_detections'].sum())\n",
    "\n",
    "    print('Correct Detections: ', correct_det)\n",
    "    print('Incorrect Detections: ', incorrect_det)\n",
    "    \n",
    "    # Total number of splits, merges, and catastrophes\n",
    "    splits = df['split'].sum()\n",
    "    merges = df['merge'].sum()\n",
    "    catastrophes = df['catastrophe'].sum()\n",
    "    \n",
    "    print('Splits: ', splits)\n",
    "    print('Merges: ', merges)\n",
    "    print('Catastrophes: ', catastrophes)\n",
    "\n",
    "    # Average Recall, Precision, and Jaccard Index\n",
    "    recall = 100 * df['correct_detections'].sum() / df['n_true'].sum()\n",
    "    precision = 100 * df['correct_detections'].sum() / df['n_pred'].sum()\n",
    "    jaccard = df['jaccard'].mean()\n",
    "\n",
    "    print('Recall: ', recall)\n",
    "    print('Precision: ', precision)\n",
    "    print('Average Jaccard Index: ', jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
