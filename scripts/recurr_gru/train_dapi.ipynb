{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import getopt\n",
    "import errno\n",
    "\n",
    "sys.path.insert(0,\"/home/sunnycui/deepcell-tf\")\n",
    "\n",
    "MODEL_DIR = os.path.join(sys.path[0], 'scripts/recurr_gru/models/')\n",
    "LOG_DIR = os.path.join(sys.path[0], 'scripts/recurr_gru/logs/')\n",
    "DATA_DIR = os.path.join(sys.path[0], 'scripts/recurr_gru/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunnycui/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/sunnycui/deepcell-tf/deepcell/utils/__init__.py:48: UserWarning: To use `compute_overlap`, the C extensions must be built using `python setup.py build_ext --inplace`\n",
      "  warnings.warn('To use `compute_overlap`, the C extensions must be built '\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "\n",
    "import deepcell\n",
    "from deepcell import losses\n",
    "from scripts.recurr_gru import image_gen\n",
    "from deepcell import image_generators, stack_generator\n",
    "from deepcell import model_zoo\n",
    "\n",
    "from deepcell.utils import train_utils\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "\n",
    "from deepcell.layers import TensorProduct, ReflectionPadding3D, DilatedMaxPool3D\n",
    "from tensorflow.python.keras.layers import MaxPool3D, Conv3DTranspose, UpSampling3D\n",
    "from scripts.recurr_gru.conv_gru_layer import ConvGRU2D\n",
    "from tensorflow.python.keras.layers import BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.python.keras.layers import Conv3D, ZeroPadding3D, ConvLSTM2D, Cropping3D\n",
    "from tensorflow.python.keras.layers import Input, Add, Concatenate, Flatten\n",
    "from tensorflow.python.keras.engine.input_layer import InputLayer\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "from deepcell.layers import ImageNormalization3D\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Softmax\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dapi_1.npz\n",
      " -\n",
      "X.shape: (680, 61, 256, 256, 1)\n",
      "y.shape: (680, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "filename = 'dapi_1.npz'\n",
    "DATA_FILE = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "print(\"Loading data from \" + filename)\n",
    "train_dict, test_dict = get_data(DATA_FILE, mode='conv', test_size=0.1, seed=0)\n",
    "\n",
    "print(' -\\nX.shape: {}\\ny.shape: {}'.format(train_dict['X'].shape, train_dict['y'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fgbg_model_name = 'nuclei_model_fgbg'\n",
    "watershed_model_name = 'nuclei_model_watershed'\n",
    "\n",
    "\n",
    "n_epoch = 20  # Number of training epochs\n",
    "test_size = .10  # % of data saved as test\n",
    "norm_method = None  # data normalization\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# FC training settings\n",
    "n_skips = 0  # number of skip-connections (only for FC training)\n",
    "batch_size = 1  # FC training uses 1 image per batch\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'watershed'\n",
    "dilation_radius = 1  # change dilation radius for edge dilation\n",
    "\n",
    "# 3D Settings\n",
    "frames_per_batch = 3\n",
    "# norm_method = None #'whole_image'\n",
    "\n",
    "distance_bins = 4  # number of distance classes\n",
    "erosion_width = 0  # erode edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_net_3D(receptive_field=61,\n",
    "                    n_frames=3,\n",
    "                    input_shape=(5, 256, 256, 1),\n",
    "                    n_features=3,\n",
    "                    n_channels=1,\n",
    "                    reg=1e-5,\n",
    "                    n_conv_filters=64,\n",
    "                    n_dense_filters=200,\n",
    "                    gru_kernel_size =3,\n",
    "                    VGG_mode=False,\n",
    "                    init='he_normal',\n",
    "                    norm_method='whole_image',\n",
    "                    gru=False,\n",
    "                    location=False,\n",
    "                    dilated=False,\n",
    "                    padding=False,\n",
    "                    padding_mode='reflect',\n",
    "                    multires=False,\n",
    "                    include_top=True):\n",
    "    # Create layers list (x) to store all of the layers.\n",
    "    # We need to use the functional API to enable the multiresolution mode\n",
    "    x = []\n",
    "\n",
    "    win = (receptive_field - 1) // 2\n",
    "    win_z = (n_frames - 1) // 2\n",
    "\n",
    "    if dilated:\n",
    "        padding = True\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        time_axis = 2\n",
    "        row_axis = 3\n",
    "        col_axis = 4\n",
    "        if not dilated:\n",
    "            input_shape = (n_channels, n_frames, receptive_field, receptive_field)\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        time_axis = 1\n",
    "        row_axis = 2\n",
    "        col_axis = 3\n",
    "        if not dilated:\n",
    "            input_shape = (n_frames, receptive_field, receptive_field, n_channels)\n",
    "\n",
    "    x.append(Input(shape=input_shape))\n",
    "    # x.append(ImageNormalization3D(norm_method=norm_method, filter_size=receptive_field)(x[-1]))\n",
    "    # x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    if padding:\n",
    "        if padding_mode == 'reflect':\n",
    "            x.append(ReflectionPadding3D(padding=(win_z, win, win))(x[-1]))\n",
    "        elif padding_mode == 'zero':\n",
    "            x.append(ZeroPadding3D(padding=(win_z, win, win))([-1]))\n",
    "\n",
    "    if location:\n",
    "        x.append(Location3D(in_shape=tuple(x[-1].shape.as_list()[1:]))(x[-1]))\n",
    "        x.append(Concatenate(axis=channel_axis)([x[-2], x[-1]]))\n",
    "\n",
    "    if multires:\n",
    "        layers_to_concat = []\n",
    "\n",
    "    rf_counter = receptive_field\n",
    "    block_counter = 0\n",
    "    d = 1\n",
    "\n",
    "    append_gru = False\n",
    "    while rf_counter > 4:\n",
    "        filter_size = 3 if rf_counter % 2 == 0 else 4\n",
    "        x.append(Conv3D(n_conv_filters, (1, filter_size, filter_size), \n",
    "                        dilation_rate=(1, d, d), kernel_initializer=init,\n",
    "                        padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "\n",
    "        \n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "        block_counter += 1\n",
    "        rf_counter -= filter_size - 1\n",
    "\n",
    "        if block_counter % 2 == 0:\n",
    "            if dilated:\n",
    "                x.append(DilatedMaxPool3D(dilation_rate=(1, d, d), pool_size=(1, 2, 2))(x[-1]))\n",
    "                d *= 2\n",
    "            else:\n",
    "                x.append(MaxPool3D(pool_size=(1, 2, 2))(x[-1]))\n",
    "\n",
    "            if VGG_mode:\n",
    "                n_conv_filters *= 2\n",
    "\n",
    "            rf_counter = rf_counter // 2\n",
    "\n",
    "            if multires:\n",
    "                layers_to_concat.append(len(x) - 1)\n",
    "\n",
    "    if multires:\n",
    "        c = []\n",
    "        for l in layers_to_concat:\n",
    "            output_shape = x[l].get_shape().as_list()\n",
    "            target_shape = x[-1].get_shape().as_list()\n",
    "            time_crop = (0, 0)\n",
    "\n",
    "            row_crop = int(output_shape[row_axis] - target_shape[row_axis])\n",
    "\n",
    "            if row_crop % 2 == 0:\n",
    "                row_crop = (row_crop // 2, row_crop // 2)\n",
    "            else:\n",
    "                row_crop = (row_crop // 2, row_crop // 2 + 1)\n",
    "\n",
    "            col_crop = int(output_shape[col_axis] - target_shape[col_axis])\n",
    "\n",
    "            if col_crop % 2 == 0:\n",
    "                col_crop = (col_crop // 2, col_crop // 2)\n",
    "            else:\n",
    "                col_crop = (col_crop // 2, col_crop // 2 + 1)\n",
    "\n",
    "            cropping = (time_crop, row_crop, col_crop)\n",
    "\n",
    "            c.append(Cropping3D(cropping=cropping)(x[l]))\n",
    "        x.append(Concatenate(axis=channel_axis)(c))\n",
    "        \n",
    "    \n",
    "    x.append(Conv3D(n_dense_filters, (1, rf_counter, rf_counter), dilation_rate=(1, d, d), kernel_initializer=init, padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(Conv3D(n_dense_filters, (n_frames, 1, 1), dilation_rate=(1, d, d), kernel_initializer=init, padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "    \n",
    "    x.append(TensorProduct(n_dense_filters, kernel_initializer=init, kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(TensorProduct(n_features, kernel_initializer=init, kernel_regularizer=l2(reg))(x[-1]))\n",
    "\n",
    "    if not dilated:\n",
    "        x.append(Flatten()(x[-1]))\n",
    "\n",
    "    if include_top:\n",
    "        x.append(Softmax(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    model = Model(inputs=x[0], outputs=x[-1])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Lambda;\n",
    "\n",
    "def image_norm(inputs):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    axes = [3, 4] if channel_axis == 1 else [2, 3]\n",
    "    output = inputs - K.mean(inputs, axis=axes, keepdims=True)\n",
    "    output = output / K.std(inputs, axis=axes, keepdims=True)\n",
    "    return output\n",
    "\n",
    "def feature_net_skip_3D(receptive_field=61,\n",
    "                        input_shape=(5, 256, 256, 1),\n",
    "                        fgbg_model=None,\n",
    "                        gru=False,\n",
    "                        gru_kernel_size=3,\n",
    "                        last_only=True,\n",
    "                        n_skips=1,\n",
    "                        norm_method='whole_image',\n",
    "                        padding_mode='reflect',\n",
    "                        **kwargs):\n",
    "    # print(K.image_data_format())\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    img = Lambda(image_norm)(inputs)\n",
    "    #img = BatchNormalization(axis=channel_axis)(inputs)\n",
    "\n",
    "    models = []\n",
    "    model_outputs = []\n",
    "\n",
    "    if fgbg_model is not None:\n",
    "        for layer in fgbg_model.layers:\n",
    "            layer.trainable = False\n",
    "        models.append(fgbg_model)\n",
    "        fgbg_output = fgbg_model(inputs)\n",
    "        if isinstance(fgbg_output, list):\n",
    "            fgbg_output = fgbg_output[-1]\n",
    "        model_outputs.append(fgbg_output)\n",
    "\n",
    "    for _ in range(n_skips + 1):\n",
    "        if model_outputs:\n",
    "            model_input = Concatenate(axis=channel_axis)([img, model_outputs[-1]])\n",
    "        else:\n",
    "            model_input = img\n",
    "        new_input_shape = model_input.get_shape().as_list()[1:]\n",
    "        models.append(feature_net_3D(receptive_field=receptive_field, \n",
    "                                     input_shape=new_input_shape, norm_method=None, dilated=True, \n",
    "                                     padding=True, padding_mode=padding_mode, gru=gru, \n",
    "                                     gru_kernel_size=gru_kernel_size, **kwargs))\n",
    "        model_outputs.append(models[-1](model_input))\n",
    "\n",
    "    if last_only:\n",
    "        model = Model(inputs=inputs, outputs=model_outputs[-1])\n",
    "    else:\n",
    "        if fgbg_model is None:\n",
    "            model = Model(inputs=inputs, outputs=model_outputs)\n",
    "        else:\n",
    "            model = Model(inputs=inputs, outputs=model_outputs[1:])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_conv(model,\n",
    "                     #dataset,\n",
    "                     train_dict,\n",
    "                     test_dict,\n",
    "                     expt='',\n",
    "                     test_size=.1,\n",
    "                     n_epoch=10,\n",
    "                     batch_size=1,\n",
    "                     num_gpus=None,\n",
    "                     frames_per_batch=5,\n",
    "                     transform=None,\n",
    "                     optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "                     log_dir='/data/tensorboard_logs',\n",
    "                     model_dir='/data/models',\n",
    "                     model_name=None,\n",
    "                     focal=False,\n",
    "                     gamma=0.5,\n",
    "                     lr_sched=rate_scheduler(lr=0.01, decay=0.95),\n",
    "                     rotation_range=0,\n",
    "                     flip=True,\n",
    "                     shear=0,\n",
    "                     zoom_range=0,\n",
    "                     seed=None,\n",
    "                     **kwargs):\n",
    "    is_channels_first = K.image_data_format() == 'channels_first'\n",
    "\n",
    "    if model_name is None:\n",
    "        todays_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "        data_name = os.path.splitext(os.path.basename(dataset))[0]\n",
    "        model_name = '{}_{}_{}'.format(todays_date, data_name, expt)\n",
    "    model_path = os.path.join(model_dir, '{}.h5'.format(model_name))\n",
    "    loss_path = os.path.join(model_dir, '{}.npz'.format(model_name))\n",
    "    \n",
    "    # train_dict, test_dict = get_data(dataset, mode='conv', test_size=test_size)\n",
    "\n",
    "    n_classes = model.layers[-1].output_shape[1 if is_channels_first else -1]\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    print('X_train shape:', train_dict['X'].shape)\n",
    "    print('y_train shape:', train_dict['y'].shape)\n",
    "    print('X_test shape:', test_dict['X'].shape)\n",
    "    print('y_test shape:', test_dict['y'].shape)\n",
    "    print('Output Shape:', model.layers[-1].output_shape)\n",
    "    print('Number of Classes:', n_classes)\n",
    "\n",
    "    def loss_function(y_true, y_pred):\n",
    "        if isinstance(transform, str) and transform.lower() == 'disc':\n",
    "            return losses.discriminative_instance_loss(y_true, y_pred)\n",
    "        if focal:\n",
    "            return losses.weighted_focal_loss(\n",
    "                y_true, y_pred, gamma=gamma, n_classes=n_classes)\n",
    "        return losses.weighted_categorical_crossentropy(\n",
    "            y_true, y_pred, n_classes=n_classes, from_logits=False)\n",
    "\n",
    "    if num_gpus is None:\n",
    "        num_gpus = train_utils.count_gpus()\n",
    "\n",
    "    if num_gpus >= 2:\n",
    "        batch_size = batch_size * num_gpus\n",
    "        model = train_utils.MultiGpuModel(model, num_gpus)\n",
    "\n",
    "    print('Training on {} GPUs'.format(num_gpus))\n",
    "\n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    if isinstance(model.output_shape, list):\n",
    "        skip = len(model.output_shape) - 1\n",
    "    else:\n",
    "        skip = None\n",
    "\n",
    "    if train_dict['X'].ndim == 4:\n",
    "        DataGenerator = image_generators.ImageFullyConvDataGenerator\n",
    "    elif train_dict['X'].ndim == 5:\n",
    "        DataGenerator = stack_generator.StackDataGenerator\n",
    "    else:\n",
    "        raise ValueError('Expected `X` to have ndim 4 or 5. Got',\n",
    "                         train_dict['X'].ndim)\n",
    "\n",
    "    if num_gpus >= 2:\n",
    "        # Each GPU must have at least one validation example\n",
    "        if test_dict['y'].shape[0] < num_gpus:\n",
    "            raise ValueError('Not enough validation data for {} GPUs. '\n",
    "                             'Received {} validation sample.'.format(\n",
    "                                 test_dict['y'].shape[0], num_gpus))\n",
    "\n",
    "        # When using multiple GPUs and skip_connections,\n",
    "        # the training data must be evenly distributed across all GPUs\n",
    "        num_train = train_dict['y'].shape[0]\n",
    "        nb_samples = num_train - num_train % batch_size\n",
    "        if nb_samples:\n",
    "            train_dict['y'] = train_dict['y'][:nb_samples]\n",
    "            train_dict['X'] = train_dict['X'][:nb_samples]\n",
    "\n",
    "    # this will do preprocessing and realtime data augmentation\n",
    "    datagen = DataGenerator(\n",
    "        rotation_range=rotation_range,\n",
    "        shear_range=shear,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=flip,\n",
    "        vertical_flip=flip)\n",
    "\n",
    "    datagen_val = DataGenerator(\n",
    "        rotation_range=0,\n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        horizontal_flip=0,\n",
    "        vertical_flip=0)\n",
    "\n",
    "    if train_dict['X'].ndim == 5:\n",
    "        train_data = datagen_val.flow(\n",
    "            train_dict,\n",
    "            skip=skip,\n",
    "            batch_size=batch_size,\n",
    "            transform=transform,\n",
    "            transform_kwargs=kwargs,\n",
    "            frames_per_batch=frames_per_batch)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            skip=skip,\n",
    "            batch_size=batch_size,\n",
    "            transform=transform,\n",
    "            transform_kwargs=kwargs,\n",
    "            frames_per_batch=frames_per_batch)\n",
    "    else:\n",
    "        train_data = datagen.flow(\n",
    "            train_dict,\n",
    "            skip=skip,\n",
    "            batch_size=batch_size,\n",
    "            transform=transform,\n",
    "            transform_kwargs=kwargs)\n",
    "\n",
    "        val_data = datagen_val.flow(\n",
    "            test_dict,\n",
    "            skip=skip,\n",
    "            batch_size=batch_size,\n",
    "            transform=transform,\n",
    "            transform_kwargs=kwargs)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    loss_history = model.fit_generator(\n",
    "        train_data,\n",
    "        steps_per_epoch=train_data.y.shape[0] // batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=val_data.y.shape[0] // batch_size,\n",
    "        callbacks=[\n",
    "            callbacks.LearningRateScheduler(lr_sched),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                model_path, monitor='val_loss', verbose=1,\n",
    "                save_best_only=True, save_weights_only=num_gpus >= 2),\n",
    "            callbacks.TensorBoard(log_dir=os.path.join(log_dir, model_name))\n",
    "        ])\n",
    "\n",
    "    model.save_weights(model_path)\n",
    "    np.savez(loss_path, loss_history=loss_history.history)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pool_v2() got an unexpected keyword argument 'dilation_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dfe245a39762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmultires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlast_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         norm_method=norm_method)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m dapi_model = train_model_conv(\n",
      "\u001b[0;32m<ipython-input-7-371138f5c36e>\u001b[0m in \u001b[0;36mfeature_net_skip_3D\u001b[0;34m(receptive_field, input_shape, fgbg_model, gru, gru_kernel_size, last_only, n_skips, norm_method, padding_mode, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                      \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_input_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                      \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                      gru_kernel_size=gru_kernel_size, **kwargs))\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9c417bac0004>\u001b[0m in \u001b[0;36mfeature_net_3D\u001b[0;34m(receptive_field, n_frames, input_shape, n_features, n_channels, reg, n_conv_filters, n_dense_filters, gru_kernel_size, VGG_mode, init, norm_method, gru, location, dilated, padding, padding_mode, multires, include_top)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdilated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDilatedMaxPool3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m                       base_layer_utils.AutoAddUpdates(self,\n\u001b[1;32m    611\u001b[0m                                                       inputs)) as auto_updater:\n\u001b[0;32m--> 612\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m                 \u001b[0mauto_updater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepcell-tf/deepcell/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    181\u001b[0m                              \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                              \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                              data_format='NDHWC')\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: pool_v2() got an unexpected keyword argument 'dilation_rate'"
     ]
    }
   ],
   "source": [
    "dapi_model = feature_net_skip_3D(\n",
    "        receptive_field=receptive_field,\n",
    "        n_features=2,  # segmentation mask (is_cell, is_not_cell)\n",
    "        n_frames=frames_per_batch,\n",
    "        n_skips=n_skips,\n",
    "        n_conv_filters=32,\n",
    "        n_dense_filters=128,\n",
    "        input_shape=tuple([frames_per_batch] + list(train_dict['X'].shape[2:])),\n",
    "        multires=False,\n",
    "        last_only=False,\n",
    "        norm_method=norm_method)\n",
    "\n",
    "dapi_model = train_model_conv(\n",
    "    model=dapi_model,\n",
    "    train_dict=train_dict,\n",
    "    test_dict=test_dict,\n",
    "    model_name=fgbg_model_name,\n",
    "    test_size=test_size,\n",
    "    optimizer=optimizer,\n",
    "    n_epoch=n_epoch,\n",
    "    batch_size=batch_size,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    transform='fgbg',\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fgbg_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_model_name))\n",
    "# fgbg_model.save_weights(fgbg_weights_file)\n",
    "\n",
    "# watershed_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(watershed_model_name))\n",
    "# watershed_model.save_weights(watershed_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# run_fgbg_model = feature_net_skip_3D(\n",
    "#     receptive_field=receptive_field,\n",
    "#     n_features=2,\n",
    "#     n_frames=frames_per_batch,\n",
    "#     n_skips=n_skips,\n",
    "#     n_conv_filters=32,\n",
    "#     n_dense_filters=128,\n",
    "#     input_shape=tuple(test_dict['X'].shape[1:]),\n",
    "#     multires=False,\n",
    "#     last_only=False,\n",
    "#     norm_method=norm_method)\n",
    "# run_fgbg_model.load_weights(fgbg_weights_file)\n",
    "\n",
    "# run_watershed_model = feature_net_skip_3D(\n",
    "#     receptive_field=receptive_field,\n",
    "#     n_skips=n_skips,\n",
    "#     n_features=distance_bins,\n",
    "#     n_frames=frames_per_batch,\n",
    "#     gru=False,\n",
    "#     gru_kernel_size=3,\n",
    "#     n_conv_filters=32,\n",
    "#     n_dense_filters=128,\n",
    "#     multires=False,\n",
    "#     last_only=False,\n",
    "#     input_shape=tuple(test_dict['X'].shape[1:]),\n",
    "#     norm_method=norm_method)\n",
    "\n",
    "# run_watershed_model.load_weights(watershed_weights_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_images = run_watershed_model.predict(test_dict['X'])[-1]\n",
    "# test_images_fgbg = run_fgbg_model.predict(test_dict['X'])[-1]\n",
    "\n",
    "# # test_images = watershed_model.predict(test_dict['X'])[-1]\n",
    "# # test_images_fgbg = fgbg_model.predict(test_dict['X'])[-1]\n",
    "\n",
    "# print('watershed transform shape:', test_images.shape)\n",
    "# print('segmentation mask shape:', test_images_fgbg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
