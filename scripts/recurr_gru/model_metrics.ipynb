{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/vanvalenlab/deepcell-tf/blob/master/scripts/misc/Model_Metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sunnycui/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'/home/sunnycui/deepcell-tf/') \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "from skimage.measure import label\n",
    "from skimage import morphology\n",
    "\n",
    "import random\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)\n",
    "\n",
    "from deepcell import metrics\n",
    "\n",
    "MODEL_DIR = os.path.join(sys.path[0], 'scripts/recurr_gru/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from combined_data.npz\n",
      "X.shape: (68, 30, 135, 160, 1)\n",
      "y.shape: (68, 30, 135, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.data_utils import get_data\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "\n",
    "data_filename = 'combined_data.npz'\n",
    "# data_filename = '3T3_NIH.npz'\n",
    "data_path = os.path.join(sys.path[0], 'scripts/recurr_gru/data', data_filename)\n",
    "\n",
    "if not os.path.isfile(data_path):\n",
    "    print('downloading ' + data_filename)\n",
    "    data_path = get_file(data_filename,\n",
    "                    origin='https://deepcell-data.s3.amazonaws.com/nuclei/3T3_NIH.npz',\n",
    "                    file_hash='954b6f4ad6a71435b84c40726837e4ba')\n",
    "\n",
    "print(\"Loading data from \" + data_filename)\n",
    "train_dict, test_dict = get_data(data_path, test_size=0.1, seed=0)\n",
    "print('X.shape: {}\\ny.shape: {}'.format(test_dict['X'].shape, test_dict['y'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.layers import MaxPool3D, Conv3DTranspose, UpSampling3D\n",
    "from scripts.recurr_gru.conv_gru_layer import ConvGRU2D\n",
    "from tensorflow.python.keras.layers import BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.python.keras.layers import Conv3D, ZeroPadding3D, ConvLSTM2D, Cropping3D\n",
    "from tensorflow.python.keras.layers import Input, Add, Concatenate, Flatten\n",
    "from tensorflow.python.keras.engine.input_layer import InputLayer\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "from deepcell.layers import ImageNormalization3D\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Softmax\n",
    "\n",
    "from deepcell.layers import TensorProduct, ReflectionPadding3D, DilatedMaxPool3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_net_3D(receptive_field=61,\n",
    "                    n_frames=3,\n",
    "                    input_shape=(5, 256, 256, 1),\n",
    "                    n_features=3,\n",
    "                    n_channels=1,\n",
    "                    reg=1e-5,\n",
    "                    n_conv_filters=64,\n",
    "                    n_dense_filters=200,\n",
    "                    gru_kernel_size =3,\n",
    "                    VGG_mode=False,\n",
    "                    init='he_normal',\n",
    "                    norm_method='whole_image',\n",
    "                    gru=False,\n",
    "                    location=False,\n",
    "                    dilated=False,\n",
    "                    padding=False,\n",
    "                    padding_mode='reflect',\n",
    "                    multires=False,\n",
    "                    include_top=True):\n",
    "    # Create layers list (x) to store all of the layers.\n",
    "    # We need to use the functional API to enable the multiresolution mode\n",
    "    x = []\n",
    "\n",
    "    win = (receptive_field - 1) // 2\n",
    "    win_z = (n_frames - 1) // 2\n",
    "\n",
    "    if dilated:\n",
    "        padding = True\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        time_axis = 2\n",
    "        row_axis = 3\n",
    "        col_axis = 4\n",
    "        if not dilated:\n",
    "            input_shape = (n_channels, n_frames, receptive_field, receptive_field)\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        time_axis = 1\n",
    "        row_axis = 2\n",
    "        col_axis = 3\n",
    "        if not dilated:\n",
    "            input_shape = (n_frames, receptive_field, receptive_field, n_channels)\n",
    "\n",
    "    x.append(Input(shape=input_shape))\n",
    "    # x.append(ImageNormalization3D(norm_method=norm_method, filter_size=receptive_field)(x[-1]))\n",
    "    # x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    if padding:\n",
    "        if padding_mode == 'reflect':\n",
    "            x.append(ReflectionPadding3D(padding=(win_z, win, win))(x[-1]))\n",
    "        elif padding_mode == 'zero':\n",
    "            x.append(ZeroPadding3D(padding=(win_z, win, win))([-1]))\n",
    "\n",
    "    if location:\n",
    "        x.append(Location3D(in_shape=tuple(x[-1].shape.as_list()[1:]))(x[-1]))\n",
    "        x.append(Concatenate(axis=channel_axis)([x[-2], x[-1]]))\n",
    "\n",
    "    if multires:\n",
    "        layers_to_concat = []\n",
    "\n",
    "    rf_counter = receptive_field\n",
    "    block_counter = 0\n",
    "    d = 1\n",
    "\n",
    "    append_gru = False\n",
    "    while rf_counter > 4:\n",
    "        filter_size = 3 if rf_counter % 2 == 0 else 4\n",
    "        if append_gru == True:\n",
    "            x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=(filter_size, filter_size), dilation_rate=(d, d),\n",
    "                            padding='valid', kernel_initializer=init,\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        else:\n",
    "            x.append(Conv3D(n_conv_filters, (1, filter_size, filter_size), \n",
    "                            dilation_rate=(1, d, d), kernel_initializer=init,\n",
    "                            padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "\n",
    "        \n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "        block_counter += 1\n",
    "        rf_counter -= filter_size - 1\n",
    "\n",
    "        if block_counter % 2 == 0:\n",
    "            if dilated:\n",
    "                x.append(DilatedMaxPool3D(dilation_rate=(1, d, d), pool_size=(1, 2, 2))(x[-1]))\n",
    "                d *= 2\n",
    "            else:\n",
    "                x.append(MaxPool3D(pool_size=(1, 2, 2))(x[-1]))\n",
    "\n",
    "            if VGG_mode:\n",
    "                n_conv_filters *= 2\n",
    "\n",
    "            rf_counter = rf_counter // 2\n",
    "\n",
    "            if multires:\n",
    "                layers_to_concat.append(len(x) - 1)\n",
    "\n",
    "    if multires:\n",
    "        c = []\n",
    "        for l in layers_to_concat:\n",
    "            output_shape = x[l].get_shape().as_list()\n",
    "            target_shape = x[-1].get_shape().as_list()\n",
    "            time_crop = (0, 0)\n",
    "\n",
    "            row_crop = int(output_shape[row_axis] - target_shape[row_axis])\n",
    "\n",
    "            if row_crop % 2 == 0:\n",
    "                row_crop = (row_crop // 2, row_crop // 2)\n",
    "            else:\n",
    "                row_crop = (row_crop // 2, row_crop // 2 + 1)\n",
    "\n",
    "            col_crop = int(output_shape[col_axis] - target_shape[col_axis])\n",
    "\n",
    "            if col_crop % 2 == 0:\n",
    "                col_crop = (col_crop // 2, col_crop // 2)\n",
    "            else:\n",
    "                col_crop = (col_crop // 2, col_crop // 2 + 1)\n",
    "\n",
    "            cropping = (time_crop, row_crop, col_crop)\n",
    "\n",
    "            c.append(Cropping3D(cropping=cropping)(x[l]))\n",
    "        x.append(Concatenate(axis=channel_axis)(c))\n",
    "        \n",
    "    \n",
    "    x.append(Conv3D(n_dense_filters, (1, rf_counter, rf_counter), dilation_rate=(1, d, d), kernel_initializer=init, padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(Conv3D(n_dense_filters, (n_frames, 1, 1), dilation_rate=(1, d, d), kernel_initializer=init, padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "    \n",
    "    if gru == True:\n",
    "        x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=(gru_kernel_size, gru_kernel_size),\n",
    "                            padding='same', kernel_initializer=init, activation='relu',\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        # x.append(Activation('relu')(x[-1]))\n",
    "        x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=(gru_kernel_size +2, gru_kernel_size +2),\n",
    "                            padding='same', kernel_initializer=init, activation='relu',\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        # x.append(Activation('relu')(x[-1]))\n",
    "    \n",
    "    \n",
    "    x.append(TensorProduct(n_dense_filters, kernel_initializer=init, kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(TensorProduct(n_features, kernel_initializer=init, kernel_regularizer=l2(reg))(x[-1]))\n",
    "\n",
    "    if not dilated:\n",
    "        x.append(Flatten()(x[-1]))\n",
    "\n",
    "    if include_top:\n",
    "        x.append(Softmax(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    model = Model(inputs=x[0], outputs=x[-1])\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Lambda;\n",
    "\n",
    "def image_norm(inputs):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    axes = [3, 4] if channel_axis == 1 else [2, 3]\n",
    "    output = inputs - K.mean(inputs, axis=axes, keepdims=True)\n",
    "    output = output / K.std(inputs, axis=axes, keepdims=True)\n",
    "    return output\n",
    "\n",
    "def feature_net_skip_3D(receptive_field=61,\n",
    "                        input_shape=(5, 256, 256, 1),\n",
    "                        fgbg_model=None,\n",
    "                        gru=False,\n",
    "                        last_only=True,\n",
    "                        n_skips=1,\n",
    "                        norm_method='whole_image',\n",
    "                        padding_mode='reflect',\n",
    "                        **kwargs):\n",
    "    # print(K.image_data_format())\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    img = Lambda(image_norm)(inputs)\n",
    "\n",
    "    models = []\n",
    "    model_outputs = []\n",
    "\n",
    "    if fgbg_model is not None:\n",
    "        for layer in fgbg_model.layers:\n",
    "            layer.trainable = False\n",
    "        models.append(fgbg_model)\n",
    "        fgbg_output = fgbg_model(inputs)\n",
    "        if isinstance(fgbg_output, list):\n",
    "            fgbg_output = fgbg_output[-1]\n",
    "        model_outputs.append(fgbg_output)\n",
    "\n",
    "    for _ in range(n_skips + 1):\n",
    "        if model_outputs:\n",
    "            model_input = Concatenate(axis=channel_axis)([img, model_outputs[-1]])\n",
    "        else:\n",
    "            model_input = img\n",
    "        new_input_shape = model_input.get_shape().as_list()[1:]\n",
    "        models.append(feature_net_3D(receptive_field=receptive_field, \n",
    "                                     input_shape=new_input_shape, norm_method=None, dilated=True, \n",
    "                                     padding=True, padding_mode=padding_mode, gru=gru, **kwargs))\n",
    "        model_outputs.append(models[-1](model_input))\n",
    "\n",
    "    if last_only:\n",
    "        model = Model(inputs=inputs, outputs=model_outputs[-1])\n",
    "    else:\n",
    "        if fgbg_model is None:\n",
    "            model = Model(inputs=inputs, outputs=model_outputs)\n",
    "        else:\n",
    "            model = Model(inputs=inputs, outputs=model_outputs[1:])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gru_model(gru_kernel_size=3):\n",
    "    fgbg_gru_model = feature_net_skip_3D(\n",
    "                    receptive_field=61,\n",
    "                    n_features=2,\n",
    "                    n_frames=3,\n",
    "                    n_skips=1,\n",
    "                    gru=True,\n",
    "                    gru_kernel_size=gru_kernel_size,\n",
    "                    n_conv_filters=32,\n",
    "                    n_dense_filters=128,\n",
    "                    input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "                    multires=False,\n",
    "                    last_only=False,\n",
    "                    norm_method='wholeimage')\n",
    "\n",
    "    conv_gru_model = feature_net_skip_3D(\n",
    "                    # fgbg_model=run_fgbg_model,\n",
    "                    receptive_field=61,\n",
    "                    n_skips=1,\n",
    "                    n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "                    n_frames=3,\n",
    "                    n_conv_filters=32,\n",
    "                    n_dense_filters=128,\n",
    "                    gru=True,\n",
    "                    gru_kernel_size=gru_kernel_size,\n",
    "                    multires=False,\n",
    "                    last_only=False,\n",
    "                    input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "                    norm_method='whole_image')\n",
    "    return fgbg_gru_model, conv_gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_model():\n",
    "    fgbg_model = feature_net_skip_3D(\n",
    "            receptive_field=61,\n",
    "            n_features=2,\n",
    "            n_frames=3,\n",
    "            n_skips=1,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=False,\n",
    "            input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "            multires=False,\n",
    "            last_only=False,\n",
    "            norm_method='whole_image')\n",
    "\n",
    "    conv_model = feature_net_skip_3D(\n",
    "            # fgbg_model=run_fgbg_model,\n",
    "            receptive_field=61,\n",
    "            n_skips=1,\n",
    "            n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "            n_frames=3,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=False,\n",
    "            multires=False,\n",
    "            last_only=False,\n",
    "            input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "            norm_method='whole_image')\n",
    "    return fgbg_model, conv_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(test_images, test_images_fgbg):\n",
    "    argmax_images = []\n",
    "    for i in range(test_images.shape[0]):\n",
    "        max_image = np.argmax(test_images[i], axis=-1)\n",
    "        argmax_images.append(max_image)\n",
    "    argmax_images = np.array(argmax_images)\n",
    "    argmax_images = np.expand_dims(argmax_images, axis=-1)\n",
    "\n",
    "    print('argmax shape:', argmax_images.shape)\n",
    "\n",
    "    # threshold the foreground/background\n",
    "    # and remove back ground from edge transform\n",
    "    threshold = 0.9\n",
    "\n",
    "    fg_thresh = test_images_fgbg[..., 1] > threshold\n",
    "    fg_thresh = np.expand_dims(fg_thresh, axis=-1)\n",
    "\n",
    "    test_images_post_fgbg = test_images * fg_thresh\n",
    "\n",
    "\n",
    "    # Label interior predictions\n",
    "\n",
    "    labeled_images = []\n",
    "    for i in range(test_images_post_fgbg.shape[0]):\n",
    "        interior = test_images_post_fgbg[i, ..., 2] > .2\n",
    "        labeled_image = label(interior)\n",
    "        labeled_image = morphology.remove_small_objects(\n",
    "            labeled_image, min_size=50, connectivity=1)\n",
    "        labeled_images.append(labeled_image)\n",
    "    labeled_images = np.array(labeled_images)\n",
    "    labeled_images = np.expand_dims(labeled_images, axis=-1)\n",
    "\n",
    "    print('labeled_images shape:', labeled_images.shape)\n",
    "\n",
    "    return labeled_images, fg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = .10  # % of data saved as test\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# FC training settings\n",
    "n_skips = 1 # number of skip-connections (only for FC training)\n",
    "batch_size = 1  # FC training uses 1 image per batch\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'deepcell_flat' # 'watershed'\n",
    "dilation_radius = 1  # change dilation radius for edge dilation\n",
    "n_features = 4  # (cDell-background edge, cell-cell edge, cell interior, background)\n",
    "\n",
    "# 3D Settings\n",
    "frames_per_batch = 3\n",
    "norm_method = None #'whole_image'\n",
    "\n",
    "\n",
    "def test_gru(X_test, fgbg_gru_weights_file, conv_gru_weights_file, gru_kernel_size=3, gru=False):\n",
    "    run_fgbg_model = feature_net_skip_3D(\n",
    "        receptive_field=receptive_field,\n",
    "        n_features=2,\n",
    "        n_frames=frames_per_batch,\n",
    "        n_skips=n_skips,\n",
    "        n_conv_filters=32,\n",
    "        n_dense_filters=128,\n",
    "        input_shape=tuple(X_test.shape[1:]),\n",
    "        gru=gru,\n",
    "        gru_kernel_size=gru_kernel_size,\n",
    "        multires=False,\n",
    "        last_only=False,\n",
    "        norm_method=norm_method)\n",
    "\n",
    "    run_fgbg_model.load_weights(fgbg_gru_weights_file)\n",
    "\n",
    "    \n",
    "    run_conv_model = feature_net_skip_3D(\n",
    "        receptive_field=receptive_field,\n",
    "        n_skips=n_skips,\n",
    "        n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "        n_frames=frames_per_batch,\n",
    "        n_conv_filters=32,\n",
    "        n_dense_filters=128,\n",
    "        gru=gru,\n",
    "        gru_kernel_size=gru_kernel_size,\n",
    "        multires=False,\n",
    "        last_only=False,\n",
    "        input_shape=tuple(X_test.shape[1:]),\n",
    "        norm_method=norm_method)\n",
    "    run_conv_model.load_weights(conv_gru_weights_file)\n",
    "    \n",
    "    test_images = run_conv_model.predict(X_test)[-1]\n",
    "    test_images_fgbg = run_fgbg_model.predict(X_test)[-1]\n",
    "\n",
    "    print('edge/interior prediction shape:', test_images.shape)\n",
    "    print('fgbg mask shape:', test_images_fgbg.shape)\n",
    "\n",
    "    return test_images, test_images_fgbg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import metrics\n",
    "from statistics import mean \n",
    "import decimal\n",
    "\n",
    "\n",
    "def to_precision(x, p):\n",
    "    \"\"\"\n",
    "    returns a string representation of x formatted with a precision of p\n",
    "\n",
    "    Based on the webkit javascript implementation taken from here:\n",
    "    https://code.google.com/p/webkit-mirror/source/browse/JavaScriptCore/kjs/number_object.cpp\n",
    "    \"\"\"\n",
    "\n",
    "    decimal.getcontext().prec = p\n",
    "    return decimal.Decimal(x)\n",
    "\n",
    "def get_metrics(model, test_dict_X, test_dict_y, fgbg_weights, conv_weights, gru):\n",
    "    if model == 'fgbg':\n",
    "        m = metrics.Metrics('fgbg',seg=False)\n",
    "    elif model == 'segmentation':\n",
    "        m = metrics.Metrics('deepcell',seg=True)\n",
    "\n",
    "    n_true = []\n",
    "    n_pred = []\n",
    "    correct_detections = []\n",
    "    gained_detections = []\n",
    "    missed_detections = []\n",
    "    split = []\n",
    "    merge = []\n",
    "    catastrophe = []\n",
    "    seg = []\n",
    "    jaccard = []\n",
    "    gained_det_from_split = []\n",
    "    missed_det_from_merge = []\n",
    "    true_det_in_catastrophe = []\n",
    "    pred_det_in_catastrophe = []\n",
    "\n",
    "    for i in range(0, len(test_dict_y), 6):\n",
    "        top = min(i+6, len(test_dict_y))\n",
    "        X_test, y_test = test_dict_X[i:top], test_dict_y[i:top]\n",
    "        test_images, test_images_fgbg = test_gru(X_test, fgbg_weights, conv_weights, \n",
    "                                             gru_kernel_size=3, gru=gru)\n",
    "\n",
    "        y_pred, fg_thresh = post_process(test_images, test_images_fgbg)\n",
    "        if y_test.shape != y_pred.shape:\n",
    "            print(\"y_test.shape != y_pred.shape\")\n",
    "            print(\"y_test.shape: \", y_test.shape)\n",
    "            print(\"y_pred.shape: \", y_pred.shape)\n",
    "        \n",
    "        y_true_lbl = y_test[:,:,:,0].astype('int')\n",
    "        y_pred_lbl = y_pred[:,:,:,0]\n",
    "                \n",
    "        m.calc_object_stats(y_true_lbl,y_pred_lbl)\n",
    "        \n",
    "        n_true.append(m.stats['n_true'].sum())\n",
    "        n_pred.append(m.stats['n_pred'].sum())\n",
    "        correct_detections.append(m.stats['correct_detections'].sum())\n",
    "        missed_detections.append(m.stats['missed_detections'].sum())\n",
    "        gained_detections.append(m.stats['gained_detections'].sum())\n",
    "        catastrophe.append(m.stats['catastrophe'].sum())\n",
    "        merge.append(m.stats['merge'].sum())\n",
    "        split.append(m.stats['split'].sum())\n",
    "        \n",
    "        gained_det_from_split.append(m.stats['gained_det_from_split'].sum())\n",
    "        missed_det_from_merge.append(m.stats['missed_det_from_merge'].sum())\n",
    "        true_det_in_catastrophe.append(m.stats['true_det_in_catastrophe'].sum())\n",
    "        pred_det_in_catastrophe.append(m.stats['pred_det_in_catastrophe'].sum())\n",
    "        \n",
    "        jaccard.extend(m.stats['jaccard'])\n",
    "        \n",
    "        if m.seg is True:\n",
    "            seg = seg + m.stats['seg']\n",
    "        \n",
    "    print('\\n____________Object-based statistics____________\\n')\n",
    "    print('Number of true cells:\\t\\t', sum(n_true))\n",
    "    print('Number of predicted cells:\\t', sum(n_pred))\n",
    "\n",
    "    print('\\nCorrect detections:  {}\\tRecall: {}%'.format(\n",
    "        int(sum(correct_detections)),\n",
    "        to_precision(100 * sum(correct_detections) / sum(n_true),\n",
    "                     m.ndigits)))\n",
    "    print('Incorrect detections: {}\\tPrecision: {}%'.format(\n",
    "        int(sum(n_pred) - sum(correct_detections)),\n",
    "        to_precision(100 * sum(correct_detections) / sum(n_pred),\n",
    "                     m.ndigits)))\n",
    "\n",
    "    total_err = (sum(gained_detections)\n",
    "                 + sum(missed_detections)\n",
    "                 + sum(split)\n",
    "                 + sum(merge)\n",
    "                 + sum(catastrophe))\n",
    "\n",
    "    print('\\nGained detections: {}\\tPerc Error: {}%'.format(\n",
    "        int(sum(gained_detections)),\n",
    "        to_precision(100 * sum(gained_detections) / total_err, m.ndigits)))\n",
    "    print('Missed detections: {}\\tPerc Error: {}%'.format(\n",
    "        int(sum(missed_detections)),\n",
    "        to_precision(100 * sum(missed_detections) / total_err, m.ndigits)))\n",
    "    print('Merges: {}\\t\\tPerc Error: {}%'.format(\n",
    "        int(sum(merge)),\n",
    "        to_precision(100 * sum(merge) / total_err, m.ndigits)))\n",
    "    print('Splits: {}\\t\\tPerc Error: {}%'.format(\n",
    "        int(sum(split)),\n",
    "        to_precision(100 * sum(split) / total_err, m.ndigits)))\n",
    "    print('Catastrophes: {}\\t\\tPerc Error: {}%\\n'.format(\n",
    "        int(sum(catastrophe)),\n",
    "        to_precision(100 * sum(catastrophe) / total_err, m.ndigits)))\n",
    "\n",
    "    print('Gained detections from splits: {}'.format(\n",
    "        int(sum(gained_det_from_split))))\n",
    "    print('Missed detections from merges: {}'.format(\n",
    "        int(sum(missed_det_from_merge))))\n",
    "    print('True detections involved in catastrophes: {}'.format(\n",
    "        int(sum(true_det_in_catastrophe))))\n",
    "    print('Predicted detections involved in catastrophes: {}'.format(\n",
    "        int(sum(pred_det_in_catastrophe))), '\\n')\n",
    "\n",
    "    if m.seg is True:\n",
    "        print('SEG:', to_precision(mean(seg), m.ndigits), '\\n')\n",
    "\n",
    "    print('Average Pixel IOU (Jaccard Index):',\n",
    "          to_precision(mean(jaccard), m.ndigits), '\\n')\n",
    "\n",
    "#     return n_true, n_pred, correct_detections, gained_detections, \n",
    "#         missed_detections, split, merge, catastrophe, seg, jaccard, \n",
    "#         gained_det_from_split, missed_det_from_merge, \n",
    "#         true_det_in_catastrophe, pred_det_in_catastrophe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature net 3D (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "INFO:tensorflow:0 samples processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:113: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  dice = (2 * intersection.sum() / (pred.sum() + truth.sum()))\n",
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:114: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  jaccard = intersection.sum() / union.sum()\n",
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:115: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = intersection.sum() / pred.sum()\n",
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:116: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = intersection.sum() / truth.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:Prediction frame is empty\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "edge/interior prediction shape: (2, 30, 135, 160, 4)\n",
      "fgbg mask shape: (2, 30, 135, 160, 2)\n",
      "argmax shape: (2, 30, 135, 160, 1)\n",
      "labeled_images shape: (2, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 221\n",
      "Number of predicted cells:\t 167\n",
      "\n",
      "Correct detections:  66\tRecall: 29.86425339366515885330954915843904018402099609375%\n",
      "Incorrect detections: 101\tPrecision: 39.52095808383233332961026462726294994354248046875%\n",
      "\n",
      "Gained detections: 63\tPerc Error: 30.143540669856459857101071975193917751312255859375%\n",
      "Missed detections: 124\tPerc Error: 59.33014354066985873714656918309628963470458984375%\n",
      "Merges: 7\t\tPerc Error: 3.34928229665071786058661018614657223224639892578125%\n",
      "Splits: 15\t\tPerc Error: 7.1770334928229662097010077559389173984527587890625%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 16\n",
      "Missed detections from merges: 9\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): NaN \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "fgbg_model_name = 'fgbg_featurenet_model_full'\n",
    "fgbg_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_model_name))\n",
    "\n",
    "conv_model_name = 'conv_featurenet_model_full'\n",
    "conv_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_model_name))\n",
    "\n",
    "get_metrics('fgbg', test_dict['X'], test_dict['y'], fgbg_weights_file, conv_weights_file, False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "____________Object-based statistics____________\n",
    "\n",
    "Number of true cells:\t\t 221\n",
    "Number of predicted cells:\t 167\n",
    "\n",
    "Correct detections:  66\tRecall: 29.86425339366515885330954915843904018402099609375%\n",
    "Incorrect detections: 101\tPrecision: 39.52095808383233332961026462726294994354248046875%\n",
    "\n",
    "Gained detections: 63\tPerc Error: 30.143540669856459857101071975193917751312255859375%\n",
    "Missed detections: 124\tPerc Error: 59.33014354066985873714656918309628963470458984375%\n",
    "Merges: 7\t\tPerc Error: 3.34928229665071786058661018614657223224639892578125%\n",
    "Splits: 15\t\tPerc Error: 7.1770334928229662097010077559389173984527587890625%\n",
    "Catastrophes: 0\t\tPerc Error: 0%\n",
    "\n",
    "Gained detections from splits: 16\n",
    "Missed detections from merges: 9\n",
    "True detections involved in catastrophes: 0\n",
    "Predicted detections involved in catastrophes: 0 \n",
    "\n",
    "Average Pixel IOU (Jaccard Index): NaN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixelwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.683667  0.519372   0.927727  0.541273  0.683667\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.793892  0.658227   0.966374  0.673656  0.793892\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.795701  0.660717   0.995482  0.662704  0.795701\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.755852  0.607526   0.992752  0.610233  0.755852\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.618439  0.447638   0.592187  0.647126  0.618439\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.802582  0.670261   0.896204  0.726671  0.802582\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.801129  0.668237   0.961278  0.686722  0.801129\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.820884  0.696186   0.941316  0.727773  0.820884\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.712351  0.553219   0.946152  0.571203  0.712351\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.774828  0.632424     0.9738  0.643372  0.774828\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision  recall  Fmeasure\n",
      "0  0.754551  0.605847   0.756009  0.7531  0.754551\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (2, 30, 135, 160, 4)\n",
      "fgbg mask shape: (2, 30, 135, 160, 2)\n",
      "argmax shape: (2, 30, 135, 160, 1)\n",
      "labeled_images shape: (2, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.789015  0.651547   0.985472  0.657866  0.789015\n",
      "\n",
      "Confusion Matrix\n",
      "[[1296000]]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "pixel_df = None\n",
    "cms = []\n",
    "import pandas as pd \n",
    "\n",
    "fgbg_model_name = 'fgbg_featurenet_model_full'\n",
    "fgbg_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_model_name))\n",
    "\n",
    "conv_model_name = 'conv_featurenet_model_full'\n",
    "conv_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_model_name))\n",
    "m = metrics.Metrics('fgbg',seg=False)\n",
    "\n",
    "for i in range(0, len(test_dict['y']), 6):\n",
    "    top = min(i+6, len(test_dict['y']))\n",
    "    X_test, y_test = test_dict['X'][i:top], test_dict['y'][i:top]\n",
    "    test_images, test_images_fgbg = test_gru(X_test, fgbg_weights_file, conv_weights_file,\n",
    "                                     gru_kernel_size=3, gru=False)\n",
    "    y_pred, fg_thresh = post_process(test_images, test_images_fgbg)\n",
    "    m.all_pixel_stats(y_test, y_pred)\n",
    "    cms.append(m.cm)\n",
    "    if counter == 0:\n",
    "        pixel_df = m.pixel_df\n",
    "    else:\n",
    "        pixel_df = pixel_df.append(m.pixel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "dice         0.758574\n",
      "jaccard      0.614267\n",
      "precision    0.911229\n",
      "recall       0.658475\n",
      "Fmeasure     0.758574\n",
      "dtype: float64\n",
      "\n",
      "Confusion Matrix\n",
      "3888000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "print('\\n____________Pixel-based statistics____________\\n')\n",
    "temp_df = pd.DataFrame([[0.683667,  0.519372,   0.927727,  0.541273,  0.683667],\n",
    "[0.793892,  0.658227,   0.966374,  0.673656,  0.793892],\n",
    "[0.795701,  0.660717,   0.995482,  0.662704,  0.795701],\n",
    "[0.755852,  0.607526,   0.992752,  0.610233,  0.755852],\n",
    "[0.618439,  0.447638,   0.592187,  0.647126,  0.618439],\n",
    "[0.802582,  0.670261,   0.896204,  0.726671,  0.802582],\n",
    "[0.801129,  0.668237,   0.961278,  0.686722,  0.801129],\n",
    "[0.820884,  0.696186,   0.941316,  0.727773,  0.820884],\n",
    "[0.712351,  0.553219,   0.946152,  0.571203,  0.712351],\n",
    "[0.774828,  0.632424,     0.9738,  0.643372,  0.774828],\n",
    "[0.754551,  0.605847,   0.756009,  0.7531,  0.754551],\n",
    "[0.789015,  0.651547,   0.985472,  0.657866,  0.789015]], \n",
    "                       columns = [\"dice\",   \"jaccard\",  \"precision\",    \"recall\",  \"Fmeasure\"])\n",
    "print(temp_df.mean())\n",
    "print('\\nConfusion Matrix')\n",
    "temp_cms = [x[0][0] for x in cms[:-1]]\n",
    "print(mean(temp_cms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature net with ConvGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Kernel size (3, 3) and (5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "INFO:tensorflow:0 samples processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:113: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  dice = (2 * intersection.sum() / (pred.sum() + truth.sum()))\n",
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:114: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  jaccard = intersection.sum() / union.sum()\n",
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:115: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = intersection.sum() / pred.sum()\n",
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:116: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = intersection.sum() / truth.sum()\n",
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:117: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  Fmeasure = (2 * precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Prediction frame is empty\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:Prediction frame is empty\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Prediction frame is empty\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Prediction frame is empty\n",
      "edge/interior prediction shape: (2, 30, 135, 160, 4)\n",
      "fgbg mask shape: (2, 30, 135, 160, 2)\n",
      "argmax shape: (2, 30, 135, 160, 1)\n",
      "labeled_images shape: (2, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n",
      "WARNING:tensorflow:DICE score is technically 1.0, but prediction and truth arrays are empty. \n",
      "\n",
      "____________Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 221\n",
      "Number of predicted cells:\t 149\n",
      "\n",
      "Correct detections:  21\tRecall: 9.5022624434389140191115075140260159969329833984375%\n",
      "Incorrect detections: 128\tPrecision: 14.093959731543623803418086026795208454132080078125%\n",
      "\n",
      "Gained detections: 106\tPerc Error: 35.69023569023568853708638926036655902862548828125%\n",
      "Missed detections: 176\tPerc Error: 59.25925925925925952242323546670377254486083984375%\n",
      "Merges: 8\t\tPerc Error: 2.6936026936026937761425870121456682682037353515625%\n",
      "Splits: 7\t\tPerc Error: 2.356902356902356832080158710596151649951934814453125%\n",
      "Catastrophes: 0\t\tPerc Error: 0%\n",
      "\n",
      "Gained detections from splits: 7\n",
      "Missed detections from merges: 9\n",
      "True detections involved in catastrophes: 0\n",
      "Predicted detections involved in catastrophes: 0 \n",
      "\n",
      "Average Pixel IOU (Jaccard Index): NaN \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "fgbg_gru_model_name = 'fgbg_gru_featurenet_model_full'\n",
    "fgbg_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_gru_model_name))\n",
    "\n",
    "conv_gru_model_name = 'conv_gru_featurenet_model_full'\n",
    "conv_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_gru_model_name))\n",
    "\n",
    "# Predict\n",
    "get_metrics('fgbg', test_dict['X'], test_dict['y'], fgbg_gru_weights_file, conv_gru_weights_file, gru=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixelwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.343607  0.207443   0.928009  0.210836  0.343607\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "      dice  jaccard  precision    recall  Fmeasure\n",
      "0  0.58157  0.41001   0.962494  0.416667   0.58157\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.653242  0.485048   0.997939  0.485534  0.653242\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.533109  0.363428   0.996458  0.363898  0.533109\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice  jaccard  precision    recall  Fmeasure\n",
      "0  0.504673   0.3375   0.557467  0.461013  0.504673\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "      dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.46404  0.302117   0.935065  0.308591   0.46404\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "      dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.54703  0.376491   0.962544  0.382089   0.54703\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.623734  0.453208   0.929236  0.469409  0.623734\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.418123  0.264321   0.916296  0.270861  0.418123\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.579613  0.408067   0.982024  0.411139  0.579613\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.528312  0.358984    0.73029  0.413852  0.528312\n",
      "\n",
      "Confusion Matrix\n",
      "[[3888000]]\n",
      "edge/interior prediction shape: (2, 30, 135, 160, 4)\n",
      "fgbg mask shape: (2, 30, 135, 160, 2)\n",
      "argmax shape: (2, 30, 135, 160, 1)\n",
      "labeled_images shape: (2, 30, 135, 160, 1)\n",
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "       dice   jaccard  precision    recall  Fmeasure\n",
      "0  0.408233  0.256466        1.0  0.256466  0.408233\n",
      "\n",
      "Confusion Matrix\n",
      "[[1296000]]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "pixel_df = None\n",
    "cms = []\n",
    "\n",
    "fgbg_gru_model_name = 'fgbg_gru_featurenet_model_full'\n",
    "fgbg_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_gru_model_name))\n",
    "\n",
    "conv_gru_model_name = 'conv_gru_featurenet_model_full'\n",
    "conv_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_gru_model_name))\n",
    "m = metrics.Metrics('fgbg',seg=False)\n",
    "\n",
    "for i in range(0, len(test_dict['y']), 6):\n",
    "    top = min(i+6, len(test_dict['y']))\n",
    "    X_test, y_test = test_dict['X'][i:top], test_dict['y'][i:top]\n",
    "    test_images, test_images_fgbg = test_gru(X_test, fgbg_gru_weights_file, conv_gru_weights_file,\n",
    "                                     gru_kernel_size=3, gru=True)\n",
    "    y_pred, fg_thresh = post_process(test_images, test_images_fgbg)\n",
    "    m.all_pixel_stats(y_test, y_pred)\n",
    "    cms.append(m.cm)\n",
    "    if counter == 0:\n",
    "        pixel_df = m.pixel_df\n",
    "    else:\n",
    "        pixel_df = pixel_df.append(m.pixel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________Pixel-based statistics____________\n",
      "\n",
      "dice         0.515441\n",
      "jaccard      0.351924\n",
      "precision    0.908152\n",
      "recall       0.370863\n",
      "Fmeasure     0.515441\n",
      "dtype: float64\n",
      "\n",
      "Confusion Matrix\n",
      "3888000\n"
     ]
    }
   ],
   "source": [
    "print('\\n____________Pixel-based statistics____________\\n')\n",
    "temp_df = pd.DataFrame([[0.343607,  0.207443,   0.928009,  0.210836,  0.343607],\n",
    "[0.58157,  0.41001,   0.962494,  0.416667,   0.58157],\n",
    "[0.653242,  0.485048,   0.997939,  0.485534,  0.653242],\n",
    "[0.533109,  0.363428,   0.996458,  0.363898,  0.533109],\n",
    "[0.504673,   0.3375,   0.557467,  0.461013,  0.504673],\n",
    "[0.46404,  0.302117,   0.935065,  0.308591,   0.46404],\n",
    "[0.54703,  0.376491,   0.962544,  0.382089,   0.54703],\n",
    "[0.623734,  0.453208,   0.929236,  0.469409,  0.623734],\n",
    "[0.418123,  0.264321,   0.916296,  0.270861,  0.418123],\n",
    "[0.579613,  0.408067,   0.982024,  0.411139,  0.579613],\n",
    "[0.528312,  0.358984,    0.73029,  0.413852,  0.528312],\n",
    "[0.408233,  0.256466,        1.0,  0.256466,  0.408233]], \n",
    "                       columns = [\"dice\",   \"jaccard\",  \"precision\",    \"recall\",  \"Fmeasure\"])\n",
    "print(temp_df.mean())\n",
    "print('\\nConfusion Matrix')\n",
    "temp_cm = [3888000, 3888000, 3888000, 3888000, 3888000, 3888000, \n",
    "3888000, 3888000, 3888000, 3888000, 3888000, 1296000]\n",
    "print(mean(temp_cm[:-1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
