{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/vanvalenlab/deepcell-tf/blob/185406798a76cf52a812c650303200fa84af6d9d/scripts/misc/Model_Metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'/home/sunnycui/deepcell-tf/') \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "from skimage.measure import label\n",
    "from skimage import morphology\n",
    "\n",
    "\n",
    "import keras\n",
    "import random\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)\n",
    "\n",
    "from deepcell import metrics\n",
    "\n",
    "MODEL_DIR = os.path.join(sys.path[0], 'scripts/recurr_gru/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from combined_data.npz\n",
      "X.shape: (68, 30, 135, 160, 1)\n",
      "y.shape: (68, 30, 135, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.data_utils import get_data\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "\n",
    "data_filename = 'combined_data.npz'\n",
    "# data_filename = '3T3_NIH.npz'\n",
    "data_path = os.path.join(sys.path[0], 'scripts/recurr_gru/data', data_filename)\n",
    "\n",
    "if not os.path.isfile(data_path):\n",
    "    print('downloading ' + data_filename)\n",
    "    data_path = get_file(data_filename,\n",
    "                    origin='https://deepcell-data.s3.amazonaws.com/nuclei/3T3_NIH.npz',\n",
    "                    file_hash='954b6f4ad6a71435b84c40726837e4ba')\n",
    "\n",
    "print(\"Loading data from \" + data_filename)\n",
    "train_dict, test_dict = get_data(data_path, test_size=0.1, seed=0)\n",
    "print('X.shape: {}\\ny.shape: {}'.format(test_dict['X'].shape, test_dict['y'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.layers import MaxPool3D, Conv3DTranspose, UpSampling3D\n",
    "from scripts.recurr_gru.conv_gru_layer import ConvGRU2D\n",
    "from tensorflow.python.keras.layers import BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.python.keras.layers import Conv3D, ZeroPadding3D, ConvLSTM2D, Cropping3D\n",
    "from tensorflow.python.keras.layers import Input, Add, Concatenate, Flatten\n",
    "from tensorflow.python.keras.engine.input_layer import InputLayer\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "from deepcell.layers import ImageNormalization3D\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Softmax\n",
    "\n",
    "from deepcell.layers import TensorProduct, ReflectionPadding3D, DilatedMaxPool3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_net_3D(receptive_field=61,\n",
    "                    n_frames=3,\n",
    "                    input_shape=(5, 256, 256, 1),\n",
    "                    n_features=3,\n",
    "                    n_channels=1,\n",
    "                    reg=1e-5,\n",
    "                    n_conv_filters=64,\n",
    "                    n_dense_filters=200,\n",
    "                    gru_kernel_size =3,\n",
    "                    VGG_mode=False,\n",
    "                    init='he_normal',\n",
    "                    norm_method='whole_image',\n",
    "                    gru=False,\n",
    "                    location=False,\n",
    "                    dilated=False,\n",
    "                    padding=False,\n",
    "                    padding_mode='reflect',\n",
    "                    multires=False,\n",
    "                    include_top=True):\n",
    "    # Create layers list (x) to store all of the layers.\n",
    "    # We need to use the functional API to enable the multiresolution mode\n",
    "    x = []\n",
    "\n",
    "    win = (receptive_field - 1) // 2\n",
    "    win_z = (n_frames - 1) // 2\n",
    "\n",
    "    if dilated:\n",
    "        padding = True\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        time_axis = 2\n",
    "        row_axis = 3\n",
    "        col_axis = 4\n",
    "        if not dilated:\n",
    "            input_shape = (n_channels, n_frames, receptive_field, receptive_field)\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        time_axis = 1\n",
    "        row_axis = 2\n",
    "        col_axis = 3\n",
    "        if not dilated:\n",
    "            input_shape = (n_frames, receptive_field, receptive_field, n_channels)\n",
    "\n",
    "    x.append(Input(shape=input_shape))\n",
    "    # x.append(ImageNormalization3D(norm_method=norm_method, filter_size=receptive_field)(x[-1]))\n",
    "    # x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    if padding:\n",
    "        if padding_mode == 'reflect':\n",
    "            x.append(ReflectionPadding3D(padding=(win_z, win, win))(x[-1]))\n",
    "        elif padding_mode == 'zero':\n",
    "            x.append(ZeroPadding3D(padding=(win_z, win, win))([-1]))\n",
    "\n",
    "    if location:\n",
    "        x.append(Location3D(in_shape=tuple(x[-1].shape.as_list()[1:]))(x[-1]))\n",
    "        x.append(Concatenate(axis=channel_axis)([x[-2], x[-1]]))\n",
    "\n",
    "    if multires:\n",
    "        layers_to_concat = []\n",
    "\n",
    "    rf_counter = receptive_field\n",
    "    block_counter = 0\n",
    "    d = 1\n",
    "\n",
    "    append_gru = False\n",
    "    while rf_counter > 4:\n",
    "        filter_size = 3 if rf_counter % 2 == 0 else 4\n",
    "        if append_gru == True:\n",
    "            x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=(filter_size, filter_size), dilation_rate=(d, d),\n",
    "                            padding='valid', kernel_initializer=init,\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        else:\n",
    "            x.append(Conv3D(n_conv_filters, (1, filter_size, filter_size), \n",
    "                            dilation_rate=(1, d, d), kernel_initializer=init,\n",
    "                            padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "\n",
    "        \n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "        block_counter += 1\n",
    "        rf_counter -= filter_size - 1\n",
    "\n",
    "        if block_counter % 2 == 0:\n",
    "            if dilated:\n",
    "                x.append(DilatedMaxPool3D(dilation_rate=(1, d, d), pool_size=(1, 2, 2))(x[-1]))\n",
    "                d *= 2\n",
    "            else:\n",
    "                x.append(MaxPool3D(pool_size=(1, 2, 2))(x[-1]))\n",
    "\n",
    "            if VGG_mode:\n",
    "                n_conv_filters *= 2\n",
    "\n",
    "            rf_counter = rf_counter // 2\n",
    "\n",
    "            if multires:\n",
    "                layers_to_concat.append(len(x) - 1)\n",
    "\n",
    "    if multires:\n",
    "        c = []\n",
    "        for l in layers_to_concat:\n",
    "            output_shape = x[l].get_shape().as_list()\n",
    "            target_shape = x[-1].get_shape().as_list()\n",
    "            time_crop = (0, 0)\n",
    "\n",
    "            row_crop = int(output_shape[row_axis] - target_shape[row_axis])\n",
    "\n",
    "            if row_crop % 2 == 0:\n",
    "                row_crop = (row_crop // 2, row_crop // 2)\n",
    "            else:\n",
    "                row_crop = (row_crop // 2, row_crop // 2 + 1)\n",
    "\n",
    "            col_crop = int(output_shape[col_axis] - target_shape[col_axis])\n",
    "\n",
    "            if col_crop % 2 == 0:\n",
    "                col_crop = (col_crop // 2, col_crop // 2)\n",
    "            else:\n",
    "                col_crop = (col_crop // 2, col_crop // 2 + 1)\n",
    "\n",
    "            cropping = (time_crop, row_crop, col_crop)\n",
    "\n",
    "            c.append(Cropping3D(cropping=cropping)(x[l]))\n",
    "        x.append(Concatenate(axis=channel_axis)(c))\n",
    "        \n",
    "    \n",
    "    x.append(Conv3D(n_dense_filters, (1, rf_counter, rf_counter), dilation_rate=(1, d, d), kernel_initializer=init, padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(Conv3D(n_dense_filters, (n_frames, 1, 1), dilation_rate=(1, d, d), kernel_initializer=init, padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "    \n",
    "    if gru == True:\n",
    "        x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=(gru_kernel_size, gru_kernel_size),\n",
    "                            padding='same', kernel_initializer=init, activation='relu',\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        # x.append(Activation('relu')(x[-1]))\n",
    "        x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=(gru_kernel_size +2, gru_kernel_size +2),\n",
    "                            padding='same', kernel_initializer=init, activation='relu',\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        # x.append(Activation('relu')(x[-1]))\n",
    "    \n",
    "    \n",
    "    x.append(TensorProduct(n_dense_filters, kernel_initializer=init, kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(TensorProduct(n_features, kernel_initializer=init, kernel_regularizer=l2(reg))(x[-1]))\n",
    "\n",
    "    if not dilated:\n",
    "        x.append(Flatten()(x[-1]))\n",
    "\n",
    "    if include_top:\n",
    "        x.append(Softmax(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    model = Model(inputs=x[0], outputs=x[-1])\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Lambda;\n",
    "\n",
    "def image_norm(inputs):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    axes = [3, 4] if channel_axis == 1 else [2, 3]\n",
    "    output = inputs - K.mean(inputs, axis=axes, keepdims=True)\n",
    "    output = output / K.std(inputs, axis=axes, keepdims=True)\n",
    "    return output\n",
    "\n",
    "def feature_net_skip_3D(receptive_field=61,\n",
    "                        input_shape=(5, 256, 256, 1),\n",
    "                        fgbg_model=None,\n",
    "                        gru=False,\n",
    "                        last_only=True,\n",
    "                        n_skips=1,\n",
    "                        norm_method='whole_image',\n",
    "                        padding_mode='reflect',\n",
    "                        **kwargs):\n",
    "    # print(K.image_data_format())\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    img = Lambda(image_norm)(inputs)\n",
    "\n",
    "    models = []\n",
    "    model_outputs = []\n",
    "\n",
    "    if fgbg_model is not None:\n",
    "        for layer in fgbg_model.layers:\n",
    "            layer.trainable = False\n",
    "        models.append(fgbg_model)\n",
    "        fgbg_output = fgbg_model(inputs)\n",
    "        if isinstance(fgbg_output, list):\n",
    "            fgbg_output = fgbg_output[-1]\n",
    "        model_outputs.append(fgbg_output)\n",
    "\n",
    "    for _ in range(n_skips + 1):\n",
    "        if model_outputs:\n",
    "            model_input = Concatenate(axis=channel_axis)([img, model_outputs[-1]])\n",
    "        else:\n",
    "            model_input = img\n",
    "        new_input_shape = model_input.get_shape().as_list()[1:]\n",
    "        models.append(feature_net_3D(receptive_field=receptive_field, \n",
    "                                     input_shape=new_input_shape, norm_method=None, dilated=True, \n",
    "                                     padding=True, padding_mode=padding_mode, gru=gru, **kwargs))\n",
    "        model_outputs.append(models[-1](model_input))\n",
    "\n",
    "    if last_only:\n",
    "        model = Model(inputs=inputs, outputs=model_outputs[-1])\n",
    "    else:\n",
    "        if fgbg_model is None:\n",
    "            model = Model(inputs=inputs, outputs=model_outputs)\n",
    "        else:\n",
    "            model = Model(inputs=inputs, outputs=model_outputs[1:])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gru_model(gru_kernel_size=3):\n",
    "    fgbg_gru_model = feature_net_skip_3D(\n",
    "                    receptive_field=61,\n",
    "                    n_features=2,\n",
    "                    n_frames=3,\n",
    "                    n_skips=1,\n",
    "                    gru=True,\n",
    "                    gru_kernel_size=gru_kernel_size,\n",
    "                    n_conv_filters=32,\n",
    "                    n_dense_filters=128,\n",
    "                    input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "                    multires=False,\n",
    "                    last_only=False,\n",
    "                    norm_method='wholeimage')\n",
    "\n",
    "    conv_gru_model = feature_net_skip_3D(\n",
    "                    # fgbg_model=run_fgbg_model,\n",
    "                    receptive_field=61,\n",
    "                    n_skips=1,\n",
    "                    n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "                    n_frames=3,\n",
    "                    n_conv_filters=32,\n",
    "                    n_dense_filters=128,\n",
    "                    gru=True,\n",
    "                    gru_kernel_size=gru_kernel_size,\n",
    "                    multires=False,\n",
    "                    last_only=False,\n",
    "                    input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "                    norm_method='whole_image')\n",
    "    return fgbg_gru_model, conv_gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_model():\n",
    "    fgbg_model = feature_net_skip_3D(\n",
    "            receptive_field=61,\n",
    "            n_features=2,\n",
    "            n_frames=3,\n",
    "            n_skips=1,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=False,\n",
    "            input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "            multires=False,\n",
    "            last_only=False,\n",
    "            norm_method='whole_image')\n",
    "\n",
    "    conv_model = feature_net_skip_3D(\n",
    "            # fgbg_model=run_fgbg_model,\n",
    "            receptive_field=61,\n",
    "            n_skips=1,\n",
    "            n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "            n_frames=3,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=False,\n",
    "            multires=False,\n",
    "            last_only=False,\n",
    "            input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "            norm_method='whole_image')\n",
    "    return fgbg_model, conv_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(test_images, test_images_fgbg):\n",
    "    argmax_images = []\n",
    "    for i in range(test_images.shape[0]):\n",
    "        max_image = np.argmax(test_images[i], axis=-1)\n",
    "        argmax_images.append(max_image)\n",
    "    argmax_images = np.array(argmax_images)\n",
    "    argmax_images = np.expand_dims(argmax_images, axis=-1)\n",
    "\n",
    "    print('argmax shape:', argmax_images.shape)\n",
    "\n",
    "    # threshold the foreground/background\n",
    "    # and remove back ground from edge transform\n",
    "    threshold = 0.9\n",
    "\n",
    "    fg_thresh = test_images_fgbg[..., 1] > threshold\n",
    "    fg_thresh = np.expand_dims(fg_thresh, axis=-1)\n",
    "\n",
    "    test_images_post_fgbg = test_images * fg_thresh\n",
    "\n",
    "\n",
    "    # Label interior predictions\n",
    "\n",
    "    labeled_images = []\n",
    "    for i in range(test_images_post_fgbg.shape[0]):\n",
    "        interior = test_images_post_fgbg[i, ..., 2] > .2\n",
    "        labeled_image = label(interior)\n",
    "        labeled_image = morphology.remove_small_objects(\n",
    "            labeled_image, min_size=50, connectivity=1)\n",
    "        labeled_images.append(labeled_image)\n",
    "    labeled_images = np.array(labeled_images)\n",
    "    labeled_images = np.expand_dims(labeled_images, axis=-1)\n",
    "\n",
    "    print('labeled_images shape:', labeled_images.shape)\n",
    "\n",
    "    return labeled_images, fg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = .10  # % of data saved as test\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# FC training settings\n",
    "n_skips = 1 # number of skip-connections (only for FC training)\n",
    "batch_size = 1  # FC training uses 1 image per batch\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'deepcell_flat' # 'watershed'\n",
    "dilation_radius = 1  # change dilation radius for edge dilation\n",
    "n_features = 4  # (cDell-background edge, cell-cell edge, cell interior, background)\n",
    "\n",
    "# 3D Settings\n",
    "frames_per_batch = 3\n",
    "norm_method = None #'whole_image'\n",
    "\n",
    "\n",
    "def test_gru(X_test, fgbg_gru_weights_file, conv_gru_weights_file, gru_kernel_size=3, gru=False):\n",
    "    run_fgbg_model = feature_net_skip_3D(\n",
    "        receptive_field=receptive_field,\n",
    "        n_features=2,\n",
    "        n_frames=frames_per_batch,\n",
    "        n_skips=n_skips,\n",
    "        n_conv_filters=32,\n",
    "        n_dense_filters=128,\n",
    "        input_shape=tuple(X_test.shape[1:]),\n",
    "        gru=gru,\n",
    "        gru_kernel_size=gru_kernel_size,\n",
    "        multires=False,\n",
    "        last_only=False,\n",
    "        norm_method=norm_method)\n",
    "\n",
    "    run_fgbg_model.load_weights(fgbg_gru_weights_file)\n",
    "\n",
    "    \n",
    "    run_conv_model = feature_net_skip_3D(\n",
    "        receptive_field=receptive_field,\n",
    "        n_skips=n_skips,\n",
    "        n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "        n_frames=frames_per_batch,\n",
    "        n_conv_filters=32,\n",
    "        n_dense_filters=128,\n",
    "        gru=gru,\n",
    "        gru_kernel_size=gru_kernel_size,\n",
    "        multires=False,\n",
    "        last_only=False,\n",
    "        input_shape=tuple(X_test.shape[1:]),\n",
    "        norm_method=norm_method)\n",
    "    run_conv_model.load_weights(conv_gru_weights_file)\n",
    "    \n",
    "    test_images = run_conv_model.predict(X_test)[-1]\n",
    "    test_images_fgbg = run_fgbg_model.predict(X_test)[-1]\n",
    "\n",
    "    print('edge/interior prediction shape:', test_images.shape)\n",
    "    print('fgbg mask shape:', test_images_fgbg.shape)\n",
    "\n",
    "    return test_images, test_images_fgbg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import metrics\n",
    "\n",
    "def get_metrics(model, y_test, y_pred):\n",
    "    if model == 'fgbg':\n",
    "        m = metrics.Metrics('fgbg',seg=True)\n",
    "    elif model == 'segmentation':\n",
    "        m = metrics.Metrics('deepcell',seg=True)\n",
    "\n",
    "    n_true = []\n",
    "    n_pred = []\n",
    "    true_pos = []\n",
    "    false_pos = []\n",
    "    false_neg = []\n",
    "    merge = []\n",
    "    split = []\n",
    "    \n",
    "    assert y_test.shape == y_pred.shape\n",
    "\n",
    "    for f in range(y_test.shape[1]):\n",
    "        y_true_lbl = y_test[:,f,:,:,0].astype('int')\n",
    "\n",
    "        y_pred_lbl = y_pred[:,f,:,:,0] #label((y_pred[:,f,:,:,1]>0.9).astype('int'))\n",
    "        \n",
    "        \n",
    "        m.calc_object_stats(y_true_lbl,y_pred_lbl)\n",
    "        \n",
    "        n_true.append(m.stats['n_true'].sum())\n",
    "        n_pred.append(m.stats['n_pred'].sum())\n",
    "        true_pos.append(m.stats['true_pos'].sum())\n",
    "        false_pos.append(m.stats['false_pos'].sum())\n",
    "        false_neg.append(m.stats['false_neg'].sum())\n",
    "        merge.append(m.stats['merge'].sum())\n",
    "        split.append(m.stats['split'].sum())\n",
    "\n",
    "    n_true = int(np.sum(n_true))\n",
    "    n_pred = int(np.sum(n_pred))\n",
    "    true_pos = int(np.sum(true_pos))\n",
    "\n",
    "    false_pos = int(np.sum(false_pos))\n",
    "    false_neg = int(np.sum(false_neg))\n",
    "    split = int(np.sum(split))\n",
    "    merge = int(np.sum(merge))\n",
    "    \n",
    "\n",
    "    print('\\n____________FINAL Object-based statistics____________\\n')\n",
    "    print('Number of true cells:\\t\\t', int(np.sum(n_true)))\n",
    "    print('Number of predicted cells:\\t', int(np.sum(n_pred)))\n",
    "    print('\\nTrue positives:  {}\\tAccuracy:   {}%'.format(\n",
    "                int(np.sum(true_pos)),\n",
    "                100 * round(np.sum(true_pos) / np.sum(n_true), 4)))\n",
    "                \n",
    "    total_err = (np.sum(np.sum(false_pos) + np.sum(false_neg) + np.sum(split) + np.sum(merge)))\n",
    "    print('\\nFalse positives: {}\\tPerc Error: {}%'.format(int(np.sum(false_pos)), \n",
    "                  100 * round(np.sum(false_pos) / total_err, 4)))\n",
    "    print('False negatives: {}\\tPerc Error: {}%'.format( int(np.sum(false_neg)),\n",
    "                  100 * round(np.sum(false_neg) / total_err, 4)))\n",
    "    print('Merges:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(merge)),\n",
    "                  100 * round(np.sum(merge) / total_err, 4)))\n",
    "    print('Splits:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(split)),\n",
    "                  100 * round(np.sum(split) / total_err, 4)))\n",
    "\n",
    "    \n",
    "    return n_true, n_pred, false_pos, true_pos, false_neg, split, merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature net 3D (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 1401\n",
      "Number of predicted cells:\t 1096\n",
      "\n",
      "True positives:  782\tAccuracy:   55.82%\n",
      "\n",
      "False positives: 130\tPerc Error: 31.03%\n",
      "False negatives: 110\tPerc Error: 26.25%\n",
      "Merges:\t\t 178\tPerc Error: 42.480000000000004%\n",
      "Splits:\t\t 1\tPerc Error: 0.24%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 1401\n",
      "Number of predicted cells:\t 1273\n",
      "\n",
      "True positives:  1094\tAccuracy:   78.09%\n",
      "\n",
      "False positives: 94\tPerc Error: 35.88%\n",
      "False negatives: 88\tPerc Error: 33.589999999999996%\n",
      "Merges:\t\t 79\tPerc Error: 30.15%\n",
      "Splits:\t\t 1\tPerc Error: 0.38%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-e9fcdc36288c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     test_images, test_images_fgbg = test_gru(X_test, fgbg_weights_file, conv_weights_file, \n\u001b[0;32m---> 26\u001b[0;31m                                          gru_kernel_size=3, gru=False)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlabeled_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images_fgbg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-cce55bbcf053>\u001b[0m in \u001b[0;36mtest_gru\u001b[0;34m(X_test, fgbg_gru_weights_file, conv_gru_weights_file, gru_kernel_size, gru)\u001b[0m\n\u001b[1;32m     32\u001b[0m         norm_method=norm_method)\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mrun_fgbg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgbg_gru_weights_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    804\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    805\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2774\u001b[0m         \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m       \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    463\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 719\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1277\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "fgbg_model_name = 'fgbg_featurenet_model_full'\n",
    "fgbg_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_model_name))\n",
    "\n",
    "conv_model_name = 'conv_featurenet_model_full'\n",
    "conv_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_model_name))\n",
    "\n",
    "# Initialize model\n",
    "# fgbg_model, conv_model = get_baseline_model()\n",
    "\n",
    "# Compile model\n",
    "# fgbg_model.compile(SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),metrics=['accuracy'])\n",
    "# fgbg_model.load_weights(fgbg_weights_file)\n",
    "\n",
    "# conv_model.compile(SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),metrics=['accuracy'])\n",
    "# conv_model.load_weights(conv_weights_file)\n",
    "\n",
    "# Predict\n",
    "fgbg_metrics = []\n",
    "seg_metrics = []\n",
    "\n",
    "for i in range(0, len(test_dict['X']), 6):\n",
    "    top = min(i+6, len(test_dict['X']))\n",
    "    X_test, y_test = test_dict['X'][i:top], test_dict['y'][i:top]\n",
    "    test_images, test_images_fgbg = test_gru(X_test, fgbg_weights_file, conv_weights_file, \n",
    "                                         gru_kernel_size=3, gru=False)\n",
    "\n",
    "    labeled_images, fg_thresh = post_process(test_images, test_images_fgbg)\n",
    "\n",
    "    fgbg_predict = fg_thresh\n",
    "    predict_seg = labeled_images\n",
    "\n",
    "    fgbg_metrics.append(get_metrics('fgbg', y_test, fgbg_predict))\n",
    "    seg_metrics.append(get_metrics('segmentation', y_test, predict_seg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_true = np.sum([i[0] for i in fgbg_metrics])\n",
    "n_pred = np.sum([i[1] for i in fgbg_metrics])\n",
    "true_pos = np.sum([i[2] for i in fgbg_metrics])\n",
    "false_pos = np.sum([i[3] for i in fgbg_metrics])\n",
    "false_neg = np.sum([i[4] for i in fgbg_metrics])\n",
    "split = np.sum([i[5] for i in fgbg_metrics])\n",
    "merge = np.sum([i[6] for i in fgbg_metrics])\n",
    "\n",
    "\n",
    "print('\\n____________FGBG FINAL Object-based statistics____________\\n')\n",
    "print('Number of true cells:\\t\\t', int(np.sum(n_true)))\n",
    "print('Number of predicted cells:\\t', int(np.sum(n_pred)))\n",
    "print('\\nTrue positives:  {}\\tAccuracy:   {}%'.format(\n",
    "            int(np.sum(true_pos)),\n",
    "            100 * round(np.sum(true_pos) / np.sum(n_true), 4)))\n",
    "\n",
    "total_err = (np.sum(np.sum(false_pos) + np.sum(false_neg) + np.sum(split) + np.sum(merge)))\n",
    "print('\\nFalse positives: {}\\tPerc Error: {}%'.format(int(np.sum(false_pos)), \n",
    "              100 * round(np.sum(false_pos) / total_err, 4)))\n",
    "print('False negatives: {}\\tPerc Error: {}%'.format( int(np.sum(false_neg)),\n",
    "              100 * round(np.sum(false_neg) / total_err, 4)))\n",
    "print('Merges:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(merge)),\n",
    "              100 * round(np.sum(merge) / total_err, 4)))\n",
    "print('Splits:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(split)),\n",
    "              100 * round(np.sum(split) / total_err, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_true = np.sum([i[0] for i in seg_metrics])\n",
    "n_pred = np.sum([i[1] for i in seg_metrics])\n",
    "true_pos = np.sum([i[2] for i in seg_metrics])\n",
    "false_pos = np.sum([i[3] for i in seg_metrics])\n",
    "false_neg = np.sum([i[4] for i in seg_metrics])\n",
    "split = np.sum([i[5] for i in seg_metrics])\n",
    "merge = np.sum([i[6] for i in seg_metrics])\n",
    "\n",
    "\n",
    "print('\\n____________SEGMENTATION FINAL Object-based statistics____________\\n')\n",
    "print('Number of true cells:\\t\\t', int(np.sum(n_true)))\n",
    "print('Number of predicted cells:\\t', int(np.sum(n_pred)))\n",
    "print('\\nTrue positives:  {}\\tAccuracy:   {}%'.format(\n",
    "            int(np.sum(true_pos)),\n",
    "            100 * round(np.sum(true_pos) / np.sum(n_true), 4)))\n",
    "\n",
    "total_err = (np.sum(np.sum(false_pos) + np.sum(false_neg) + np.sum(split) + np.sum(merge)))\n",
    "print('\\nFalse positives: {}\\tPerc Error: {}%'.format(int(np.sum(false_pos)), \n",
    "              100 * round(np.sum(false_pos) / total_err, 4)))\n",
    "print('False negatives: {}\\tPerc Error: {}%'.format( int(np.sum(false_neg)),\n",
    "              100 * round(np.sum(false_neg) / total_err, 4)))\n",
    "print('Merges:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(merge)),\n",
    "              100 * round(np.sum(merge) / total_err, 4)))\n",
    "print('Splits:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(split)),\n",
    "              100 * round(np.sum(split) / total_err, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature net with ConvGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Kernel size (3, 3) and (5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (2, 30, 135, 160, 4)\n",
      "fgbg mask shape: (2, 30, 135, 160, 2)\n",
      "argmax shape: (2, 30, 135, 160, 1)\n",
      "labeled_images shape: (2, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 681\n",
      "Number of predicted cells:\t 422\n",
      "\n",
      "True positives:  269\tAccuracy:   39.5%\n",
      "\n",
      "False positives: 41\tPerc Error: 16.14%\n",
      "False negatives: 101\tPerc Error: 39.76%\n",
      "Merges:\t\t 112\tPerc Error: 44.09%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 681\n",
      "Number of predicted cells:\t 586\n",
      "\n",
      "True positives:  513\tAccuracy:   75.33%\n",
      "\n",
      "False positives: 38\tPerc Error: 22.49%\n",
      "False negatives: 96\tPerc Error: 56.8%\n",
      "Merges:\t\t 35\tPerc Error: 20.71%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n",
      "edge/interior prediction shape: (2, 30, 135, 160, 4)\n",
      "fgbg mask shape: (2, 30, 135, 160, 2)\n",
      "argmax shape: (2, 30, 135, 160, 1)\n",
      "labeled_images shape: (2, 30, 135, 160, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6e594b476d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mpredict_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeled_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# fgbg_predict = fgbg_model.predict(X_test)[-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mfgbg_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fgbg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgbg_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# predict_seg = conv_model.predict(X_test)[-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-44607892abff>\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(model, y_test, y_pred)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0my_pred_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#label((y_pred[:,f,:,:,1]>0.9).astype('int'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_object_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_lbl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_lbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mn_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mn_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepcell-tf/deepcell/metrics.py\u001b[0m in \u001b[0;36mcalc_object_stats\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             o = ObjectAccuracy(skimage.measure.label(y_true[i]),\n\u001b[0;32m--> 594\u001b[0;31m                                \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m                                \u001b[0mcutoff1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutoff1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                                \u001b[0mcutoff2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutoff2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "fgbg_gru_model_name = 'fgbg_gru_featurenet_model_full'\n",
    "fgbg_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_gru_model_name))\n",
    "\n",
    "conv_gru_model_name = 'conv_gru_featurenet_model_full'\n",
    "conv_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_gru_model_name))\n",
    "\n",
    "\n",
    "\n",
    "# Predict\n",
    "fgbg_metrics = []\n",
    "seg_metrics = []\n",
    "\n",
    "for i in range(0, len(test_dict['X']), 2):\n",
    "    top = min(i+2, len(test_dict['X']))\n",
    "    X_test, y_test = test_dict['X'][i:top], test_dict['y'][i:top]\n",
    "    test_images, test_images_fgbg = test_gru(X_test, fgbg_gru_weights_file, conv_gru_weights_file, \n",
    "                                         gru_kernel_size=3, gru=True)\n",
    "\n",
    "    labeled_images, fg_thresh = post_process(test_images, test_images_fgbg)\n",
    "\n",
    "    fgbg_predict = fg_thresh[i:top]\n",
    "    predict_seg = labeled_images[i:top]\n",
    "    # fgbg_predict = fgbg_model.predict(X_test)[-1]\n",
    "    fgbg_metrics.append(get_metrics('fgbg', y_test, fgbg_predict))\n",
    "\n",
    "    # predict_seg = conv_model.predict(X_test)[-1]\n",
    "    seg_metrics.append(get_metrics('segmentation', y_test, predict_seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Kernel size (5, 5) and (7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 40, 216, 256, 1)   0         \n",
      "_________________________________________________________________\n",
      "reflection_padding3d_28 (Ref (None, 42, 276, 316, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_224 (Conv3D)          (None, 42, 273, 313, 32)  544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_252 (Bat (None, 42, 273, 313, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_268 (Activation)  (None, 42, 273, 313, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_225 (Conv3D)          (None, 42, 271, 311, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_253 (Bat (None, 42, 271, 311, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_269 (Activation)  (None, 42, 271, 311, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_84 (Dilat (None, 42, 270, 310, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_226 (Conv3D)          (None, 42, 266, 306, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_254 (Bat (None, 42, 266, 306, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_270 (Activation)  (None, 42, 266, 306, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_227 (Conv3D)          (None, 42, 262, 302, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_255 (Bat (None, 42, 262, 302, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_271 (Activation)  (None, 42, 262, 302, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_85 (Dilat (None, 42, 260, 300, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_228 (Conv3D)          (None, 42, 252, 292, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_256 (Bat (None, 42, 252, 292, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_272 (Activation)  (None, 42, 252, 292, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_229 (Conv3D)          (None, 42, 244, 284, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_257 (Bat (None, 42, 244, 284, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_273 (Activation)  (None, 42, 244, 284, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_86 (Dilat (None, 42, 240, 280, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_230 (Conv3D)          (None, 42, 216, 256, 128) 65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_258 (Bat (None, 42, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_274 (Activation)  (None, 42, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_231 (Conv3D)          (None, 40, 216, 256, 128) 49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_259 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_275 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_16 (ConvGRU2D)   (None, 40, 216, 256, 32)  384096    \n",
      "_________________________________________________________________\n",
      "activation_276 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_17 (ConvGRU2D)   (None, 40, 216, 256, 32)  301152    \n",
      "_________________________________________________________________\n",
      "activation_277 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "tensor_product_56 (TensorPro (None, 40, 216, 256, 128) 4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_260 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_278 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "tensor_product_57 (TensorPro (None, 40, 216, 256, 2)   258       \n",
      "_________________________________________________________________\n",
      "softmax_28 (Softmax)         (None, 40, 216, 256, 2)   0         \n",
      "=================================================================\n",
      "Total params: 853,762\n",
      "Trainable params: 852,610\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        (None, 40, 216, 256, 3)   0         \n",
      "_________________________________________________________________\n",
      "reflection_padding3d_29 (Ref (None, 42, 276, 316, 3)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_232 (Conv3D)          (None, 42, 273, 313, 32)  1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_261 (Bat (None, 42, 273, 313, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_279 (Activation)  (None, 42, 273, 313, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_233 (Conv3D)          (None, 42, 271, 311, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_262 (Bat (None, 42, 271, 311, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_280 (Activation)  (None, 42, 271, 311, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_87 (Dilat (None, 42, 270, 310, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_234 (Conv3D)          (None, 42, 266, 306, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_263 (Bat (None, 42, 266, 306, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_281 (Activation)  (None, 42, 266, 306, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_235 (Conv3D)          (None, 42, 262, 302, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_264 (Bat (None, 42, 262, 302, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_282 (Activation)  (None, 42, 262, 302, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_88 (Dilat (None, 42, 260, 300, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_236 (Conv3D)          (None, 42, 252, 292, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_265 (Bat (None, 42, 252, 292, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_283 (Activation)  (None, 42, 252, 292, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_237 (Conv3D)          (None, 42, 244, 284, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_266 (Bat (None, 42, 244, 284, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_284 (Activation)  (None, 42, 244, 284, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_89 (Dilat (None, 42, 240, 280, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_238 (Conv3D)          (None, 42, 216, 256, 128) 65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_267 (Bat (None, 42, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_285 (Activation)  (None, 42, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_239 (Conv3D)          (None, 40, 216, 256, 128) 49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_268 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_286 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_18 (ConvGRU2D)   (None, 40, 216, 256, 32)  384096    \n",
      "_________________________________________________________________\n",
      "activation_287 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_19 (ConvGRU2D)   (None, 40, 216, 256, 32)  301152    \n",
      "_________________________________________________________________\n",
      "activation_288 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "tensor_product_58 (TensorPro (None, 40, 216, 256, 128) 4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_269 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_289 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "tensor_product_59 (TensorPro (None, 40, 216, 256, 2)   258       \n",
      "_________________________________________________________________\n",
      "softmax_29 (Softmax)         (None, 40, 216, 256, 2)   0         \n",
      "=================================================================\n",
      "Total params: 854,786\n",
      "Trainable params: 853,634\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        (None, 40, 216, 256, 1)   0         \n",
      "_________________________________________________________________\n",
      "reflection_padding3d_30 (Ref (None, 42, 276, 316, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_240 (Conv3D)          (None, 42, 273, 313, 32)  544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_270 (Bat (None, 42, 273, 313, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_290 (Activation)  (None, 42, 273, 313, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_241 (Conv3D)          (None, 42, 271, 311, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_271 (Bat (None, 42, 271, 311, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_291 (Activation)  (None, 42, 271, 311, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_90 (Dilat (None, 42, 270, 310, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_242 (Conv3D)          (None, 42, 266, 306, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_272 (Bat (None, 42, 266, 306, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_292 (Activation)  (None, 42, 266, 306, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_243 (Conv3D)          (None, 42, 262, 302, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_273 (Bat (None, 42, 262, 302, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_293 (Activation)  (None, 42, 262, 302, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_91 (Dilat (None, 42, 260, 300, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_244 (Conv3D)          (None, 42, 252, 292, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_274 (Bat (None, 42, 252, 292, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_294 (Activation)  (None, 42, 252, 292, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_245 (Conv3D)          (None, 42, 244, 284, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_275 (Bat (None, 42, 244, 284, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_295 (Activation)  (None, 42, 244, 284, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_92 (Dilat (None, 42, 240, 280, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_246 (Conv3D)          (None, 42, 216, 256, 128) 65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_276 (Bat (None, 42, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_296 (Activation)  (None, 42, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_247 (Conv3D)          (None, 40, 216, 256, 128) 49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_277 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_297 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_20 (ConvGRU2D)   (None, 40, 216, 256, 32)  384096    \n",
      "_________________________________________________________________\n",
      "activation_298 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_21 (ConvGRU2D)   (None, 40, 216, 256, 32)  301152    \n",
      "_________________________________________________________________\n",
      "activation_299 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "tensor_product_60 (TensorPro (None, 40, 216, 256, 128) 4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_278 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_300 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "tensor_product_61 (TensorPro (None, 40, 216, 256, 4)   516       \n",
      "_________________________________________________________________\n",
      "softmax_30 (Softmax)         (None, 40, 216, 256, 4)   0         \n",
      "=================================================================\n",
      "Total params: 854,020\n",
      "Trainable params: 852,868\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        (None, 40, 216, 256, 5)   0         \n",
      "_________________________________________________________________\n",
      "reflection_padding3d_31 (Ref (None, 42, 276, 316, 5)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_248 (Conv3D)          (None, 42, 273, 313, 32)  2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_279 (Bat (None, 42, 273, 313, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_301 (Activation)  (None, 42, 273, 313, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_249 (Conv3D)          (None, 42, 271, 311, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_280 (Bat (None, 42, 271, 311, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_302 (Activation)  (None, 42, 271, 311, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_93 (Dilat (None, 42, 270, 310, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_250 (Conv3D)          (None, 42, 266, 306, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_281 (Bat (None, 42, 266, 306, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_303 (Activation)  (None, 42, 266, 306, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_251 (Conv3D)          (None, 42, 262, 302, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_282 (Bat (None, 42, 262, 302, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_304 (Activation)  (None, 42, 262, 302, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_94 (Dilat (None, 42, 260, 300, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_252 (Conv3D)          (None, 42, 252, 292, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_283 (Bat (None, 42, 252, 292, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_305 (Activation)  (None, 42, 252, 292, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_253 (Conv3D)          (None, 42, 244, 284, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_284 (Bat (None, 42, 244, 284, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_306 (Activation)  (None, 42, 244, 284, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_95 (Dilat (None, 42, 240, 280, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_254 (Conv3D)          (None, 42, 216, 256, 128) 65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_285 (Bat (None, 42, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_307 (Activation)  (None, 42, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_255 (Conv3D)          (None, 40, 216, 256, 128) 49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_286 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_308 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_22 (ConvGRU2D)   (None, 40, 216, 256, 32)  384096    \n",
      "_________________________________________________________________\n",
      "activation_309 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_23 (ConvGRU2D)   (None, 40, 216, 256, 32)  301152    \n",
      "_________________________________________________________________\n",
      "activation_310 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "tensor_product_62 (TensorPro (None, 40, 216, 256, 128) 4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_287 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_311 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "tensor_product_63 (TensorPro (None, 40, 216, 256, 4)   516       \n",
      "_________________________________________________________________\n",
      "softmax_31 (Softmax)         (None, 40, 216, 256, 4)   0         \n",
      "=================================================================\n",
      "Total params: 856,068\n",
      "Trainable params: 854,916\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"model_42\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_42\".\n",
      "WARNING:tensorflow:Output \"model_43\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_43\".\n",
      "WARNING:tensorflow:Output \"model_45\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_45\".\n",
      "WARNING:tensorflow:Output \"model_46\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_46\".\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 412\n",
      "Number of predicted cells:\t 381\n",
      "\n",
      "True positives:  341\tAccuracy:   82.77%\n",
      "\n",
      "False positives: 10\tPerc Error: 24.39%\n",
      "False negatives: 4\tPerc Error: 9.76%\n",
      "Merges:\t\t 27\tPerc Error: 65.85%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 412\n",
      "Number of predicted cells:\t 352\n",
      "\n",
      "True positives:  203\tAccuracy:   49.27%\n",
      "\n",
      "False positives: 149\tPerc Error: 41.620000000000005%\n",
      "False negatives: 209\tPerc Error: 58.379999999999995%\n",
      "Merges:\t\t 0\tPerc Error: 0.0%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "fgbg_gru_model_name = 'fgbg_gru_featurenet_model_k5'\n",
    "fgbg_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_gru_model_name))\n",
    "\n",
    "conv_gru_model_name = 'conv_gru_featurenet_model_k5'\n",
    "conv_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_gru_model_name))\n",
    "\n",
    "# Initialize Models\n",
    "fgbg_gru_model, conv_gru_model = get_gru_model(gru_kernel_size=5)\n",
    "\n",
    "# Compile models\n",
    "fgbg_gru_model.compile(SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),metrics=['accuracy'])\n",
    "fgbg_gru_model.load_weights(fgbg_gru_weights_file)\n",
    "\n",
    "conv_gru_model.compile(SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),metrics=['accuracy'])\n",
    "conv_gru_model.load_weights(conv_gru_weights_file)\n",
    "\n",
    "\n",
    "# Predict\n",
    "X_test, y_test = test_dict['X'][:2], test_dict['y'][:2]\n",
    "\n",
    "predict_gru = fgbg_gru_model.predict(X_test)[-1]\n",
    "print_metrics('fgbg', y_test, predict_gru)\n",
    "\n",
    "predict_seg = conv_gru_model.predict(X_test)[-1]\n",
    "print_metrics('segmentation', y_test, predict_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
