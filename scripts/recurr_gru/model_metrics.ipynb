{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/vanvalenlab/deepcell-tf/blob/185406798a76cf52a812c650303200fa84af6d9d/scripts/misc/Model_Metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'/home/sunnycui/deepcell-tf/') \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "from skimage.measure import label\n",
    "from skimage import morphology\n",
    "\n",
    "\n",
    "import keras\n",
    "import random\n",
    "np.random.seed(2019)\n",
    "random.seed(2019)\n",
    "\n",
    "from deepcell import metrics\n",
    "\n",
    "MODEL_DIR = os.path.join(sys.path[0], 'scripts/recurr_gru/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.utils.data_utils import get_data\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "\n",
    "data_filename = 'combined_data.npz'\n",
    "# data_filename = '3T3_NIH.npz'\n",
    "data_path = os.path.join(sys.path[0], 'scripts/recurr_gru/data', data_filename)\n",
    "\n",
    "if not os.path.isfile(data_path):\n",
    "    print('downloading ' + data_filename)\n",
    "    data_path = get_file(data_filename,\n",
    "                    origin='https://deepcell-data.s3.amazonaws.com/nuclei/3T3_NIH.npz',\n",
    "                    file_hash='954b6f4ad6a71435b84c40726837e4ba')\n",
    "\n",
    "print(\"Loading data from \" + data_filename)\n",
    "train_dict, test_dict = get_data(data_path, test_size=0.1, seed=0)\n",
    "print('X.shape: {}\\ny.shape: {}'.format(test_dict['X'].shape, test_dict['y'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import callbacks\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.layers import MaxPool3D, Conv3DTranspose, UpSampling3D\n",
    "from scripts.recurr_gru.conv_gru_layer import ConvGRU2D\n",
    "from tensorflow.python.keras.layers import BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.python.keras.layers import Conv3D, ZeroPadding3D, ConvLSTM2D, Cropping3D\n",
    "from tensorflow.python.keras.layers import Input, Add, Concatenate, Flatten\n",
    "from tensorflow.python.keras.engine.input_layer import InputLayer\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "from deepcell.layers import ImageNormalization3D\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Softmax\n",
    "\n",
    "from deepcell.layers import TensorProduct, ReflectionPadding3D, DilatedMaxPool3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_net_3D(receptive_field=61,\n",
    "                    n_frames=3,\n",
    "                    input_shape=(5, 256, 256, 1),\n",
    "                    n_features=3,\n",
    "                    n_channels=1,\n",
    "                    reg=1e-5,\n",
    "                    n_conv_filters=64,\n",
    "                    n_dense_filters=200,\n",
    "                    gru_kernel_size =3,\n",
    "                    VGG_mode=False,\n",
    "                    init='he_normal',\n",
    "                    norm_method='whole_image',\n",
    "                    gru=False,\n",
    "                    location=False,\n",
    "                    dilated=False,\n",
    "                    padding=False,\n",
    "                    padding_mode='reflect',\n",
    "                    multires=False,\n",
    "                    include_top=True):\n",
    "    # Create layers list (x) to store all of the layers.\n",
    "    # We need to use the functional API to enable the multiresolution mode\n",
    "    x = []\n",
    "\n",
    "    win = (receptive_field - 1) // 2\n",
    "    win_z = (n_frames - 1) // 2\n",
    "\n",
    "    if dilated:\n",
    "        padding = True\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        time_axis = 2\n",
    "        row_axis = 3\n",
    "        col_axis = 4\n",
    "        if not dilated:\n",
    "            input_shape = (n_channels, n_frames, receptive_field, receptive_field)\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "        time_axis = 1\n",
    "        row_axis = 2\n",
    "        col_axis = 3\n",
    "        if not dilated:\n",
    "            input_shape = (n_frames, receptive_field, receptive_field, n_channels)\n",
    "\n",
    "    x.append(Input(shape=input_shape))\n",
    "    # x.append(ImageNormalization3D(norm_method=norm_method, filter_size=receptive_field)(x[-1]))\n",
    "    # x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    if padding:\n",
    "        if padding_mode == 'reflect':\n",
    "            x.append(ReflectionPadding3D(padding=(win_z, win, win))(x[-1]))\n",
    "        elif padding_mode == 'zero':\n",
    "            x.append(ZeroPadding3D(padding=(win_z, win, win))([-1]))\n",
    "\n",
    "    if location:\n",
    "        x.append(Location3D(in_shape=tuple(x[-1].shape.as_list()[1:]))(x[-1]))\n",
    "        x.append(Concatenate(axis=channel_axis)([x[-2], x[-1]]))\n",
    "\n",
    "    if multires:\n",
    "        layers_to_concat = []\n",
    "\n",
    "    rf_counter = receptive_field\n",
    "    block_counter = 0\n",
    "    d = 1\n",
    "\n",
    "    append_gru = False\n",
    "    while rf_counter > 4:\n",
    "        filter_size = 3 if rf_counter % 2 == 0 else 4\n",
    "        if append_gru == True:\n",
    "            x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=(filter_size, filter_size), dilation_rate=(d, d),\n",
    "                            padding='valid', kernel_initializer=init,\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        else:\n",
    "            x.append(Conv3D(n_conv_filters, (1, filter_size, filter_size), \n",
    "                            dilation_rate=(1, d, d), kernel_initializer=init,\n",
    "                            padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "\n",
    "        \n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "        block_counter += 1\n",
    "        rf_counter -= filter_size - 1\n",
    "\n",
    "        if block_counter % 2 == 0:\n",
    "            if dilated:\n",
    "                x.append(DilatedMaxPool3D(dilation_rate=(1, d, d), pool_size=(1, 2, 2))(x[-1]))\n",
    "                d *= 2\n",
    "            else:\n",
    "                x.append(MaxPool3D(pool_size=(1, 2, 2))(x[-1]))\n",
    "\n",
    "            if VGG_mode:\n",
    "                n_conv_filters *= 2\n",
    "\n",
    "            rf_counter = rf_counter // 2\n",
    "\n",
    "            if multires:\n",
    "                layers_to_concat.append(len(x) - 1)\n",
    "\n",
    "    if multires:\n",
    "        c = []\n",
    "        for l in layers_to_concat:\n",
    "            output_shape = x[l].get_shape().as_list()\n",
    "            target_shape = x[-1].get_shape().as_list()\n",
    "            time_crop = (0, 0)\n",
    "\n",
    "            row_crop = int(output_shape[row_axis] - target_shape[row_axis])\n",
    "\n",
    "            if row_crop % 2 == 0:\n",
    "                row_crop = (row_crop // 2, row_crop // 2)\n",
    "            else:\n",
    "                row_crop = (row_crop // 2, row_crop // 2 + 1)\n",
    "\n",
    "            col_crop = int(output_shape[col_axis] - target_shape[col_axis])\n",
    "\n",
    "            if col_crop % 2 == 0:\n",
    "                col_crop = (col_crop // 2, col_crop // 2)\n",
    "            else:\n",
    "                col_crop = (col_crop // 2, col_crop // 2 + 1)\n",
    "\n",
    "            cropping = (time_crop, row_crop, col_crop)\n",
    "\n",
    "            c.append(Cropping3D(cropping=cropping)(x[l]))\n",
    "        x.append(Concatenate(axis=channel_axis)(c))\n",
    "        \n",
    "    \n",
    "    x.append(Conv3D(n_dense_filters, (1, rf_counter, rf_counter), dilation_rate=(1, d, d), kernel_initializer=init, padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(Conv3D(n_dense_filters, (n_frames, 1, 1), dilation_rate=(1, d, d), kernel_initializer=init, padding='valid', kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "    \n",
    "    if gru == True:\n",
    "        x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=(gru_kernel_size, gru_kernel_size),\n",
    "                            padding='same', kernel_initializer=init, activation='relu',\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        # x.append(Activation('relu')(x[-1]))\n",
    "        x.append(ConvGRU2D(filters=n_conv_filters, kernel_size=(gru_kernel_size +2, gru_kernel_size +2),\n",
    "                            padding='same', kernel_initializer=init, activation='relu',\n",
    "                            kernel_regularizer=l2(reg), return_sequences=True)(x[-1]))\n",
    "        x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "        # x.append(Activation('relu')(x[-1]))\n",
    "    \n",
    "    \n",
    "    x.append(TensorProduct(n_dense_filters, kernel_initializer=init, kernel_regularizer=l2(reg))(x[-1]))\n",
    "    x.append(BatchNormalization(axis=channel_axis)(x[-1]))\n",
    "    x.append(Activation('relu')(x[-1]))\n",
    "\n",
    "    x.append(TensorProduct(n_features, kernel_initializer=init, kernel_regularizer=l2(reg))(x[-1]))\n",
    "\n",
    "    if not dilated:\n",
    "        x.append(Flatten()(x[-1]))\n",
    "\n",
    "    if include_top:\n",
    "        x.append(Softmax(axis=channel_axis)(x[-1]))\n",
    "\n",
    "    model = Model(inputs=x[0], outputs=x[-1])\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Lambda;\n",
    "\n",
    "def image_norm(inputs):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    axes = [3, 4] if channel_axis == 1 else [2, 3]\n",
    "    output = inputs - K.mean(inputs, axis=axes, keepdims=True)\n",
    "    output = output / K.std(inputs, axis=axes, keepdims=True)\n",
    "    return output\n",
    "\n",
    "def feature_net_skip_3D(receptive_field=61,\n",
    "                        input_shape=(5, 256, 256, 1),\n",
    "                        fgbg_model=None,\n",
    "                        gru=False,\n",
    "                        last_only=True,\n",
    "                        n_skips=1,\n",
    "                        norm_method='whole_image',\n",
    "                        padding_mode='reflect',\n",
    "                        **kwargs):\n",
    "    # print(K.image_data_format())\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    img = Lambda(image_norm)(inputs)\n",
    "\n",
    "    models = []\n",
    "    model_outputs = []\n",
    "\n",
    "    if fgbg_model is not None:\n",
    "        for layer in fgbg_model.layers:\n",
    "            layer.trainable = False\n",
    "        models.append(fgbg_model)\n",
    "        fgbg_output = fgbg_model(inputs)\n",
    "        if isinstance(fgbg_output, list):\n",
    "            fgbg_output = fgbg_output[-1]\n",
    "        model_outputs.append(fgbg_output)\n",
    "\n",
    "    for _ in range(n_skips + 1):\n",
    "        if model_outputs:\n",
    "            model_input = Concatenate(axis=channel_axis)([img, model_outputs[-1]])\n",
    "        else:\n",
    "            model_input = img\n",
    "        new_input_shape = model_input.get_shape().as_list()[1:]\n",
    "        models.append(feature_net_3D(receptive_field=receptive_field, \n",
    "                                     input_shape=new_input_shape, norm_method=None, dilated=True, \n",
    "                                     padding=True, padding_mode=padding_mode, gru=gru, **kwargs))\n",
    "        model_outputs.append(models[-1](model_input))\n",
    "\n",
    "    if last_only:\n",
    "        model = Model(inputs=inputs, outputs=model_outputs[-1])\n",
    "    else:\n",
    "        if fgbg_model is None:\n",
    "            model = Model(inputs=inputs, outputs=model_outputs)\n",
    "        else:\n",
    "            model = Model(inputs=inputs, outputs=model_outputs[1:])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gru_model(gru_kernel_size=3):\n",
    "    fgbg_gru_model = feature_net_skip_3D(\n",
    "                    receptive_field=61,\n",
    "                    n_features=2,\n",
    "                    n_frames=3,\n",
    "                    n_skips=1,\n",
    "                    gru=True,\n",
    "                    gru_kernel_size=gru_kernel_size,\n",
    "                    n_conv_filters=32,\n",
    "                    n_dense_filters=128,\n",
    "                    input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "                    multires=False,\n",
    "                    last_only=False,\n",
    "                    norm_method='wholeimage')\n",
    "\n",
    "    conv_gru_model = feature_net_skip_3D(\n",
    "                    # fgbg_model=run_fgbg_model,\n",
    "                    receptive_field=61,\n",
    "                    n_skips=1,\n",
    "                    n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "                    n_frames=3,\n",
    "                    n_conv_filters=32,\n",
    "                    n_dense_filters=128,\n",
    "                    gru=True,\n",
    "                    gru_kernel_size=gru_kernel_size,\n",
    "                    multires=False,\n",
    "                    last_only=False,\n",
    "                    input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "                    norm_method='whole_image')\n",
    "    return fgbg_gru_model, conv_gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_model():\n",
    "    fgbg_model = feature_net_skip_3D(\n",
    "            receptive_field=61,\n",
    "            n_features=2,\n",
    "            n_frames=3,\n",
    "            n_skips=1,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=False,\n",
    "            input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "            multires=False,\n",
    "            last_only=False,\n",
    "            norm_method='whole_image')\n",
    "\n",
    "    conv_model = feature_net_skip_3D(\n",
    "            # fgbg_model=run_fgbg_model,\n",
    "            receptive_field=61,\n",
    "            n_skips=1,\n",
    "            n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "            n_frames=3,\n",
    "            n_conv_filters=32,\n",
    "            n_dense_filters=128,\n",
    "            gru=False,\n",
    "            multires=False,\n",
    "            last_only=False,\n",
    "            input_shape=tuple(train_dict['X'].shape[1:]),\n",
    "            norm_method='whole_image')\n",
    "    return fgbg_model, conv_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(test_images, test_images_fgbg):\n",
    "    argmax_images = []\n",
    "    for i in range(test_images.shape[0]):\n",
    "        max_image = np.argmax(test_images[i], axis=-1)\n",
    "        argmax_images.append(max_image)\n",
    "    argmax_images = np.array(argmax_images)\n",
    "    argmax_images = np.expand_dims(argmax_images, axis=-1)\n",
    "\n",
    "    print('argmax shape:', argmax_images.shape)\n",
    "\n",
    "    # threshold the foreground/background\n",
    "    # and remove back ground from edge transform\n",
    "    threshold = 0.9\n",
    "\n",
    "    fg_thresh = test_images_fgbg[..., 1] > threshold\n",
    "    fg_thresh = np.expand_dims(fg_thresh, axis=-1)\n",
    "\n",
    "    test_images_post_fgbg = test_images * fg_thresh\n",
    "\n",
    "\n",
    "    # Label interior predictions\n",
    "\n",
    "    labeled_images = []\n",
    "    for i in range(test_images_post_fgbg.shape[0]):\n",
    "        interior = test_images_post_fgbg[i, ..., 2] > .2\n",
    "        labeled_image = label(interior)\n",
    "        labeled_image = morphology.remove_small_objects(\n",
    "            labeled_image, min_size=50, connectivity=1)\n",
    "        labeled_images.append(labeled_image)\n",
    "    labeled_images = np.array(labeled_images)\n",
    "    labeled_images = np.expand_dims(labeled_images, axis=-1)\n",
    "\n",
    "    print('labeled_images shape:', labeled_images.shape)\n",
    "\n",
    "    return labeled_images, fg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = .10  # % of data saved as test\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# FC training settings\n",
    "n_skips = 1 # number of skip-connections (only for FC training)\n",
    "batch_size = 1  # FC training uses 1 image per batch\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'deepcell_flat' # 'watershed'\n",
    "dilation_radius = 1  # change dilation radius for edge dilation\n",
    "n_features = 4  # (cDell-background edge, cell-cell edge, cell interior, background)\n",
    "\n",
    "# 3D Settings\n",
    "frames_per_batch = 3\n",
    "norm_method = None #'whole_image'\n",
    "\n",
    "\n",
    "def test_gru(X_test, fgbg_gru_weights_file, conv_gru_weights_file, gru_kernel_size=3, gru=False):\n",
    "    run_fgbg_model = feature_net_skip_3D(\n",
    "        receptive_field=receptive_field,\n",
    "        n_features=2,\n",
    "        n_frames=frames_per_batch,\n",
    "        n_skips=n_skips,\n",
    "        n_conv_filters=32,\n",
    "        n_dense_filters=128,\n",
    "        input_shape=tuple(X_test.shape[1:]),\n",
    "        gru=gru,\n",
    "        gru_kernel_size=gru_kernel_size,\n",
    "        multires=False,\n",
    "        last_only=False,\n",
    "        norm_method=norm_method)\n",
    "\n",
    "    run_fgbg_model.load_weights(fgbg_gru_weights_file)\n",
    "\n",
    "    \n",
    "    run_conv_model = feature_net_skip_3D(\n",
    "        receptive_field=receptive_field,\n",
    "        n_skips=n_skips,\n",
    "        n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "        n_frames=frames_per_batch,\n",
    "        n_conv_filters=32,\n",
    "        n_dense_filters=128,\n",
    "        gru=gru,\n",
    "        gru_kernel_size=gru_kernel_size,\n",
    "        multires=False,\n",
    "        last_only=False,\n",
    "        input_shape=tuple(X_test.shape[1:]),\n",
    "        norm_method=norm_method)\n",
    "    run_conv_model.load_weights(conv_gru_weights_file)\n",
    "    \n",
    "    test_images = run_conv_model.predict(X_test)[-1]\n",
    "    test_images_fgbg = run_fgbg_model.predict(X_test)[-1]\n",
    "\n",
    "    print('edge/interior prediction shape:', test_images.shape)\n",
    "    print('fgbg mask shape:', test_images_fgbg.shape)\n",
    "\n",
    "    return test_images, test_images_fgbg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import metrics\n",
    "\n",
    "def get_metrics(model, y_test, y_pred):\n",
    "    if model == 'fgbg':\n",
    "        m = metrics.Metrics('fgbg',seg=True)\n",
    "    elif model == 'segmentation':\n",
    "        m = metrics.Metrics('deepcell',seg=True)\n",
    "\n",
    "    n_true = []\n",
    "    n_pred = []\n",
    "    true_pos = []\n",
    "    false_pos = []\n",
    "    false_neg = []\n",
    "    merge = []\n",
    "    split = []\n",
    "    \n",
    "    if y_test.shape != y_pred.shape:\n",
    "        print(\"y_test.shape != y_pred.shape\")\n",
    "        print(\"y_test.shape: \", y_test.shape)\n",
    "        print(\"y_pred.shape: \", y_pred.shape)\n",
    "\n",
    "    for f in range(y_test.shape[1]):\n",
    "        y_true_lbl = y_test[:,f,:,:,0].astype('int')\n",
    "\n",
    "        y_pred_lbl = y_pred[:,f,:,:,0] #label((y_pred[:,f,:,:,1]>0.9).astype('int'))\n",
    "        \n",
    "        \n",
    "        m.calc_object_stats(y_true_lbl,y_pred_lbl)\n",
    "        \n",
    "        n_true.append(m.stats['n_true'].sum())\n",
    "        n_pred.append(m.stats['n_pred'].sum())\n",
    "        true_pos.append(m.stats['true_pos'].sum())\n",
    "        false_pos.append(m.stats['false_pos'].sum())\n",
    "        false_neg.append(m.stats['false_neg'].sum())\n",
    "        merge.append(m.stats['merge'].sum())\n",
    "        split.append(m.stats['split'].sum())\n",
    "\n",
    "    n_true = int(np.sum(n_true))\n",
    "    n_pred = int(np.sum(n_pred))\n",
    "    true_pos = int(np.sum(true_pos))\n",
    "\n",
    "    false_pos = int(np.sum(false_pos))\n",
    "    false_neg = int(np.sum(false_neg))\n",
    "    split = int(np.sum(split))\n",
    "    merge = int(np.sum(merge))\n",
    "    \n",
    "\n",
    "    print('\\n____________FINAL Object-based statistics____________\\n')\n",
    "    print('Number of true cells:\\t\\t', int(np.sum(n_true)))\n",
    "    print('Number of predicted cells:\\t', int(np.sum(n_pred)))\n",
    "    print('\\nTrue positives:  {}\\tAccuracy:   {}%'.format(\n",
    "                int(np.sum(true_pos)),\n",
    "                100 * round(np.sum(true_pos) / np.sum(n_true), 4)))\n",
    "                \n",
    "    total_err = (np.sum(np.sum(false_pos) + np.sum(false_neg) + np.sum(split) + np.sum(merge)))\n",
    "    print('\\nFalse positives: {}\\tPerc Error: {}%'.format(int(np.sum(false_pos)), \n",
    "                  100 * round(np.sum(false_pos) / total_err, 4)))\n",
    "    print('False negatives: {}\\tPerc Error: {}%'.format( int(np.sum(false_neg)),\n",
    "                  100 * round(np.sum(false_neg) / total_err, 4)))\n",
    "    print('Merges:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(merge)),\n",
    "                  100 * round(np.sum(merge) / total_err, 4)))\n",
    "    print('Splits:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(split)),\n",
    "                  100 * round(np.sum(split) / total_err, 4)))\n",
    "\n",
    "    \n",
    "    return n_true, n_pred, false_pos, true_pos, false_neg, split, merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature net 3D (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunnycui/deepcell-tf/deepcell/metrics.py:283: RuntimeWarning: Mean of empty slice\n",
      "  self.true_pos_ind[1]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 1401\n",
      "Number of predicted cells:\t 1096\n",
      "\n",
      "True positives:  782\tAccuracy:   55.82%\n",
      "\n",
      "False positives: 130\tPerc Error: 31.03%\n",
      "False negatives: 110\tPerc Error: 26.25%\n",
      "Merges:\t\t 178\tPerc Error: 42.480000000000004%\n",
      "Splits:\t\t 1\tPerc Error: 0.24%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 1401\n",
      "Number of predicted cells:\t 1273\n",
      "\n",
      "True positives:  1094\tAccuracy:   78.09%\n",
      "\n",
      "False positives: 94\tPerc Error: 35.88%\n",
      "False negatives: 88\tPerc Error: 33.589999999999996%\n",
      "Merges:\t\t 79\tPerc Error: 30.15%\n",
      "Splits:\t\t 1\tPerc Error: 0.38%\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2374\n",
      "Number of predicted cells:\t 1785\n",
      "\n",
      "True positives:  1512\tAccuracy:   63.690000000000005%\n",
      "\n",
      "False positives: 23\tPerc Error: 4.88%\n",
      "False negatives: 206\tPerc Error: 43.74%\n",
      "Merges:\t\t 239\tPerc Error: 50.739999999999995%\n",
      "Splits:\t\t 3\tPerc Error: 0.64%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2374\n",
      "Number of predicted cells:\t 2138\n",
      "\n",
      "True positives:  2006\tAccuracy:   84.5%\n",
      "\n",
      "False positives: 21\tPerc Error: 8.27%\n",
      "False negatives: 129\tPerc Error: 50.79%\n",
      "Merges:\t\t 99\tPerc Error: 38.98%\n",
      "Splits:\t\t 5\tPerc Error: 1.97%\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2769\n",
      "Number of predicted cells:\t 2030\n",
      "\n",
      "True positives:  1628\tAccuracy:   58.79%\n",
      "\n",
      "False positives: 69\tPerc Error: 9.26%\n",
      "False negatives: 353\tPerc Error: 47.38%\n",
      "Merges:\t\t 314\tPerc Error: 42.15%\n",
      "Splits:\t\t 9\tPerc Error: 1.21%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2769\n",
      "Number of predicted cells:\t 2460\n",
      "\n",
      "True positives:  2248\tAccuracy:   81.17999999999999%\n",
      "\n",
      "False positives: 72\tPerc Error: 15.86%\n",
      "False negatives: 262\tPerc Error: 57.709999999999994%\n",
      "Merges:\t\t 104\tPerc Error: 22.91%\n",
      "Splits:\t\t 16\tPerc Error: 3.52%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2329\n",
      "Number of predicted cells:\t 1680\n",
      "\n",
      "True positives:  1393\tAccuracy:   59.809999999999995%\n",
      "\n",
      "False positives: 62\tPerc Error: 10.33%\n",
      "False negatives: 320\tPerc Error: 53.33%\n",
      "Merges:\t\t 216\tPerc Error: 36.0%\n",
      "Splits:\t\t 2\tPerc Error: 0.33%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2329\n",
      "Number of predicted cells:\t 2053\n",
      "\n",
      "True positives:  1915\tAccuracy:   82.22%\n",
      "\n",
      "False positives: 52\tPerc Error: 16.25%\n",
      "False negatives: 187\tPerc Error: 58.440000000000005%\n",
      "Merges:\t\t 78\tPerc Error: 24.38%\n",
      "Splits:\t\t 3\tPerc Error: 0.9400000000000001%\n"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "fgbg_model_name = 'fgbg_featurenet_model_full'\n",
    "fgbg_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_model_name))\n",
    "\n",
    "conv_model_name = 'conv_featurenet_model_full'\n",
    "conv_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_model_name))\n",
    "\n",
    "# Initialize model\n",
    "# fgbg_model, conv_model = get_baseline_model()\n",
    "\n",
    "# Compile model\n",
    "# fgbg_model.compile(SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),metrics=['accuracy'])\n",
    "# fgbg_model.load_weights(fgbg_weights_file)\n",
    "\n",
    "# conv_model.compile(SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),metrics=['accuracy'])\n",
    "# conv_model.load_weights(conv_weights_file)\n",
    "\n",
    "# Predict\n",
    "fgbg_metrics = []\n",
    "seg_metrics = []\n",
    "\n",
    "for i in range(0, len(test_dict['X']), 6):\n",
    "    top = min(i+6, len(test_dict['X']))\n",
    "    X_test, y_test = test_dict['X'][i:top], test_dict['y'][i:top]\n",
    "    test_images, test_images_fgbg = test_gru(X_test, fgbg_weights_file, conv_weights_file, \n",
    "                                         gru_kernel_size=3, gru=False)\n",
    "\n",
    "    labeled_images, fg_thresh = post_process(test_images, test_images_fgbg)\n",
    "\n",
    "    fgbg_predict = fg_thresh\n",
    "    predict_seg = labeled_images\n",
    "\n",
    "    fgbg_metrics.append(get_metrics('fgbg', y_test, fgbg_predict))\n",
    "    seg_metrics.append(get_metrics('segmentation', y_test, predict_seg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________FGBG FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 12828\n",
      "Number of predicted cells:\t 9410\n",
      "\n",
      "True positives:  7267\tAccuracy:   56.65%\n",
      "\n",
      "False positives: 702\tPerc Error: 17.91%\n",
      "False negatives: 1819\tPerc Error: 46.400000000000006%\n",
      "Merges:\t\t 1390\tPerc Error: 35.46%\n",
      "Splits:\t\t 9\tPerc Error: 0.22999999999999998%\n"
     ]
    }
   ],
   "source": [
    "n_true = np.sum([i[0] for i in fgbg_metrics])\n",
    "n_pred = np.sum([i[1] for i in fgbg_metrics])\n",
    "false_pos = np.sum([i[2] for i in fgbg_metrics])\n",
    "true_pos = np.sum([i[3] for i in fgbg_metrics])\n",
    "false_neg = np.sum([i[4] for i in fgbg_metrics])\n",
    "split = np.sum([i[5] for i in fgbg_metrics])\n",
    "merge = np.sum([i[6] for i in fgbg_metrics])\n",
    "\n",
    "\n",
    "print('\\n____________FGBG FINAL Object-based statistics____________\\n')\n",
    "print('Number of true cells:\\t\\t', int(np.sum(n_true)))\n",
    "print('Number of predicted cells:\\t', int(np.sum(n_pred)))\n",
    "print('\\nTrue positives:  {}\\tAccuracy:   {}%'.format(\n",
    "            int(np.sum(true_pos)),\n",
    "            100 * round(np.sum(true_pos) / np.sum(n_true), 4)))\n",
    "\n",
    "total_err = (np.sum(np.sum(false_pos) + np.sum(false_neg) + np.sum(split) + np.sum(merge)))\n",
    "print('\\nFalse positives: {}\\tPerc Error: {}%'.format(int(np.sum(false_pos)), \n",
    "              100 * round(np.sum(false_pos) / total_err, 4)))\n",
    "print('False negatives: {}\\tPerc Error: {}%'.format( int(np.sum(false_neg)),\n",
    "              100 * round(np.sum(false_neg) / total_err, 4)))\n",
    "print('Merges:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(merge)),\n",
    "              100 * round(np.sum(merge) / total_err, 4)))\n",
    "print('Splits:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(split)),\n",
    "              100 * round(np.sum(split) / total_err, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________SEGMENTATION FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 12828\n",
      "Number of predicted cells:\t 11630\n",
      "\n",
      "True positives:  10581\tAccuracy:   82.48%\n",
      "\n",
      "False positives: 628\tPerc Error: 27.779999999999998%\n",
      "False negatives: 1271\tPerc Error: 56.21000000000001%\n",
      "Merges:\t\t 327\tPerc Error: 14.46%\n",
      "Splits:\t\t 35\tPerc Error: 1.55%\n"
     ]
    }
   ],
   "source": [
    "n_true = np.sum([i[0] for i in seg_metrics])\n",
    "n_pred = np.sum([i[1] for i in seg_metrics])\n",
    "false_pos = np.sum([i[2] for i in seg_metrics])\n",
    "true_pos = np.sum([i[3] for i in seg_metrics])\n",
    "false_neg = np.sum([i[4] for i in seg_metrics])\n",
    "split = np.sum([i[5] for i in seg_metrics])\n",
    "merge = np.sum([i[6] for i in seg_metrics])\n",
    "\n",
    "\n",
    "print('\\n____________SEGMENTATION FINAL Object-based statistics____________\\n')\n",
    "print('Number of true cells:\\t\\t', int(np.sum(n_true)))\n",
    "print('Number of predicted cells:\\t', int(np.sum(n_pred)))\n",
    "print('\\nTrue positives:  {}\\tAccuracy:   {}%'.format(\n",
    "            int(np.sum(true_pos)),\n",
    "            100 * round(np.sum(true_pos) / np.sum(n_true), 4)))\n",
    "\n",
    "total_err = (np.sum(np.sum(false_pos) + np.sum(false_neg) + np.sum(split) + np.sum(merge)))\n",
    "print('\\nFalse positives: {}\\tPerc Error: {}%'.format(int(np.sum(false_pos)), \n",
    "              100 * round(np.sum(false_pos) / total_err, 4)))\n",
    "print('False negatives: {}\\tPerc Error: {}%'.format( int(np.sum(false_neg)),\n",
    "              100 * round(np.sum(false_neg) / total_err, 4)))\n",
    "print('Merges:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(merge)),\n",
    "              100 * round(np.sum(merge) / total_err, 4)))\n",
    "print('Splits:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(split)),\n",
    "              100 * round(np.sum(split) / total_err, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature net with ConvGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Kernel size (3, 3) and (5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 1401\n",
      "Number of predicted cells:\t 1010\n",
      "\n",
      "True positives:  603\tAccuracy:   43.04%\n",
      "\n",
      "False positives: 226\tPerc Error: 31.39%\n",
      "False negatives: 313\tPerc Error: 43.47%\n",
      "Merges:\t\t 181\tPerc Error: 25.14%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 1401\n",
      "Number of predicted cells:\t 1257\n",
      "\n",
      "True positives:  1013\tAccuracy:   72.31%\n",
      "\n",
      "False positives: 199\tPerc Error: 37.2%\n",
      "False negatives: 291\tPerc Error: 54.39000000000001%\n",
      "Merges:\t\t 45\tPerc Error: 8.41%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2374\n",
      "Number of predicted cells:\t 1769\n",
      "\n",
      "True positives:  1383\tAccuracy:   58.26%\n",
      "\n",
      "False positives: 100\tPerc Error: 16.1%\n",
      "False negatives: 237\tPerc Error: 38.16%\n",
      "Merges:\t\t 284\tPerc Error: 45.73%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2374\n",
      "Number of predicted cells:\t 2243\n",
      "\n",
      "True positives:  2080\tAccuracy:   87.62%\n",
      "\n",
      "False positives: 90\tPerc Error: 31.14%\n",
      "False negatives: 129\tPerc Error: 44.64%\n",
      "Merges:\t\t 67\tPerc Error: 23.18%\n",
      "Splits:\t\t 3\tPerc Error: 1.04%\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2769\n",
      "Number of predicted cells:\t 1858\n",
      "\n",
      "True positives:  1386\tAccuracy:   50.05%\n",
      "\n",
      "False positives: 90\tPerc Error: 9.9%\n",
      "False negatives: 441\tPerc Error: 48.51%\n",
      "Merges:\t\t 374\tPerc Error: 41.14%\n",
      "Splits:\t\t 4\tPerc Error: 0.44%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2769\n",
      "Number of predicted cells:\t 2465\n",
      "\n",
      "True positives:  2272\tAccuracy:   82.05%\n",
      "\n",
      "False positives: 87\tPerc Error: 18.12%\n",
      "False negatives: 303\tPerc Error: 63.12%\n",
      "Merges:\t\t 76\tPerc Error: 15.83%\n",
      "Splits:\t\t 14\tPerc Error: 2.92%\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2329\n",
      "Number of predicted cells:\t 1643\n",
      "\n",
      "True positives:  1289\tAccuracy:   55.35%\n",
      "\n",
      "False positives: 115\tPerc Error: 15.09%\n",
      "False negatives: 414\tPerc Error: 54.33%\n",
      "Merges:\t\t 231\tPerc Error: 30.31%\n",
      "Splits:\t\t 2\tPerc Error: 0.26%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2329\n",
      "Number of predicted cells:\t 2104\n",
      "\n",
      "True positives:  1917\tAccuracy:   82.31%\n",
      "\n",
      "False positives: 109\tPerc Error: 25.71%\n",
      "False negatives: 240\tPerc Error: 56.599999999999994%\n",
      "Merges:\t\t 74\tPerc Error: 17.45%\n",
      "Splits:\t\t 1\tPerc Error: 0.24%\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 1582\n",
      "Number of predicted cells:\t 1273\n",
      "\n",
      "True positives:  1063\tAccuracy:   67.19000000000001%\n",
      "\n",
      "False positives: 84\tPerc Error: 24.490000000000002%\n",
      "False negatives: 158\tPerc Error: 46.06%\n",
      "Merges:\t\t 101\tPerc Error: 29.45%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 1582\n",
      "Number of predicted cells:\t 1383\n",
      "\n",
      "True positives:  1252\tAccuracy:   79.14%\n",
      "\n",
      "False positives: 64\tPerc Error: 29.770000000000003%\n",
      "False negatives: 117\tPerc Error: 54.42%\n",
      "Merges:\t\t 21\tPerc Error: 9.77%\n",
      "Splits:\t\t 13\tPerc Error: 6.05%\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2373\n",
      "Number of predicted cells:\t 1857\n",
      "\n",
      "True positives:  1543\tAccuracy:   65.02%\n",
      "\n",
      "False positives: 87\tPerc Error: 15.4%\n",
      "False negatives: 256\tPerc Error: 45.31%\n",
      "Merges:\t\t 219\tPerc Error: 38.76%\n",
      "Splits:\t\t 3\tPerc Error: 0.53%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 2373\n",
      "Number of predicted cells:\t 2178\n",
      "\n",
      "True positives:  2047\tAccuracy:   86.26%\n",
      "\n",
      "False positives: 79\tPerc Error: 24.84%\n",
      "False negatives: 191\tPerc Error: 60.06%\n",
      "Merges:\t\t 44\tPerc Error: 13.84%\n",
      "Splits:\t\t 4\tPerc Error: 1.26%\n",
      "edge/interior prediction shape: (6, 30, 135, 160, 4)\n",
      "fgbg mask shape: (6, 30, 135, 160, 2)\n",
      "argmax shape: (6, 30, 135, 160, 1)\n",
      "labeled_images shape: (6, 30, 135, 160, 1)\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:Ground truth frame is empty\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ObjectAccuracy' object has no attribute 'seg_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fb9590f5b0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpredict_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeled_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# fgbg_predict = fgbg_model.predict(X_test)[-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mfgbg_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fgbg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgbg_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# predict_seg = conv_model.predict(X_test)[-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b5fccd7a3113>\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(model, y_test, y_pred)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_object_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_lbl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_lbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mn_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepcell-tf/deepcell/metrics.py\u001b[0m in \u001b[0;36mcalc_object_stats\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    596\u001b[0m                                \u001b[0mcutoff2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutoff2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                                seg=self.seg)\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} samples processed'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepcell-tf/deepcell/metrics.py\u001b[0m in \u001b[0;36msave_to_dataframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m         }\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseg_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ObjectAccuracy' object has no attribute 'seg_score'"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "fgbg_gru_model_name = 'fgbg_gru_featurenet_model_full'\n",
    "fgbg_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_gru_model_name))\n",
    "\n",
    "conv_gru_model_name = 'conv_gru_featurenet_model_full'\n",
    "conv_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_gru_model_name))\n",
    "\n",
    "# Predict\n",
    "fgbg_metrics = []\n",
    "seg_metrics = []\n",
    "\n",
    "for i in range(0, len(test_dict['X']), 6):\n",
    "    top = min(i+6, len(test_dict['X']))\n",
    "    X_test, y_test = test_dict['X'][i:top], test_dict['y'][i:top]\n",
    "    test_images, test_images_fgbg = test_gru(X_test, fgbg_gru_weights_file, conv_gru_weights_file, \n",
    "                                         gru_kernel_size=3, gru=True)\n",
    "\n",
    "    labeled_images, fg_thresh = post_process(test_images, test_images_fgbg)\n",
    "\n",
    "    fgbg_predict = fg_thresh\n",
    "    predict_seg = labeled_images\n",
    "    # fgbg_predict = fgbg_model.predict(X_test)[-1]\n",
    "    fgbg_metrics.append(get_metrics('fgbg', y_test, fgbg_predict))\n",
    "\n",
    "    # predict_seg = conv_model.predict(X_test)[-1]\n",
    "    seg_metrics.append(get_metrics('segmentation', y_test, predict_seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________FGBG FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 12828\n",
      "Number of predicted cells:\t 9410\n",
      "\n",
      "True positives:  7267\tAccuracy:   56.65%\n",
      "\n",
      "False positives: 702\tPerc Error: 17.91%\n",
      "False negatives: 1819\tPerc Error: 46.400000000000006%\n",
      "Merges:\t\t 1390\tPerc Error: 35.46%\n",
      "Splits:\t\t 9\tPerc Error: 0.22999999999999998%\n"
     ]
    }
   ],
   "source": [
    "n_true = np.sum([i[0] for i in fgbg_metrics])\n",
    "n_pred = np.sum([i[1] for i in fgbg_metrics])\n",
    "false_pos = np.sum([i[2] for i in fgbg_metrics])\n",
    "true_pos = np.sum([i[3] for i in fgbg_metrics])\n",
    "false_neg = np.sum([i[4] for i in fgbg_metrics])\n",
    "split = np.sum([i[5] for i in fgbg_metrics])\n",
    "merge = np.sum([i[6] for i in fgbg_metrics])\n",
    "\n",
    "\n",
    "print('\\n____________FGBG FINAL Object-based statistics____________\\n')\n",
    "print('Number of true cells:\\t\\t', int(np.sum(n_true)))\n",
    "print('Number of predicted cells:\\t', int(np.sum(n_pred)))\n",
    "print('\\nTrue positives:  {}\\tAccuracy:   {}%'.format(\n",
    "            int(np.sum(true_pos)),\n",
    "            100 * round(np.sum(true_pos) / np.sum(n_true), 4)))\n",
    "\n",
    "total_err = (np.sum(np.sum(false_pos) + np.sum(false_neg) + np.sum(split) + np.sum(merge)))\n",
    "print('\\nFalse positives: {}\\tPerc Error: {}%'.format(int(np.sum(false_pos)), \n",
    "              100 * round(np.sum(false_pos) / total_err, 4)))\n",
    "print('False negatives: {}\\tPerc Error: {}%'.format( int(np.sum(false_neg)),\n",
    "              100 * round(np.sum(false_neg) / total_err, 4)))\n",
    "print('Merges:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(merge)),\n",
    "              100 * round(np.sum(merge) / total_err, 4)))\n",
    "print('Splits:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(split)),\n",
    "              100 * round(np.sum(split) / total_err, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________SEGMENTATION FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 12828\n",
      "Number of predicted cells:\t 11630\n",
      "\n",
      "True positives:  10581\tAccuracy:   82.48%\n",
      "\n",
      "False positives: 628\tPerc Error: 27.779999999999998%\n",
      "False negatives: 1271\tPerc Error: 56.21000000000001%\n",
      "Merges:\t\t 327\tPerc Error: 14.46%\n",
      "Splits:\t\t 35\tPerc Error: 1.55%\n"
     ]
    }
   ],
   "source": [
    "n_true = np.sum([i[0] for i in seg_metrics])\n",
    "n_pred = np.sum([i[1] for i in seg_metrics])\n",
    "false_pos = np.sum([i[2] for i in seg_metrics])\n",
    "true_pos = np.sum([i[3] for i in seg_metrics])\n",
    "false_neg = np.sum([i[4] for i in seg_metrics])\n",
    "split = np.sum([i[5] for i in seg_metrics])\n",
    "merge = np.sum([i[6] for i in seg_metrics])\n",
    "\n",
    "\n",
    "print('\\n____________SEGMENTATION FINAL Object-based statistics____________\\n')\n",
    "print('Number of true cells:\\t\\t', int(np.sum(n_true)))\n",
    "print('Number of predicted cells:\\t', int(np.sum(n_pred)))\n",
    "print('\\nTrue positives:  {}\\tAccuracy:   {}%'.format(\n",
    "            int(np.sum(true_pos)),\n",
    "            100 * round(np.sum(true_pos) / np.sum(n_true), 4)))\n",
    "\n",
    "total_err = (np.sum(np.sum(false_pos) + np.sum(false_neg) + np.sum(split) + np.sum(merge)))\n",
    "print('\\nFalse positives: {}\\tPerc Error: {}%'.format(int(np.sum(false_pos)), \n",
    "              100 * round(np.sum(false_pos) / total_err, 4)))\n",
    "print('False negatives: {}\\tPerc Error: {}%'.format( int(np.sum(false_neg)),\n",
    "              100 * round(np.sum(false_neg) / total_err, 4)))\n",
    "print('Merges:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(merge)),\n",
    "              100 * round(np.sum(merge) / total_err, 4)))\n",
    "print('Splits:\\t\\t {}\\tPerc Error: {}%'.format(int(np.sum(split)),\n",
    "              100 * round(np.sum(split) / total_err, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Kernel size (5, 5) and (7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 40, 216, 256, 1)   0         \n",
      "_________________________________________________________________\n",
      "reflection_padding3d_28 (Ref (None, 42, 276, 316, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_224 (Conv3D)          (None, 42, 273, 313, 32)  544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_252 (Bat (None, 42, 273, 313, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_268 (Activation)  (None, 42, 273, 313, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_225 (Conv3D)          (None, 42, 271, 311, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_253 (Bat (None, 42, 271, 311, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_269 (Activation)  (None, 42, 271, 311, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_84 (Dilat (None, 42, 270, 310, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_226 (Conv3D)          (None, 42, 266, 306, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_254 (Bat (None, 42, 266, 306, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_270 (Activation)  (None, 42, 266, 306, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_227 (Conv3D)          (None, 42, 262, 302, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_255 (Bat (None, 42, 262, 302, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_271 (Activation)  (None, 42, 262, 302, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_85 (Dilat (None, 42, 260, 300, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_228 (Conv3D)          (None, 42, 252, 292, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_256 (Bat (None, 42, 252, 292, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_272 (Activation)  (None, 42, 252, 292, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_229 (Conv3D)          (None, 42, 244, 284, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_257 (Bat (None, 42, 244, 284, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_273 (Activation)  (None, 42, 244, 284, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_86 (Dilat (None, 42, 240, 280, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_230 (Conv3D)          (None, 42, 216, 256, 128) 65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_258 (Bat (None, 42, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_274 (Activation)  (None, 42, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_231 (Conv3D)          (None, 40, 216, 256, 128) 49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_259 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_275 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_16 (ConvGRU2D)   (None, 40, 216, 256, 32)  384096    \n",
      "_________________________________________________________________\n",
      "activation_276 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_17 (ConvGRU2D)   (None, 40, 216, 256, 32)  301152    \n",
      "_________________________________________________________________\n",
      "activation_277 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "tensor_product_56 (TensorPro (None, 40, 216, 256, 128) 4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_260 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_278 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "tensor_product_57 (TensorPro (None, 40, 216, 256, 2)   258       \n",
      "_________________________________________________________________\n",
      "softmax_28 (Softmax)         (None, 40, 216, 256, 2)   0         \n",
      "=================================================================\n",
      "Total params: 853,762\n",
      "Trainable params: 852,610\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        (None, 40, 216, 256, 3)   0         \n",
      "_________________________________________________________________\n",
      "reflection_padding3d_29 (Ref (None, 42, 276, 316, 3)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_232 (Conv3D)          (None, 42, 273, 313, 32)  1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_261 (Bat (None, 42, 273, 313, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_279 (Activation)  (None, 42, 273, 313, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_233 (Conv3D)          (None, 42, 271, 311, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_262 (Bat (None, 42, 271, 311, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_280 (Activation)  (None, 42, 271, 311, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_87 (Dilat (None, 42, 270, 310, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_234 (Conv3D)          (None, 42, 266, 306, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_263 (Bat (None, 42, 266, 306, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_281 (Activation)  (None, 42, 266, 306, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_235 (Conv3D)          (None, 42, 262, 302, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_264 (Bat (None, 42, 262, 302, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_282 (Activation)  (None, 42, 262, 302, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_88 (Dilat (None, 42, 260, 300, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_236 (Conv3D)          (None, 42, 252, 292, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_265 (Bat (None, 42, 252, 292, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_283 (Activation)  (None, 42, 252, 292, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_237 (Conv3D)          (None, 42, 244, 284, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_266 (Bat (None, 42, 244, 284, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_284 (Activation)  (None, 42, 244, 284, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_89 (Dilat (None, 42, 240, 280, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_238 (Conv3D)          (None, 42, 216, 256, 128) 65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_267 (Bat (None, 42, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_285 (Activation)  (None, 42, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_239 (Conv3D)          (None, 40, 216, 256, 128) 49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_268 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_286 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_18 (ConvGRU2D)   (None, 40, 216, 256, 32)  384096    \n",
      "_________________________________________________________________\n",
      "activation_287 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_19 (ConvGRU2D)   (None, 40, 216, 256, 32)  301152    \n",
      "_________________________________________________________________\n",
      "activation_288 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "tensor_product_58 (TensorPro (None, 40, 216, 256, 128) 4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_269 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_289 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "tensor_product_59 (TensorPro (None, 40, 216, 256, 2)   258       \n",
      "_________________________________________________________________\n",
      "softmax_29 (Softmax)         (None, 40, 216, 256, 2)   0         \n",
      "=================================================================\n",
      "Total params: 854,786\n",
      "Trainable params: 853,634\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        (None, 40, 216, 256, 1)   0         \n",
      "_________________________________________________________________\n",
      "reflection_padding3d_30 (Ref (None, 42, 276, 316, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_240 (Conv3D)          (None, 42, 273, 313, 32)  544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_270 (Bat (None, 42, 273, 313, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_290 (Activation)  (None, 42, 273, 313, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_241 (Conv3D)          (None, 42, 271, 311, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_271 (Bat (None, 42, 271, 311, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_291 (Activation)  (None, 42, 271, 311, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_90 (Dilat (None, 42, 270, 310, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_242 (Conv3D)          (None, 42, 266, 306, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_272 (Bat (None, 42, 266, 306, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_292 (Activation)  (None, 42, 266, 306, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_243 (Conv3D)          (None, 42, 262, 302, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_273 (Bat (None, 42, 262, 302, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_293 (Activation)  (None, 42, 262, 302, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_91 (Dilat (None, 42, 260, 300, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_244 (Conv3D)          (None, 42, 252, 292, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_274 (Bat (None, 42, 252, 292, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_294 (Activation)  (None, 42, 252, 292, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_245 (Conv3D)          (None, 42, 244, 284, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_275 (Bat (None, 42, 244, 284, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_295 (Activation)  (None, 42, 244, 284, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_92 (Dilat (None, 42, 240, 280, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_246 (Conv3D)          (None, 42, 216, 256, 128) 65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_276 (Bat (None, 42, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_296 (Activation)  (None, 42, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_247 (Conv3D)          (None, 40, 216, 256, 128) 49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_277 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_297 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_20 (ConvGRU2D)   (None, 40, 216, 256, 32)  384096    \n",
      "_________________________________________________________________\n",
      "activation_298 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_21 (ConvGRU2D)   (None, 40, 216, 256, 32)  301152    \n",
      "_________________________________________________________________\n",
      "activation_299 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "tensor_product_60 (TensorPro (None, 40, 216, 256, 128) 4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_278 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_300 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "tensor_product_61 (TensorPro (None, 40, 216, 256, 4)   516       \n",
      "_________________________________________________________________\n",
      "softmax_30 (Softmax)         (None, 40, 216, 256, 4)   0         \n",
      "=================================================================\n",
      "Total params: 854,020\n",
      "Trainable params: 852,868\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        (None, 40, 216, 256, 5)   0         \n",
      "_________________________________________________________________\n",
      "reflection_padding3d_31 (Ref (None, 42, 276, 316, 5)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_248 (Conv3D)          (None, 42, 273, 313, 32)  2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_279 (Bat (None, 42, 273, 313, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_301 (Activation)  (None, 42, 273, 313, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_249 (Conv3D)          (None, 42, 271, 311, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_280 (Bat (None, 42, 271, 311, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_302 (Activation)  (None, 42, 271, 311, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_93 (Dilat (None, 42, 270, 310, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_250 (Conv3D)          (None, 42, 266, 306, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_281 (Bat (None, 42, 266, 306, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_303 (Activation)  (None, 42, 266, 306, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_251 (Conv3D)          (None, 42, 262, 302, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_282 (Bat (None, 42, 262, 302, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_304 (Activation)  (None, 42, 262, 302, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_94 (Dilat (None, 42, 260, 300, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_252 (Conv3D)          (None, 42, 252, 292, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_283 (Bat (None, 42, 252, 292, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_305 (Activation)  (None, 42, 252, 292, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_253 (Conv3D)          (None, 42, 244, 284, 32)  9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_284 (Bat (None, 42, 244, 284, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_306 (Activation)  (None, 42, 244, 284, 32)  0         \n",
      "_________________________________________________________________\n",
      "dilated_max_pool3d_95 (Dilat (None, 42, 240, 280, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_254 (Conv3D)          (None, 42, 216, 256, 128) 65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_285 (Bat (None, 42, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_307 (Activation)  (None, 42, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_255 (Conv3D)          (None, 40, 216, 256, 128) 49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_286 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_308 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_22 (ConvGRU2D)   (None, 40, 216, 256, 32)  384096    \n",
      "_________________________________________________________________\n",
      "activation_309 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_gr_u2d_23 (ConvGRU2D)   (None, 40, 216, 256, 32)  301152    \n",
      "_________________________________________________________________\n",
      "activation_310 (Activation)  (None, 40, 216, 256, 32)  0         \n",
      "_________________________________________________________________\n",
      "tensor_product_62 (TensorPro (None, 40, 216, 256, 128) 4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_287 (Bat (None, 40, 216, 256, 128) 512       \n",
      "_________________________________________________________________\n",
      "activation_311 (Activation)  (None, 40, 216, 256, 128) 0         \n",
      "_________________________________________________________________\n",
      "tensor_product_63 (TensorPro (None, 40, 216, 256, 4)   516       \n",
      "_________________________________________________________________\n",
      "softmax_31 (Softmax)         (None, 40, 216, 256, 4)   0         \n",
      "=================================================================\n",
      "Total params: 856,068\n",
      "Trainable params: 854,916\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"model_42\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_42\".\n",
      "WARNING:tensorflow:Output \"model_43\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_43\".\n",
      "WARNING:tensorflow:Output \"model_45\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_45\".\n",
      "WARNING:tensorflow:Output \"model_46\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_46\".\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 412\n",
      "Number of predicted cells:\t 381\n",
      "\n",
      "True positives:  341\tAccuracy:   82.77%\n",
      "\n",
      "False positives: 10\tPerc Error: 24.39%\n",
      "False negatives: 4\tPerc Error: 9.76%\n",
      "Merges:\t\t 27\tPerc Error: 65.85%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "INFO:tensorflow:0 samples processed\n",
      "\n",
      "____________FINAL Object-based statistics____________\n",
      "\n",
      "Number of true cells:\t\t 412\n",
      "Number of predicted cells:\t 352\n",
      "\n",
      "True positives:  203\tAccuracy:   49.27%\n",
      "\n",
      "False positives: 149\tPerc Error: 41.620000000000005%\n",
      "False negatives: 209\tPerc Error: 58.379999999999995%\n",
      "Merges:\t\t 0\tPerc Error: 0.0%\n",
      "Splits:\t\t 0\tPerc Error: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "fgbg_gru_model_name = 'fgbg_gru_featurenet_model_k5'\n",
    "fgbg_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(fgbg_gru_model_name))\n",
    "\n",
    "conv_gru_model_name = 'conv_gru_featurenet_model_k5'\n",
    "conv_gru_weights_file = os.path.join(MODEL_DIR, '{}.h5'.format(conv_gru_model_name))\n",
    "\n",
    "# Initialize Models\n",
    "fgbg_gru_model, conv_gru_model = get_gru_model(gru_kernel_size=5)\n",
    "\n",
    "# Compile models\n",
    "fgbg_gru_model.compile(SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),metrics=['accuracy'])\n",
    "fgbg_gru_model.load_weights(fgbg_gru_weights_file)\n",
    "\n",
    "conv_gru_model.compile(SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),metrics=['accuracy'])\n",
    "conv_gru_model.load_weights(conv_gru_weights_file)\n",
    "\n",
    "\n",
    "# Predict\n",
    "X_test, y_test = test_dict['X'][:2], test_dict['y'][:2]\n",
    "\n",
    "predict_gru = fgbg_gru_model.predict(X_test)[-1]\n",
    "print_metrics('fgbg', y_test, predict_gru)\n",
    "\n",
    "predict_seg = conv_gru_model.predict(X_test)[-1]\n",
    "print_metrics('segmentation', y_test, predict_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
